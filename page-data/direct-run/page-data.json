{"componentChunkName":"component---src-pages-direct-run-mdx","path":"/direct-run/","result":{"pageContext":{"frontmatter":{"title":"The elaunch.py command line tool"},"relativePagePath":"/direct-run.mdx","titleType":"page","MdxNode":{"id":"83a810a0-74ca-5f78-854d-5eb9f141ab72","children":[],"parent":"ae465a95-0524-5bba-9857-8ffc2c229dfd","internal":{"content":"---\ntitle: The elaunch.py command line tool\n---\n\nimport { CarbonForIbmDotcom } from \"@carbon/pictograms-react\";\nimport { ArtTools_01 } from \"@carbon/pictograms-react\";\nimport { FileBackup } from \"@carbon/pictograms-react\";\nimport { Tools } from \"@carbon/pictograms-react\";\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nThe `elaunch.py` command line tool executes and monitors virtual experiments. You can use it to run experiments on your laptop or on a High Performance Computing Cluster. When you submit a virtual experiment via ST4SD API it is executed by `elaunch.py`.\n\n</PageDescription>\n\n\n<AnchorLinks>\n\n  <AnchorLink>Running experiments with elaunch.py</AnchorLink>\n  <AnchorLink>Providing the inputs to the experiment</AnchorLink>\n  <AnchorLink>Checking if your experiment worked</AnchorLink>\n  <AnchorLink>What is the output of my experiment ?</AnchorLink>\n  <AnchorLink>Troubleshooting</AnchorLink>\n</AnchorLinks>\n\n\n## Install elaunch.py\n\nIf you haven't already, install the `st4sd-runtime-core` python package:\n\n```\npip install \"st4sd-runtime-core[develop]>=2.5.1\"\n```\n\n## Running experiments with elaunch.py\n\nUse elaunch.py to run virtual experiments: `elaunch.py <path to experiment>`.\n\nNote, running experiments locally requires using either Linux or MacOS.\nWindows users should either use a Virtual Machine (e.g. [VirtualBox](https://www.virtualbox.org) etc) or the Windows Subsystem for Linux ([WSL](https://learn.microsoft.com/en-us/windows/wsl/install)).\n\nSome experiments, like the below example, also require you to install one of [docker](https://docs.docker.com/engine/install/), [podman](https://podman.io/docs/installation), or [Rancher Desktop](https://docs.rancherdesktop.io/getting-started/installation/) too.\n\nFor example, you can run the workflow [`nanopore-geometry-experiment`](https://github.com/st4sd/nanopore-geometry-experiment) like so:\n\n```bash\n: # Get the directory containing the virtual experiment and cd into it\ngit clone https://github.com/st4sd/nanopore-geometry-experiment.git\ncd nanopore-geometry-experiment\n\n: # Run elaunch.py specifying certain files in the directory created above\nelaunch.py -i docker-example/cif_files.dat -l 40 --nostamp\\\n      --applicationDependencySource=\"nanopore-database=cif:copy\" \\\n      nanopore-geometry-experiment.package\n```\n\nThe experiment should take about 5 minutes to complete. The `-l 40` option keeps the log printouts to the bare minimum so don't worry if the command is silent for a few minutes. When the experiment completes expect to see something similar to the following text on your terminal:\n\n```\ncompleted-on=2024-03-15 14:39:29.909105\ncost=0\ncreated-on=2024-03-15 14:38:04.402969\ncurrent-stage=stage3\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0', 'stage1', 'stage2', 'stage3']\ntotal-progress=1.0\nupdated=2024-03-15 14:39:33.804727\nupdated-on=2024-03-15 14:39:33.804727\n```\n\n<InlineNotification kind=\"info\">\n\nIf you run the same command a second time elaunch.py will complain that the experiment instance already exists. Either remove the `--nostamp` argument or delete the directory and retry `elaunch.py`. See Section [What is the output of my experiment?](#what-is-the-output-of-my-experiment) for more information.\n\n</InlineNotification>\n\n\n## Providing the inputs to the experiment\n\nThe experiment requires two types of inputs:\nthe **cif_files.dat** input file, which contains a list of filenames, and\nthe **nanopore-database** application dependency, a directory containing the files listed in **cif_files.dat**.\n\nNote that application dependencies are directories located in the root of the virtual experiment instance. These directories are populated by the runtime system using the `--applicationDependencySource=$appDepName:/path/to/source` command-line argument in `elaunch.py`.\n\nFor more details, refer to the [application-dependencies documentation](/workflow-specification#application-dependencies).\n\n## Checking if your experiment worked\n\nIf the experiment works `elaunch.py` prints `exit-status=Success` before it terminates and then exits with return code 0. You can find more information about the status of your experiment under the file `${package_name}-${timestamp}.instance/output/status.txt`. For example, here's a `status.txt` for a successful run of an experiment:\n\n```\ncompleted-on=2025-03-21 13:15:19.790371\ncost=0\ncreated-on=2025-03-21 13:14:30.088069\ncurrent-stage=stage2\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0', 'stage1', 'stage2']\ntotal-progress=1.0\nupdated=2025-03-21 13:15:19.799143\nupdated-on=2025-03-21 13:15:19.799143\n```\n\nIf the experiment fails you will see the line `exit-status=Failed` in the logs of `elaunch.py` and it will exit with a return code other than `0`. If the experiment failed after the instance directory was created you will see this information in the `output/status.txt` file too. Common reasons for failures are invalid syntax, missing input files, or requesting a compute resource that is not available. For more information and dealing with these errors see our [Troubleshooting](#troubleshooting) section.\n\n\n## What is the output of my experiment ?\n\nLooking inside the instance directory created for the experiment, we see the following:\n\n```\nls -lth nanopore-geometry-experiment.instance\ntotal 64\ndrwxrwxr-x@ 10 user  wheel   320B 21 Mar 13:15 output/\n-rw-r--r--@  1 user  wheel    28K 21 Mar 13:15 status.db\n-rw-rw-r--@  1 user  wheel   536B 21 Mar 13:14 elaunch.yaml\ndrwxr-xr-x@  5 user  wheel   160B 21 Mar 13:14 hooks/\ndrwxrwxr-x@  5 user  wheel   160B 21 Mar 13:14 stages/\ndrwxr-xr-x@  5 user  wheel   160B 21 Mar 13:14 conf/\nlrwxrwxr-x@  1 user  wheel    31B 21 Mar 13:14 python@ -> /Users/user/venvs/st4sd\ndrwxrwxr-x@  3 user  wheel    96B 21 Mar 13:14 input/\ndrwxr-xr-x@  4 user  wheel   128B 21 Mar 13:03 nanopore-database/\n```\n\nIn order of importance:\n\n* **output**: This directory contains metadata about the key outputs of the experiment as well as the measured properties of the input systems the experiment processed. You can find more information about the contents of this directory in our detailed [breakdown of the output directory](/direct-run-advanced#the-output-directory).\n* **stages**: This directory holds all the working directories of all the steps that were executed during this experiment instance\n* **input**: The input files and variable parameterisation files we provided to the `elaunch.py` command earlier\n* **nanopore-database**: This is an application-dependency that the experiment for reading information about the nanoporous materials it simulates\n* **conf**: The experiment definition\n* **hooks**: This contains code used to produce the interface properties. In general, it may also contain code that checks whether tasks finished successfully or not, however then `nanopore-geometry-experiment` does not use this feature.\n* **python**: A link to the virtual environment that was used during the execution of the experiment\n* **elaunch.yaml**: A YAML file containing metadata about the execution of the experiment\n* **status.db**: A SQLITE database containing metadata about execution of the experiment\n\n\n### Key outputs\n\nAll experiments produce files, but not all generated files are equally important. To this end ST4SD has the concept of key-outputs. These are files, and directories, that an experiment produces which the developers of the experiment consider important.\n\nThe file `$instanceDirectory/output/output.json` contains metadata about the key outputs of the experiment. Here's how tha file looks like for the experiment we just ran:\n\n```\n{\n    \"geometricalProperties\": {\n        \"creationtime\": \"1742562196.4740903\",\n        \"description\": \"\",\n        \"filename\": \"geometry.tgz\",\n        \"filepath\": \"stages/stage2/AggregateGeometry/geometry.tgz\",\n        \"final\": \"yes\",\n        \"production\": \"yes\",\n        \"type\": \"\",\n        \"version\": \"1\"\n    }\n}\n```\n\nThe experiment generates a single key output, **geometricalProperties**, which is a tar file named `geometry.tgz`. This file is created by the `stage2.AggregateGeometry` step.\n\n\n### Measured properties\n\nKey outputs are not always immediately parseable without deep understanding of their format. To address this, ST4SD supports the **interface** feature. This feature allows workflow developers to extract measured properties and store them in a CSV file, making the data easier to consume.\n\nExperiments that implement an `interface` will produce a file under `${instance-directory}/output/properties.csv`. Here is the file that the `nanopore-geometry-experiment` produced above:\n\n```\ninput-id;d_is;d_fs;d_isfs;asa_m^2/cm^3;asa_m^2/g;nasa_m^2/cm^3;nasa_m^2/g;unitcell_volume;density;av_volume_fraction;av_cm^3/g;nav_volume_fraction;nav_cm^3/g;n_pockets\nCoRE2019/GUJVOX_clean;3.98106;2.74095;3.93078;0.0;0.0;760.654;564.703;1164.59;1.347;0.0;0.0;0.016015;0.0118894;1.0\n```\n\nThe CSV file will always contain the `input-id` column. Its values are the identifiers of the input system ids for which the virtual experiment measured properties. The remaining columns contain the measured properties for the input systems.\n\n## Troubleshooting\n\n### Unable to create instance directory at specified location Error\n\nIf you run the same command a second time elaunch.py will complain that the experiment instance already exists:\n\n```\ncompleted-on=N/A\ncost=0\ncreated-on=N/A\ncurrent-stage=None\nerror-description=ExperimentSetupError Error encountered while setting up experiment.\\\\nPackage validation failed - cannot deploy\\\\nUnderlying error: Unable to create instance directory at specified location.\\\\nUnderlying error: [Errno 17] File exists: '/private/tmp/test/nanopore-geometry-experiment/nanopore-geometry-experiment/nanopore-geometry-experiment/nanopore-geometry-experiment.instance'\nexit-status=Failed\nexperiment-state=failed\nstage-progress=0\nstage-state=Initialising\nstages=[]\ntotal-progress=0\nupdated=2025-03-21 13:25:21.950382\nupdated-on=2025-03-21 13:25:21.950382\n```\n\nTo fix this problem, either remove the `--nostamp` argument or delete the directory and retry `elaunch.py`.\n\n### Investigating a Failed experiment\n\nIf the `exit-status` of your experiment instance is `Failed` then this means that at least one of your components was unable to terminate successfully. You can find the name of the component that caused the experiment to fail in the `status` file and printout.\n\nHere is an example:\n\n```\ncompleted-on=2024-05-23 09:44:03.757679\ncost=0\ncreated-on=2024-05-23 09:42:19.223491\ncurrent-stage=stage1\nerror-description=Stage 1 failed. Reason:\\\\\\\\n3 jobs failed unexpectedly.\\\\\\\\nJob: stage1.PartialSum0. Returncode 1. Reason KnownIssue\\\\\\\\nJob: stage1.PartialSum2. Returncode 1. Reason KnownIssue\\\\\\\\nJob: stage1.PartialSum1. Returncode 1. Reason KnownIssue\\\\\\\\n\nexit-status=Failed\nexperiment-state=finished\nstage-progress=0.5\nstage-state=failed\nstages=['stage0', 'stage1', 'stage2', 'stage3']\ntotal-progress=0.875\nupdated=2024-05-23 09:44:08.793316\nupdated-on=2024-05-23 09:44:08.793316\n```\n\nThe error reports that multiple components failed: `stage1.PartialSum0`, `stage1.PartialSum1`, `stage1.PartialSum2`.\n\nYou may also get a full view of the state of the experiment by using the `einspect.py -f all` tool.\n\n```\n========== STAGE 0 ==========\n\nComponents using engine-type: engine\nreference, state, backend, isWaitingOnOutput, engineExitReason, lastTaskRunTime, lastTaskRunState\nstage0.GenerateInput, finished, local, True, Success, 0:00:00.358677, finished\n\n========== STAGE 1 ==========\n\nComponents using engine-type: engine\nreference, state, backend, isWaitingOnOutput, engineExitReason, lastTaskRunTime, lastTaskRunState\nstage1.ExtractRow0, finished, local, True, Success, 0:01:00.246955, finished\nstage1.ExtractRow1, finished, local, True, Success, 0:01:00.209115, finished\nstage1.ExtractRow2, finished, local, True, Success, 0:01:00.226946, finished\nstage1.PartialSum0, failed, local, True, KnownIssue, 0:00:00.323739, failed\nstage1.PartialSum1, failed, local, True, KnownIssue, 0:00:00.336899, failed\nstage1.PartialSum2, failed, local, True, KnownIssue, 0:00:00.360914, failed\n\n========== STAGE 2 ==========\n\nComponents using engine-type: engine\nreference, state, backend, isWaitingOnOutput, engineExitReason, lastTaskRunTime, lastTaskRunState\nstage2.Sum, component_shutdown, local, False, Killed, N/A, N/A\n\n========== STAGE 3 ==========\n\nComponents using engine-type: engine\nreference, state, backend, isWaitingOnOutput, engineExitReason, lastTaskRunTime, lastTaskRunState\nstage3.Cat, finished, local, True, Success, 0:00:00.011466, finished\n```\n\nAfter you spot a `Failed` component, try looking at the files it produced, including its stdout and stderr (for some backends both streams get fed into stdout). Recall that you can find these files under `$INSTANCE_DIR/stages/stage<stage index>/<component name>/`. Look for the `out.stdout` and `out.stderr` files.\n\nSometimes, a component fails because one of its predecessors (direct, or indirect) produced unexpected output. To find the predecessors of a component, look at the `$INSTANCE_DIR/conf/flowir_instance.yaml`, locate the component you are investigating and then follow its predecessors by looking at the `references` of the component. You can then investigate the output files and stdout/stderr of those components to see if you can spot why the downstream component failed.\n\n\n## The experiment outputs\n\n## Learn more\n\n<div className=\"expressive-content-list-group\">\n\n<ExpressiveList\n    title=\"Write experiments\"\n    background=\"true\"\n    pictogram={<FileBackup />}>\n\nGet an introduction to [writing virtual experiment](/write-experiments) with ST4SD Core.\n\n  </ExpressiveList>\n\n<ExpressiveList\n    title=\"Advanced usage of elaunch.py\"\n    background=\"true\"\n    pictogram={<Tools />}>\n\nThis example only scratches the surface of how you can use elaunch.py. See [elaunch.py for advanced users](/direct-run-advanced) for more information about using `elaunch.py` including running on High Performance Computing clusters.\n\n  </ExpressiveList>\n\n  <ExpressiveList\n    title=\"Exploring the Registry UI\"\n    background=\"true\"\n    pictogram={<CarbonForIbmDotcom />}>\n\nLearn about all the features of\n[our web interface](/using-the-virtual-experiments-registry-ui) for browsing and\nexamining virtual experiments packages and runs. You can visit the\n[ST4SD Global Registry](https://registry.st4sd.res.ibm.com/) for a first look.\n\n  </ExpressiveList>\n\n  <ExpressiveList\n    title=\"No Code, No Fuss creation of Experiments\"\n    background=\"true\"\n    pictogram={<ArtTools_01 />}>\n\nUse\n[an interactive Build Canvas and a Graph Library](/build-canvas)\nto create and modify experiments straight from your browser.\n\n  </ExpressiveList>\n\n</div>\n","type":"Mdx","contentDigest":"9677da8fcde0aac966b4b9b2ead1a15c","owner":"gatsby-plugin-mdx","counter":258},"frontmatter":{"title":"The elaunch.py command line tool"},"exports":{},"rawBody":"---\ntitle: The elaunch.py command line tool\n---\n\nimport { CarbonForIbmDotcom } from \"@carbon/pictograms-react\";\nimport { ArtTools_01 } from \"@carbon/pictograms-react\";\nimport { FileBackup } from \"@carbon/pictograms-react\";\nimport { Tools } from \"@carbon/pictograms-react\";\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nThe `elaunch.py` command line tool executes and monitors virtual experiments. You can use it to run experiments on your laptop or on a High Performance Computing Cluster. When you submit a virtual experiment via ST4SD API it is executed by `elaunch.py`.\n\n</PageDescription>\n\n\n<AnchorLinks>\n\n  <AnchorLink>Running experiments with elaunch.py</AnchorLink>\n  <AnchorLink>Providing the inputs to the experiment</AnchorLink>\n  <AnchorLink>Checking if your experiment worked</AnchorLink>\n  <AnchorLink>What is the output of my experiment ?</AnchorLink>\n  <AnchorLink>Troubleshooting</AnchorLink>\n</AnchorLinks>\n\n\n## Install elaunch.py\n\nIf you haven't already, install the `st4sd-runtime-core` python package:\n\n```\npip install \"st4sd-runtime-core[develop]>=2.5.1\"\n```\n\n## Running experiments with elaunch.py\n\nUse elaunch.py to run virtual experiments: `elaunch.py <path to experiment>`.\n\nNote, running experiments locally requires using either Linux or MacOS.\nWindows users should either use a Virtual Machine (e.g. [VirtualBox](https://www.virtualbox.org) etc) or the Windows Subsystem for Linux ([WSL](https://learn.microsoft.com/en-us/windows/wsl/install)).\n\nSome experiments, like the below example, also require you to install one of [docker](https://docs.docker.com/engine/install/), [podman](https://podman.io/docs/installation), or [Rancher Desktop](https://docs.rancherdesktop.io/getting-started/installation/) too.\n\nFor example, you can run the workflow [`nanopore-geometry-experiment`](https://github.com/st4sd/nanopore-geometry-experiment) like so:\n\n```bash\n: # Get the directory containing the virtual experiment and cd into it\ngit clone https://github.com/st4sd/nanopore-geometry-experiment.git\ncd nanopore-geometry-experiment\n\n: # Run elaunch.py specifying certain files in the directory created above\nelaunch.py -i docker-example/cif_files.dat -l 40 --nostamp\\\n      --applicationDependencySource=\"nanopore-database=cif:copy\" \\\n      nanopore-geometry-experiment.package\n```\n\nThe experiment should take about 5 minutes to complete. The `-l 40` option keeps the log printouts to the bare minimum so don't worry if the command is silent for a few minutes. When the experiment completes expect to see something similar to the following text on your terminal:\n\n```\ncompleted-on=2024-03-15 14:39:29.909105\ncost=0\ncreated-on=2024-03-15 14:38:04.402969\ncurrent-stage=stage3\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0', 'stage1', 'stage2', 'stage3']\ntotal-progress=1.0\nupdated=2024-03-15 14:39:33.804727\nupdated-on=2024-03-15 14:39:33.804727\n```\n\n<InlineNotification kind=\"info\">\n\nIf you run the same command a second time elaunch.py will complain that the experiment instance already exists. Either remove the `--nostamp` argument or delete the directory and retry `elaunch.py`. See Section [What is the output of my experiment?](#what-is-the-output-of-my-experiment) for more information.\n\n</InlineNotification>\n\n\n## Providing the inputs to the experiment\n\nThe experiment requires two types of inputs:\nthe **cif_files.dat** input file, which contains a list of filenames, and\nthe **nanopore-database** application dependency, a directory containing the files listed in **cif_files.dat**.\n\nNote that application dependencies are directories located in the root of the virtual experiment instance. These directories are populated by the runtime system using the `--applicationDependencySource=$appDepName:/path/to/source` command-line argument in `elaunch.py`.\n\nFor more details, refer to the [application-dependencies documentation](/workflow-specification#application-dependencies).\n\n## Checking if your experiment worked\n\nIf the experiment works `elaunch.py` prints `exit-status=Success` before it terminates and then exits with return code 0. You can find more information about the status of your experiment under the file `${package_name}-${timestamp}.instance/output/status.txt`. For example, here's a `status.txt` for a successful run of an experiment:\n\n```\ncompleted-on=2025-03-21 13:15:19.790371\ncost=0\ncreated-on=2025-03-21 13:14:30.088069\ncurrent-stage=stage2\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0', 'stage1', 'stage2']\ntotal-progress=1.0\nupdated=2025-03-21 13:15:19.799143\nupdated-on=2025-03-21 13:15:19.799143\n```\n\nIf the experiment fails you will see the line `exit-status=Failed` in the logs of `elaunch.py` and it will exit with a return code other than `0`. If the experiment failed after the instance directory was created you will see this information in the `output/status.txt` file too. Common reasons for failures are invalid syntax, missing input files, or requesting a compute resource that is not available. For more information and dealing with these errors see our [Troubleshooting](#troubleshooting) section.\n\n\n## What is the output of my experiment ?\n\nLooking inside the instance directory created for the experiment, we see the following:\n\n```\nls -lth nanopore-geometry-experiment.instance\ntotal 64\ndrwxrwxr-x@ 10 user  wheel   320B 21 Mar 13:15 output/\n-rw-r--r--@  1 user  wheel    28K 21 Mar 13:15 status.db\n-rw-rw-r--@  1 user  wheel   536B 21 Mar 13:14 elaunch.yaml\ndrwxr-xr-x@  5 user  wheel   160B 21 Mar 13:14 hooks/\ndrwxrwxr-x@  5 user  wheel   160B 21 Mar 13:14 stages/\ndrwxr-xr-x@  5 user  wheel   160B 21 Mar 13:14 conf/\nlrwxrwxr-x@  1 user  wheel    31B 21 Mar 13:14 python@ -> /Users/user/venvs/st4sd\ndrwxrwxr-x@  3 user  wheel    96B 21 Mar 13:14 input/\ndrwxr-xr-x@  4 user  wheel   128B 21 Mar 13:03 nanopore-database/\n```\n\nIn order of importance:\n\n* **output**: This directory contains metadata about the key outputs of the experiment as well as the measured properties of the input systems the experiment processed. You can find more information about the contents of this directory in our detailed [breakdown of the output directory](/direct-run-advanced#the-output-directory).\n* **stages**: This directory holds all the working directories of all the steps that were executed during this experiment instance\n* **input**: The input files and variable parameterisation files we provided to the `elaunch.py` command earlier\n* **nanopore-database**: This is an application-dependency that the experiment for reading information about the nanoporous materials it simulates\n* **conf**: The experiment definition\n* **hooks**: This contains code used to produce the interface properties. In general, it may also contain code that checks whether tasks finished successfully or not, however then `nanopore-geometry-experiment` does not use this feature.\n* **python**: A link to the virtual environment that was used during the execution of the experiment\n* **elaunch.yaml**: A YAML file containing metadata about the execution of the experiment\n* **status.db**: A SQLITE database containing metadata about execution of the experiment\n\n\n### Key outputs\n\nAll experiments produce files, but not all generated files are equally important. To this end ST4SD has the concept of key-outputs. These are files, and directories, that an experiment produces which the developers of the experiment consider important.\n\nThe file `$instanceDirectory/output/output.json` contains metadata about the key outputs of the experiment. Here's how tha file looks like for the experiment we just ran:\n\n```\n{\n    \"geometricalProperties\": {\n        \"creationtime\": \"1742562196.4740903\",\n        \"description\": \"\",\n        \"filename\": \"geometry.tgz\",\n        \"filepath\": \"stages/stage2/AggregateGeometry/geometry.tgz\",\n        \"final\": \"yes\",\n        \"production\": \"yes\",\n        \"type\": \"\",\n        \"version\": \"1\"\n    }\n}\n```\n\nThe experiment generates a single key output, **geometricalProperties**, which is a tar file named `geometry.tgz`. This file is created by the `stage2.AggregateGeometry` step.\n\n\n### Measured properties\n\nKey outputs are not always immediately parseable without deep understanding of their format. To address this, ST4SD supports the **interface** feature. This feature allows workflow developers to extract measured properties and store them in a CSV file, making the data easier to consume.\n\nExperiments that implement an `interface` will produce a file under `${instance-directory}/output/properties.csv`. Here is the file that the `nanopore-geometry-experiment` produced above:\n\n```\ninput-id;d_is;d_fs;d_isfs;asa_m^2/cm^3;asa_m^2/g;nasa_m^2/cm^3;nasa_m^2/g;unitcell_volume;density;av_volume_fraction;av_cm^3/g;nav_volume_fraction;nav_cm^3/g;n_pockets\nCoRE2019/GUJVOX_clean;3.98106;2.74095;3.93078;0.0;0.0;760.654;564.703;1164.59;1.347;0.0;0.0;0.016015;0.0118894;1.0\n```\n\nThe CSV file will always contain the `input-id` column. Its values are the identifiers of the input system ids for which the virtual experiment measured properties. The remaining columns contain the measured properties for the input systems.\n\n## Troubleshooting\n\n### Unable to create instance directory at specified location Error\n\nIf you run the same command a second time elaunch.py will complain that the experiment instance already exists:\n\n```\ncompleted-on=N/A\ncost=0\ncreated-on=N/A\ncurrent-stage=None\nerror-description=ExperimentSetupError Error encountered while setting up experiment.\\\\nPackage validation failed - cannot deploy\\\\nUnderlying error: Unable to create instance directory at specified location.\\\\nUnderlying error: [Errno 17] File exists: '/private/tmp/test/nanopore-geometry-experiment/nanopore-geometry-experiment/nanopore-geometry-experiment/nanopore-geometry-experiment.instance'\nexit-status=Failed\nexperiment-state=failed\nstage-progress=0\nstage-state=Initialising\nstages=[]\ntotal-progress=0\nupdated=2025-03-21 13:25:21.950382\nupdated-on=2025-03-21 13:25:21.950382\n```\n\nTo fix this problem, either remove the `--nostamp` argument or delete the directory and retry `elaunch.py`.\n\n### Investigating a Failed experiment\n\nIf the `exit-status` of your experiment instance is `Failed` then this means that at least one of your components was unable to terminate successfully. You can find the name of the component that caused the experiment to fail in the `status` file and printout.\n\nHere is an example:\n\n```\ncompleted-on=2024-05-23 09:44:03.757679\ncost=0\ncreated-on=2024-05-23 09:42:19.223491\ncurrent-stage=stage1\nerror-description=Stage 1 failed. Reason:\\\\\\\\n3 jobs failed unexpectedly.\\\\\\\\nJob: stage1.PartialSum0. Returncode 1. Reason KnownIssue\\\\\\\\nJob: stage1.PartialSum2. Returncode 1. Reason KnownIssue\\\\\\\\nJob: stage1.PartialSum1. Returncode 1. Reason KnownIssue\\\\\\\\n\nexit-status=Failed\nexperiment-state=finished\nstage-progress=0.5\nstage-state=failed\nstages=['stage0', 'stage1', 'stage2', 'stage3']\ntotal-progress=0.875\nupdated=2024-05-23 09:44:08.793316\nupdated-on=2024-05-23 09:44:08.793316\n```\n\nThe error reports that multiple components failed: `stage1.PartialSum0`, `stage1.PartialSum1`, `stage1.PartialSum2`.\n\nYou may also get a full view of the state of the experiment by using the `einspect.py -f all` tool.\n\n```\n========== STAGE 0 ==========\n\nComponents using engine-type: engine\nreference, state, backend, isWaitingOnOutput, engineExitReason, lastTaskRunTime, lastTaskRunState\nstage0.GenerateInput, finished, local, True, Success, 0:00:00.358677, finished\n\n========== STAGE 1 ==========\n\nComponents using engine-type: engine\nreference, state, backend, isWaitingOnOutput, engineExitReason, lastTaskRunTime, lastTaskRunState\nstage1.ExtractRow0, finished, local, True, Success, 0:01:00.246955, finished\nstage1.ExtractRow1, finished, local, True, Success, 0:01:00.209115, finished\nstage1.ExtractRow2, finished, local, True, Success, 0:01:00.226946, finished\nstage1.PartialSum0, failed, local, True, KnownIssue, 0:00:00.323739, failed\nstage1.PartialSum1, failed, local, True, KnownIssue, 0:00:00.336899, failed\nstage1.PartialSum2, failed, local, True, KnownIssue, 0:00:00.360914, failed\n\n========== STAGE 2 ==========\n\nComponents using engine-type: engine\nreference, state, backend, isWaitingOnOutput, engineExitReason, lastTaskRunTime, lastTaskRunState\nstage2.Sum, component_shutdown, local, False, Killed, N/A, N/A\n\n========== STAGE 3 ==========\n\nComponents using engine-type: engine\nreference, state, backend, isWaitingOnOutput, engineExitReason, lastTaskRunTime, lastTaskRunState\nstage3.Cat, finished, local, True, Success, 0:00:00.011466, finished\n```\n\nAfter you spot a `Failed` component, try looking at the files it produced, including its stdout and stderr (for some backends both streams get fed into stdout). Recall that you can find these files under `$INSTANCE_DIR/stages/stage<stage index>/<component name>/`. Look for the `out.stdout` and `out.stderr` files.\n\nSometimes, a component fails because one of its predecessors (direct, or indirect) produced unexpected output. To find the predecessors of a component, look at the `$INSTANCE_DIR/conf/flowir_instance.yaml`, locate the component you are investigating and then follow its predecessors by looking at the `references` of the component. You can then investigate the output files and stdout/stderr of those components to see if you can spot why the downstream component failed.\n\n\n## The experiment outputs\n\n## Learn more\n\n<div className=\"expressive-content-list-group\">\n\n<ExpressiveList\n    title=\"Write experiments\"\n    background=\"true\"\n    pictogram={<FileBackup />}>\n\nGet an introduction to [writing virtual experiment](/write-experiments) with ST4SD Core.\n\n  </ExpressiveList>\n\n<ExpressiveList\n    title=\"Advanced usage of elaunch.py\"\n    background=\"true\"\n    pictogram={<Tools />}>\n\nThis example only scratches the surface of how you can use elaunch.py. See [elaunch.py for advanced users](/direct-run-advanced) for more information about using `elaunch.py` including running on High Performance Computing clusters.\n\n  </ExpressiveList>\n\n  <ExpressiveList\n    title=\"Exploring the Registry UI\"\n    background=\"true\"\n    pictogram={<CarbonForIbmDotcom />}>\n\nLearn about all the features of\n[our web interface](/using-the-virtual-experiments-registry-ui) for browsing and\nexamining virtual experiments packages and runs. You can visit the\n[ST4SD Global Registry](https://registry.st4sd.res.ibm.com/) for a first look.\n\n  </ExpressiveList>\n\n  <ExpressiveList\n    title=\"No Code, No Fuss creation of Experiments\"\n    background=\"true\"\n    pictogram={<ArtTools_01 />}>\n\nUse\n[an interactive Build Canvas and a Graph Library](/build-canvas)\nto create and modify experiments straight from your browser.\n\n  </ExpressiveList>\n\n</div>\n","fileAbsolutePath":"/home/travis/build/st4sd/overview/src/pages/direct-run.mdx"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}