{"componentChunkName":"component---src-pages-packaging-workflows-mdx","path":"/packaging-workflows/","result":{"pageContext":{"frontmatter":{"title":"Project Types"},"relativePagePath":"/packaging-workflows.mdx","titleType":"page","MdxNode":{"id":"1522c77b-011b-57f7-b7d9-18af63b1c65c","children":[],"parent":"0358e0fa-0e15-5d42-ae36-0fc5e6cd9f93","internal":{"content":"---\ntitle: Project Types\n---\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nThis page describes  how to structure, test, and run your ST4SD virtual experiment projects\n\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Quick guide to selecting a project type</AnchorLink>\n  <AnchorLink>Before beginning</AnchorLink>\n  <AnchorLink>Standard project</AnchorLink>\n  <AnchorLink>Standalone project</AnchorLink>\n  <AnchorLink>Testing projects</AnchorLink>\n  <AnchorLink>Projects and cloud execution</AnchorLink>\n  <AnchorLink>Providing external data to experiments</AnchorLink>\n</AnchorLinks>\n\nST4SD virtual experiments often consist of a variety of files -- such as configuration files, scripts, and [restart hooks](/restart).\n\nST4SD supports two ways of structuring projects in order to collect these files together so your project can be tested and also so those fields will be present when you run the virtual experiment.\n\n**Standard projects** are flexible, allowing for multiple virtual experiment definitions to be bundled together and share files, like scripts and restart hooks.\n\n**Standalone projects**  only support a single virtual experiment and are best suited for workflows with many artifacts or resources that are actively changing (i.e., they have multiple commits).\n\n\n## Quick Guide to Selecting a Project Type\n\nTo identify the best project type for storing your virtual experiment find the statement that is the closest match to your situation:\n\n* *I have assets that need to be present when the virtual experiment runs. These assets are shared between multiple experiments and I can choose where to put them*.\n  * Use a [standard project](#standard-project).\n  * **Recommendation**: If you have an internet accessible location for hosting git repositories e.g. GitHub,  store the workflows there.\n* *I have assets that need to be present when the virtual -experiment runs. However these assets cannot be placed in a git repo due to size restrictions OR they live in a defined COS bucket they can't be moved from*.\n  * Use a [standard project](#standard-project) but specify the assets location as a runtime application-dependency source - see [application dependencies](#providing-external-data-to-experiments).\n  * **Recommendation**: If you have an internet accessible location for hosting git repositories e.g. GitHub,  store the experiments there.\n* *I have a production virtual experiment with multiple restart hooks and/or many required configuration files. I  need to have strong version control and also automated regression testing*.\n  * Use a [standalone project](#standalone-project).\n\n## Before beginning\n\nBefore diving into the below sections there  are a couple of things to be aware of.\n\n### Virtual Experiment Dependencies\n\nThe dependencies of a virtual experiment are a set of directories it requires to be present in the top-level of its instance directory when it runs.\nThese directories are in addition to `input`, `stages`, and `output` which are always created.\n\nThey are specified in the virtual experiment configuration YAML using the key `application-dependencies`:\n\n```yaml path=myworkflow.yaml\napplication-dependencies:\n  default: # platform name\n  \t - $DIRECTORY_NAME_ONE\n  \t - $DIRECTORY_NAME_TWO\n  \t - ...\n```\n\nIn the configuration file these names can be used in references e.g. `$DIRECTORY_NAME_ONE/myconftemplate.dat:ref`.\n\nWhen [testing the configuration](#testing-projects) the parser checks that all direct references to directories that aren't called `input` are listed under `application-dependencies`; i.e., that the directories you are using in the workflow configuration are specified and will be present.\n\nTo populate these directories at run time with the correct files we need to specify the **dependency sources** using one of the following options:\n\n1. Specifying them in a `manifest`, if using [a standard project](#standard-project).\n\n2. Explicitly creating them, if using [a standalone project ](#standalone-project).\n\n3. Specifying them when submitting an experiment via the `st4sd-runtime-service`.\n\nEach of these options is explain in the section below\n\n### Use case\n\nIn the following sections we will illustrate the two project types with a workflow called `myworkflow.yaml` that has:\n- Two required configuration files:\n  - `configuration_template.txt`\n  - `default_model.dat`\n- Two restart hooks:\n  - `component_one_restart.py`\n  - `component_two_restart.py`.\n\n## Standard Project\n\n<InlineNotification>\n\nThis type of project:\n\n* Requires a manifest.\n\n* Allows storing multiple virtual experiments in the same project.\n\n* Required files for execution are stored in the project itself.\n\n</InlineNotification>\n\n<InlineNotification kind=\"success\">\n\nYou can test standard projects using the tool `etest.py` available with `st4sd-runtime-core`\nSee [testing projects](#testing-projects) for more details.\n\n</InlineNotification>\n\nVirtual experiments belonging to a standard project live under a single root directory (which can have any name e.g., \"my-experiments\") and contain at least one **configuration file** and optionally a related **manifest file**.\n\nThe **configuration** is a YAML file containing the FlowIR definition of the virtual experiment (more on FlowIR [here](/tutorial#introduction-to-flowir)), while the **manifest** is a YAML file defining which directories in the project the particular virtual experiment needs and where they will be accessible from when the workflow is running.\n\n<InlineNotification kind=\"warning\">\n\nThe directories specified in the manifest must be under project root directory\n\n</InlineNotification>\n\nThe manifest and configuration files for an experiment can have any name and be stored in separate directories, although a common pattern is for them to be stored together in one directory beneath the root direcory and be called `manifest.yaml` and with the same name of the workflow (e.g. `myworkflow.yaml`), respectively.\n\n<InlineNotification kind=\"warning\">\n\nFor running via the `st4sd-runtime-service` the root directory must be stored on a remotely accessible git repository or a COS bucket.\nSee [projects and cloud execution](#projects-and-cloud-execution) for more details.\n\n</InlineNotification>\n\n<InlineNotification>\n\nStandard projects allow having multiple (manifest+configuration file) pairs in the same project.\n\n</InlineNotification>\n\n### Writing a manifest \n\n\nThe content of the manifest file is a YAML dictionary whose keys/values are:\n\n```yaml\n$APPLICATION_DEPENDENCY_NAME: $RELATIVE_PATH_TO_SOURCE_DIRECTORY[:$METHOD]\n```\n\nWhere:\n\n- `APPLICATION_DEPENDENCY_NAME` is the name you use to refer to the directory containing the files in the virtual experiment configuration. At runtime a directory will be created in the top-level of the workflow instance with this name and populated with contents from the source directory based on `METHOD` (see below).\n- `RELATIVE_PATH_TO_SOURCE_DIRECTORY` is the path to the directory under the root directory of the standard project that you want to access when the virtual experiment runs.\n- `METHOD` defines how you want the directory to be made available. It can be `copy` or `link`. If no method is specified `copy` is used, as it ensures the `data` will be present in the instance when it finishes.\n\n<InlineNotification kind=\"warning\">\n\n**Remember**: the application dependencies in your manifest file must also be listed in your virtual experiment configuration under the top-level key `application-dependencies` (see [here](#providing-external-data-to-experiments)).\nThis is required for testing as it allows checking that the manifest associates source-folders to the application dependencies the workflow expects.\n\n</InlineNotification>\n\n<InlineNotification kind=\"warning\">\n\nIf you host your standard project on GitHub and your manifest file contains application dependency sources that point to other folders in your workflow package, you should use the `copy` method. If you use `link`, the files under the application dependency sources will only be visible to components that use the `local` backend.\n\n</InlineNotification>\n\n\n#### Example Layout\n\nHere is an example of how the [use case](#use-case) could be structured using the standard method:\n\n```bash\nmyworkflow/\n myworkflows/\n   workflowOne/\n      - myworkflow.yaml\n      - manifest.yaml\n   shared_data/\n      - configuration_template.txt\n      - default_model.dat\n   hooks/\n      - __init__.py\n      - component_one_restart.py\n      - component_two_restart.py\n```\n\nThe manifest file would be:\n\n```yaml path=manifest.yaml\ndata: ../shared_data\nhooks: ../hooks\n```\n\nThe configuration file would be:\n\n```yaml path=myworfklow.yaml\napplication-dependencies:\n  default:\n  \t - data\n  \t - hooks\n```\n\nWhen such a virtual experiment is executed the `hooks` will be automatically run and the data files will be available in `data/`.\nFor example, the path to `default_model.dat` file would be used in `myworkflow.yaml` via the reference `data/default_model.dat:ref`.\n\n## Standalone Project\n\n<InlineNotification>\n\nThis type of project:\n\n* Does not require a manifest or any modification of the virtual experiment configuration.\n\n* Allows only one virtual experiment per project.\n\n* Stores resources/artifacts in the project itself.\n\n</InlineNotification>\n\n<InlineNotification kind=\"success\">\n\nYou can test experiment packages using the tool `etest.py` available with the `st4sd-runtime-core`.\n\n</InlineNotification>\n\nWith this method the project is dedicated to a single virtual experiment, containing a single root directory with all the associated files inside of it.\nThe manifest file is also created automatically from all the directories in the root of the project, and the developer does not need to create one.\n\nThis project structure ensures that:\n- All the artifacts related to a virtual experiment are kept together in a single version control history.\n- The history of the repository coincides with the history of a single virtual experiment, with no contamination from changes to other virtual experiments.\n\nAs such, this method is best suited for complex virtual experiments or ones that require tighter version controls.\n\n### Example Layout\n\nHere is an example of how  the [use case](#use-case) could be structured using the standalone method:\n\n```bash\nmyworkflow/\n   conf/\n      - flowir_package.yaml\n   data/\n      - configuration_template.txt\n      - default_model.dat\n   hooks/\n      - __init__.py\n      - component_one_restart.py\n      - component_two_restart.py\n```\n\nWhen such a virtual experiment is executed the `hooks` will be automatically run and the data files will be available in `data/`.\nFor example the following reference is valid `data/default_model.dat:ref`\n\nSee [sum-numbers](https://github.com/st4sd/sum-numbers/) for a simple example of a virtual experiment defined in this way that you can also run.\n\n## Testing Projects\n\nVirtual experiments defined in any of the ways described above can be tested using the tool `etest.py` available in `st4sd-runtime-core`.\nSee [here](/installation#set-up-local-client) for instructions on how to install it locally (the command will be available system-wide).\n\n<InlineNotification>\n\nIf you are in JupyterLab `etest.py` will be available if you open a terminal session. This allows you to clone the repository containing your workflow package into JupyterLab and test there.\n\n</InlineNotification>\n\n### Standalone projects\n\nIn the case of standalone projects simply `cd` to the experiment folder and execute:\n\n```bash\netest.py --notestExecutables\n```\n\n### Standard projects\n\nSince standard projects can contain multiple virtual experiments testing may require some information on what to test as such:\n\n```bash\netest.py --manifest=$PATH_TO_MANIFEST $PATH_TO_CONFIGURATION_FILE\n```\n\n## Projects and Cloud Execution\n\n<InlineNotification>\n\nIn ST4SD 2.0 we will add a method to quickly test virtual experiments without the need to store them in git or object-store or manually create a parameterised package definition \n\n</InlineNotification>\n\nTo execute virtual experiments on OpenShift/Kubernetes (independently from their project type) they need to be placed in an accessible location.\n\nThere are two options:\n\n1. A remote git repository (e.g., GitHub).\n2. A Cloud Object Store (COS) bucket.\n\n<InlineNotification>\n\nThe storage location is normally decided at the start of development, with updates being pushed regularly as changes are made.\n\n</InlineNotification>\n\n### Storing in Git\n\n**It is strongly advised** to use a git repository, at least for source code management. To create a local repository, in the top level of your project type:\n\n```bash\ngit init\ngit add .\ngit commit *\n```\n\nTo then push the project to a remote git repository use:\n\n```bash\ngit remote add origin $REMOTE_GIT_REPO\ngit push -u origin main\n```\n\n### Storing in COS\n\nCreate a COS bucket as described in [using Cloud Object Store](/UsingCloudObjectStore) and upload/copy your project directory to the created bucket.\n\n### Running the Virtual Experiments in the Project\n\nOnce a project has been stored remotely there are two steps to run the experiments it defines:\n\n1. [Add the virtual experiment to the registry of the ST4SD instance you want to run on](/creating-a-parameterised-package).\n\n2. Run it using the [ST4SD Python API](/running-workflows-on-openshift) or [command line tools](/running-ve-via-terminal).\n\n## Providing external data to experiments\n\n<InlineNotification kind=\"warning\">\n\nIf dependencies, like configuration files, cannot be placed in the virtual experiment project, they can be supplied at runtime.\nThis, however, requires users to be aware of the requirements.\n\n</InlineNotification>\n\n\nThe first two options have been already explained. To use the third option you add the following fields when submitting your workflow to run:\n\n```python\nexperimentConfiguration = {\n    #Experiment input options\n    \"volumes\": [\n    {\n      \"type\": {\"dataset\": \"$DATA_SET_NAME\"},\n      \"applicationDependency\": \"$APPLICATION_DEPENDENCY_NAME\",\n      \"subPath\": \"$PATH_TO_APPLICATION_DEPENDENCY_SOURCE_RELATIVE_TO_TOP_LEVEL_OF_BUCKET\"\n    }\n    ]\n}\nrestUID = api.api_experiment_start(experiment_id=\"myworkflow\", payload=experimentConfiguration)\n```\n\n<InlineNotification kind=\"warning\">\n\nThe [Datashim](https://github.com/datashim-io/datashim) framework needs to be installed to supply application dependencies at runtime.\nThis itself requires OpenShift v4.X.\n\n</InlineNotification>\n\n### Example Layout\n\nTo use this method create one or more COS buckets contaning the workflow's dependency sources.\nThe [example use-case](#use-case) could be packaged using the following layout in a singe bucket\n\n```\nmybucket/\n   data/\n      - configuration_template.txt\n      - default_model.dat\n   hooks/\n      - __init__.py\n      - component_one_restart.py\n      - component_two_restart.py\n```\n\nNext create a `Dataset` for the bucket - we'll call it `my-workflow-deps`.\nFor this step follow instructions [here](/UsingCloudObjectStore#datashim-method).\nThis is a one time action.\n\nNow when launching the workflow use:\n\n```python\n\texperimentConfiguration = {\n    #Experiment input options\n    \"volumes\": [\n    {\n      \"type\": {\"dataset\":\"my-workflow-deps\"},\n      \"applicationDependency\": \"hooks\",\n      \"subPath\": hooks/\n    },\n     {\n      \"type\": {\"dataset\":\"my-workflow-deps\"},\n      \"applicationDependency\": \"data\",\n      \"subPath\": data/\n    },\n    ]\n}\nrestUID = api.api_experiment_start(experiment_id=\"myworkflow\", payload=experimentConfiguration)\n```\n\n","type":"Mdx","contentDigest":"c8b8455e5aa77abd0d5f9ee52b4ad31f","owner":"gatsby-plugin-mdx","counter":183},"frontmatter":{"title":"Project Types"},"exports":{},"rawBody":"---\ntitle: Project Types\n---\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nThis page describes  how to structure, test, and run your ST4SD virtual experiment projects\n\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Quick guide to selecting a project type</AnchorLink>\n  <AnchorLink>Before beginning</AnchorLink>\n  <AnchorLink>Standard project</AnchorLink>\n  <AnchorLink>Standalone project</AnchorLink>\n  <AnchorLink>Testing projects</AnchorLink>\n  <AnchorLink>Projects and cloud execution</AnchorLink>\n  <AnchorLink>Providing external data to experiments</AnchorLink>\n</AnchorLinks>\n\nST4SD virtual experiments often consist of a variety of files -- such as configuration files, scripts, and [restart hooks](/restart).\n\nST4SD supports two ways of structuring projects in order to collect these files together so your project can be tested and also so those fields will be present when you run the virtual experiment.\n\n**Standard projects** are flexible, allowing for multiple virtual experiment definitions to be bundled together and share files, like scripts and restart hooks.\n\n**Standalone projects**  only support a single virtual experiment and are best suited for workflows with many artifacts or resources that are actively changing (i.e., they have multiple commits).\n\n\n## Quick Guide to Selecting a Project Type\n\nTo identify the best project type for storing your virtual experiment find the statement that is the closest match to your situation:\n\n* *I have assets that need to be present when the virtual experiment runs. These assets are shared between multiple experiments and I can choose where to put them*.\n  * Use a [standard project](#standard-project).\n  * **Recommendation**: If you have an internet accessible location for hosting git repositories e.g. GitHub,  store the workflows there.\n* *I have assets that need to be present when the virtual -experiment runs. However these assets cannot be placed in a git repo due to size restrictions OR they live in a defined COS bucket they can't be moved from*.\n  * Use a [standard project](#standard-project) but specify the assets location as a runtime application-dependency source - see [application dependencies](#providing-external-data-to-experiments).\n  * **Recommendation**: If you have an internet accessible location for hosting git repositories e.g. GitHub,  store the experiments there.\n* *I have a production virtual experiment with multiple restart hooks and/or many required configuration files. I  need to have strong version control and also automated regression testing*.\n  * Use a [standalone project](#standalone-project).\n\n## Before beginning\n\nBefore diving into the below sections there  are a couple of things to be aware of.\n\n### Virtual Experiment Dependencies\n\nThe dependencies of a virtual experiment are a set of directories it requires to be present in the top-level of its instance directory when it runs.\nThese directories are in addition to `input`, `stages`, and `output` which are always created.\n\nThey are specified in the virtual experiment configuration YAML using the key `application-dependencies`:\n\n```yaml path=myworkflow.yaml\napplication-dependencies:\n  default: # platform name\n  \t - $DIRECTORY_NAME_ONE\n  \t - $DIRECTORY_NAME_TWO\n  \t - ...\n```\n\nIn the configuration file these names can be used in references e.g. `$DIRECTORY_NAME_ONE/myconftemplate.dat:ref`.\n\nWhen [testing the configuration](#testing-projects) the parser checks that all direct references to directories that aren't called `input` are listed under `application-dependencies`; i.e., that the directories you are using in the workflow configuration are specified and will be present.\n\nTo populate these directories at run time with the correct files we need to specify the **dependency sources** using one of the following options:\n\n1. Specifying them in a `manifest`, if using [a standard project](#standard-project).\n\n2. Explicitly creating them, if using [a standalone project ](#standalone-project).\n\n3. Specifying them when submitting an experiment via the `st4sd-runtime-service`.\n\nEach of these options is explain in the section below\n\n### Use case\n\nIn the following sections we will illustrate the two project types with a workflow called `myworkflow.yaml` that has:\n- Two required configuration files:\n  - `configuration_template.txt`\n  - `default_model.dat`\n- Two restart hooks:\n  - `component_one_restart.py`\n  - `component_two_restart.py`.\n\n## Standard Project\n\n<InlineNotification>\n\nThis type of project:\n\n* Requires a manifest.\n\n* Allows storing multiple virtual experiments in the same project.\n\n* Required files for execution are stored in the project itself.\n\n</InlineNotification>\n\n<InlineNotification kind=\"success\">\n\nYou can test standard projects using the tool `etest.py` available with `st4sd-runtime-core`\nSee [testing projects](#testing-projects) for more details.\n\n</InlineNotification>\n\nVirtual experiments belonging to a standard project live under a single root directory (which can have any name e.g., \"my-experiments\") and contain at least one **configuration file** and optionally a related **manifest file**.\n\nThe **configuration** is a YAML file containing the FlowIR definition of the virtual experiment (more on FlowIR [here](/tutorial#introduction-to-flowir)), while the **manifest** is a YAML file defining which directories in the project the particular virtual experiment needs and where they will be accessible from when the workflow is running.\n\n<InlineNotification kind=\"warning\">\n\nThe directories specified in the manifest must be under project root directory\n\n</InlineNotification>\n\nThe manifest and configuration files for an experiment can have any name and be stored in separate directories, although a common pattern is for them to be stored together in one directory beneath the root direcory and be called `manifest.yaml` and with the same name of the workflow (e.g. `myworkflow.yaml`), respectively.\n\n<InlineNotification kind=\"warning\">\n\nFor running via the `st4sd-runtime-service` the root directory must be stored on a remotely accessible git repository or a COS bucket.\nSee [projects and cloud execution](#projects-and-cloud-execution) for more details.\n\n</InlineNotification>\n\n<InlineNotification>\n\nStandard projects allow having multiple (manifest+configuration file) pairs in the same project.\n\n</InlineNotification>\n\n### Writing a manifest \n\n\nThe content of the manifest file is a YAML dictionary whose keys/values are:\n\n```yaml\n$APPLICATION_DEPENDENCY_NAME: $RELATIVE_PATH_TO_SOURCE_DIRECTORY[:$METHOD]\n```\n\nWhere:\n\n- `APPLICATION_DEPENDENCY_NAME` is the name you use to refer to the directory containing the files in the virtual experiment configuration. At runtime a directory will be created in the top-level of the workflow instance with this name and populated with contents from the source directory based on `METHOD` (see below).\n- `RELATIVE_PATH_TO_SOURCE_DIRECTORY` is the path to the directory under the root directory of the standard project that you want to access when the virtual experiment runs.\n- `METHOD` defines how you want the directory to be made available. It can be `copy` or `link`. If no method is specified `copy` is used, as it ensures the `data` will be present in the instance when it finishes.\n\n<InlineNotification kind=\"warning\">\n\n**Remember**: the application dependencies in your manifest file must also be listed in your virtual experiment configuration under the top-level key `application-dependencies` (see [here](#providing-external-data-to-experiments)).\nThis is required for testing as it allows checking that the manifest associates source-folders to the application dependencies the workflow expects.\n\n</InlineNotification>\n\n<InlineNotification kind=\"warning\">\n\nIf you host your standard project on GitHub and your manifest file contains application dependency sources that point to other folders in your workflow package, you should use the `copy` method. If you use `link`, the files under the application dependency sources will only be visible to components that use the `local` backend.\n\n</InlineNotification>\n\n\n#### Example Layout\n\nHere is an example of how the [use case](#use-case) could be structured using the standard method:\n\n```bash\nmyworkflow/\n myworkflows/\n   workflowOne/\n      - myworkflow.yaml\n      - manifest.yaml\n   shared_data/\n      - configuration_template.txt\n      - default_model.dat\n   hooks/\n      - __init__.py\n      - component_one_restart.py\n      - component_two_restart.py\n```\n\nThe manifest file would be:\n\n```yaml path=manifest.yaml\ndata: ../shared_data\nhooks: ../hooks\n```\n\nThe configuration file would be:\n\n```yaml path=myworfklow.yaml\napplication-dependencies:\n  default:\n  \t - data\n  \t - hooks\n```\n\nWhen such a virtual experiment is executed the `hooks` will be automatically run and the data files will be available in `data/`.\nFor example, the path to `default_model.dat` file would be used in `myworkflow.yaml` via the reference `data/default_model.dat:ref`.\n\n## Standalone Project\n\n<InlineNotification>\n\nThis type of project:\n\n* Does not require a manifest or any modification of the virtual experiment configuration.\n\n* Allows only one virtual experiment per project.\n\n* Stores resources/artifacts in the project itself.\n\n</InlineNotification>\n\n<InlineNotification kind=\"success\">\n\nYou can test experiment packages using the tool `etest.py` available with the `st4sd-runtime-core`.\n\n</InlineNotification>\n\nWith this method the project is dedicated to a single virtual experiment, containing a single root directory with all the associated files inside of it.\nThe manifest file is also created automatically from all the directories in the root of the project, and the developer does not need to create one.\n\nThis project structure ensures that:\n- All the artifacts related to a virtual experiment are kept together in a single version control history.\n- The history of the repository coincides with the history of a single virtual experiment, with no contamination from changes to other virtual experiments.\n\nAs such, this method is best suited for complex virtual experiments or ones that require tighter version controls.\n\n### Example Layout\n\nHere is an example of how  the [use case](#use-case) could be structured using the standalone method:\n\n```bash\nmyworkflow/\n   conf/\n      - flowir_package.yaml\n   data/\n      - configuration_template.txt\n      - default_model.dat\n   hooks/\n      - __init__.py\n      - component_one_restart.py\n      - component_two_restart.py\n```\n\nWhen such a virtual experiment is executed the `hooks` will be automatically run and the data files will be available in `data/`.\nFor example the following reference is valid `data/default_model.dat:ref`\n\nSee [sum-numbers](https://github.com/st4sd/sum-numbers/) for a simple example of a virtual experiment defined in this way that you can also run.\n\n## Testing Projects\n\nVirtual experiments defined in any of the ways described above can be tested using the tool `etest.py` available in `st4sd-runtime-core`.\nSee [here](/installation#set-up-local-client) for instructions on how to install it locally (the command will be available system-wide).\n\n<InlineNotification>\n\nIf you are in JupyterLab `etest.py` will be available if you open a terminal session. This allows you to clone the repository containing your workflow package into JupyterLab and test there.\n\n</InlineNotification>\n\n### Standalone projects\n\nIn the case of standalone projects simply `cd` to the experiment folder and execute:\n\n```bash\netest.py --notestExecutables\n```\n\n### Standard projects\n\nSince standard projects can contain multiple virtual experiments testing may require some information on what to test as such:\n\n```bash\netest.py --manifest=$PATH_TO_MANIFEST $PATH_TO_CONFIGURATION_FILE\n```\n\n## Projects and Cloud Execution\n\n<InlineNotification>\n\nIn ST4SD 2.0 we will add a method to quickly test virtual experiments without the need to store them in git or object-store or manually create a parameterised package definition \n\n</InlineNotification>\n\nTo execute virtual experiments on OpenShift/Kubernetes (independently from their project type) they need to be placed in an accessible location.\n\nThere are two options:\n\n1. A remote git repository (e.g., GitHub).\n2. A Cloud Object Store (COS) bucket.\n\n<InlineNotification>\n\nThe storage location is normally decided at the start of development, with updates being pushed regularly as changes are made.\n\n</InlineNotification>\n\n### Storing in Git\n\n**It is strongly advised** to use a git repository, at least for source code management. To create a local repository, in the top level of your project type:\n\n```bash\ngit init\ngit add .\ngit commit *\n```\n\nTo then push the project to a remote git repository use:\n\n```bash\ngit remote add origin $REMOTE_GIT_REPO\ngit push -u origin main\n```\n\n### Storing in COS\n\nCreate a COS bucket as described in [using Cloud Object Store](/UsingCloudObjectStore) and upload/copy your project directory to the created bucket.\n\n### Running the Virtual Experiments in the Project\n\nOnce a project has been stored remotely there are two steps to run the experiments it defines:\n\n1. [Add the virtual experiment to the registry of the ST4SD instance you want to run on](/creating-a-parameterised-package).\n\n2. Run it using the [ST4SD Python API](/running-workflows-on-openshift) or [command line tools](/running-ve-via-terminal).\n\n## Providing external data to experiments\n\n<InlineNotification kind=\"warning\">\n\nIf dependencies, like configuration files, cannot be placed in the virtual experiment project, they can be supplied at runtime.\nThis, however, requires users to be aware of the requirements.\n\n</InlineNotification>\n\n\nThe first two options have been already explained. To use the third option you add the following fields when submitting your workflow to run:\n\n```python\nexperimentConfiguration = {\n    #Experiment input options\n    \"volumes\": [\n    {\n      \"type\": {\"dataset\": \"$DATA_SET_NAME\"},\n      \"applicationDependency\": \"$APPLICATION_DEPENDENCY_NAME\",\n      \"subPath\": \"$PATH_TO_APPLICATION_DEPENDENCY_SOURCE_RELATIVE_TO_TOP_LEVEL_OF_BUCKET\"\n    }\n    ]\n}\nrestUID = api.api_experiment_start(experiment_id=\"myworkflow\", payload=experimentConfiguration)\n```\n\n<InlineNotification kind=\"warning\">\n\nThe [Datashim](https://github.com/datashim-io/datashim) framework needs to be installed to supply application dependencies at runtime.\nThis itself requires OpenShift v4.X.\n\n</InlineNotification>\n\n### Example Layout\n\nTo use this method create one or more COS buckets contaning the workflow's dependency sources.\nThe [example use-case](#use-case) could be packaged using the following layout in a singe bucket\n\n```\nmybucket/\n   data/\n      - configuration_template.txt\n      - default_model.dat\n   hooks/\n      - __init__.py\n      - component_one_restart.py\n      - component_two_restart.py\n```\n\nNext create a `Dataset` for the bucket - we'll call it `my-workflow-deps`.\nFor this step follow instructions [here](/UsingCloudObjectStore#datashim-method).\nThis is a one time action.\n\nNow when launching the workflow use:\n\n```python\n\texperimentConfiguration = {\n    #Experiment input options\n    \"volumes\": [\n    {\n      \"type\": {\"dataset\":\"my-workflow-deps\"},\n      \"applicationDependency\": \"hooks\",\n      \"subPath\": hooks/\n    },\n     {\n      \"type\": {\"dataset\":\"my-workflow-deps\"},\n      \"applicationDependency\": \"data\",\n      \"subPath\": data/\n    },\n    ]\n}\nrestUID = api.api_experiment_start(experiment_id=\"myworkflow\", payload=experimentConfiguration)\n```\n\n","fileAbsolutePath":"/home/travis/build/st4sd/overview/src/pages/packaging-workflows.mdx"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}