{"componentChunkName":"component---src-pages-write-experiments-mdx","path":"/write-experiments/","result":{"pageContext":{"frontmatter":{"title":"Write experiments"},"relativePagePath":"/write-experiments.mdx","titleType":"page","MdxNode":{"id":"a4909071-b92d-5535-976a-635698395e4a","children":[],"parent":"7378461b-e1ce-54b8-a52a-ccea1cf489d4","internal":{"content":"---\ntitle: Write experiments\n---\n\nimport { CarbonForIbmDotcom } from \"@carbon/pictograms-react\";\nimport { ArtTools_01 } from \"@carbon/pictograms-react\";\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nThis page assumes you are familiar with running experiments locally using the elaunch.py command line tool. If you need a refresher take a moment to read our [docs](/direct-run) before continuing any further.\n\n</PageDescription>\n\n\n<InlineNotification kind=\"info\">\n\nHere, we are using DSL 2.0, if you need to understand the previous syntax check out the [FlowIR docs](/workflow-specification) and [FlowIR tutorial](/tutorial).\n\n</InlineNotification>\n\n<AnchorLinks>\n\n  <AnchorLink>Wrapping a python script for native execution</AnchorLink>\n  <AnchorLink>Packaging your virtual experiment</AnchorLink>\n  <AnchorLink>Using containers for shareable virtual experiments</AnchorLink>\n  <AnchorLink>Your first Simulation experiment with GAMESS US</AnchorLink>\n\n</AnchorLinks>\n\n\n\n## Requirements\n\n- An understanding of [how to run a virtual experiment locally](/direct-run).\n- A python 3.9+ interpreter, [git](https://git-scm.com/downloads) to clone code from Git servers, and an understanding of the syntax & structure of [YAML](https://www.redhat.com/en/topics/automation/what-is-yaml)\n- A virtual environment with the `st4sd-runtime-core` python module\n\n    ```bash\n    python -m venv venv\n    . ./venv/bin/activate\n    pip pip install \"st4sd-runtime-core[develop]>=2.5.0\"\n    ```\n- A Container Runtime system: install one of [docker](https://docs.docker.com/engine/install/), [podman](https://podman.io/docs/installation), or [Rancher Desktop](https://docs.rancherdesktop.io/getting-started/installation/)\n\n<InlineNotification kind=\"warning\">\n\nBefore you continue any further, please make sure you are comfortable with [running virtual experiments locally](/direct-run).\n\n</InlineNotification>\n\n## Wrapping a python script for native execution\n\nFor your first virtual experiment, we will start with a Python script and use a virtual environment where **st4sd-runtime-core** is installed. This is a great way to quickly prototype virtual experiments without worrying about making them shareable with others. Check out [Using containers for shareable virtual experiments](#using-containers-for-shareable-virtual-experiments) for an example.\n\nBegin by creating the directory `/tmp/hello-world` and navigating into it. We are going to store all files relevant to the virtual experiment of this example in this directory.\n\n<InlineNotification kind=\"info\">\n\nDouble check you have created a directory with the path `/tmp/hello-world` - this examples assumes you are using this exact path.\n\n</InlineNotification>\n\n\nA good way to become familiar with ST4SD is to wrap a simple python script in a virtual experiment and execute it. So, let's build a **hello world** experiment using python. Create the file **printer.py** with the following contents:\n\n```python\nimport sys\nprint(\" \".join(sys.argv[1:]))\n```\n\nThis Python script is straightforward and does not rely on any external Python packages. If it did, you would need to install the required dependencies using `pip install` within the virtual environment where **st4sd-runtime-core** is installed. Since this script has no external dependencies, no additional Python modules need to be installed.\n\n\nTo create a ST4SD virtual experiment based on this script, we will define it using a YAML file. The structure of a ST4SD virtual experiment definition is as follows:\n\n\n```yaml\nentrypoint:\n    # Instructions of the entry point to your experiment\ncomponents:\n    # Templates each of which execute a single task\nworkflows:\n    # Templates each of which pipelines of tasks which themselves\n    # are either instances of Workflows or Components templates\n```\n\n\nDevelopers build experiments by connecting together **Components** and **Workflows** and identifying the entry point of the virtual experiment.\n\nComponents represent individual tasks, while Workflows represent pipelines (i.e. graphs) of Workflows and Components. The example provided demonstrates the execution of a single task. A helpful way to understand virtual experiments is to think of them as **programs** written in a programming language. In this analogy, Workflows and Components serve as functions, and the **entrypoint** is similar to declaring a **main()** function, specifying which function to execute and what arguments to pass to it.\n\nLet's put together a simple experiment consisting of a single step that prints a message to its standard output.\n\nPlace the following in the file `hello-world.yaml`:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: python\n    arguments: /tmp/hello-world/printer.py \"%(message)s\"\n```\n\nIn this example, the **entrypoint** to the experiment is an instance of the **printer** component which sets its message parameter to the value **\"Hello world\"**.\n\nMoving on to the **Components** template section we observe that there is a single template called **printer**. The **printer** component template has a single parameter called **message**, which does not have a default value. Instances of this template, run the executable **python**, passing the absolute path to the **printer.py** script and the **message** value as arguments. In the next example we will show you a better way to package experiments alleviating the need to use absolute paths for your scripts.\n\n\n<InlineNotification kind=\"warning\">\n\nAt this point, double check that you have used the exact names as above.\n\nThe expected file structure in **/tmp/hello-world** is as follows:\n\n```\n/tmp/hello-world\n├── hello-world.yaml\n└── printer.py\n```\n\n</InlineNotification>\n\n\nLet's run the experiment using `elaunch.py`. Run the following command from inside the **/tmp/hello-world** directory\n\n```\nelaunch.py --nostamp hello-world.yaml\n```\n\nAfter a few seconds you should see:\n\n```\ncompleted-on=2025-03-22 12:39:13.806401\ncost=0\ncreated-on=2025-03-22 12:39:07.382235\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-22 12:39:17.417956\nupdated-on=2025-03-22 12:39:17.417956\n```\n\nThe experiment will create the directory **hello-world.instance** and store all files it generated in it.\n\n```\nhello-world.instance\n├── conf\n│   ├── dsl.yaml               # your virtual experiment definition\n│   ├── flowir_instance.yaml   # ignore this file\n│   ├── flowir_package.yaml    # ignore this file\n│   └── manifest.yaml          # ignore this file\n├── elaunch.yaml\n├── input\n├── output\n│   ├── experiment.log\n│   ├── output.json\n│   ├── output.txt\n│   ├── status.txt\n│   └── status_details.json\n├── python\n├── stages\n│   └── stage0\n│       └── entry-instance\n│           ├── component_performance.csv\n│           ├── out.stderr\n│           └── out.stdout\n└── status.db\n\n```\n\nIf you encountered any issues during the process, please refer to the [troubleshooting](/direct-run#troubleshooting) section of the documentation for guidance on launching experiments locally.\n\nNow that you have ran the experiment, take a moment to **explore its outputs**. You can find the output files following directory:\n`hello-world.instance/stages/stage0/entry-instance`.\n\n\n### Exercise\n\n\nIn ST4SD you can override the parameters of `entry-instance` that the `entrypoint` sets via the dictionary `entrypoint.execute[0].args`.\n\nFor example, place the following into a new file `my-variables.yaml`:\n\n```yaml\nglobal:\n  message: my custom message\n```\n\nThen remove the `hello-world.instance` directory and run the experiment again but this time use load the `my-variables.yaml` file:\n\n```bash\nrm -rf hello-world.instance\nelaunch.py --nostamp -a my-variables.yaml hello-world.yaml\n```\n\nThe **stdout** of the `hello` component can be found in the following file:\n`hello-world.instance/stages/stage0/entry-instance/out.stdout`.\n\n\n## Packaging your virtual experiment\n\nWhen automating simulation codes with custom bash scripts, you may have experienced difficulties with absolute paths when relocating your codes to different directories or execution environments. ST4SD provides a solution to this issue. It offers two methods for [packaging multiple files](#packaging-workflows), with the most convenient approach being the use of the [Standard](/packaging-workflows#standard-project) project structure. This structure consists of a virtual experiment definition, defined in a YAML file, and an optional **manifest** file, which specifies additional directories to be included with the virtual experiment. The **manifest** file has the following format:\n\n\n\nThe **manifest** file has the following format:\n\n```yaml\ndestinationDirectoryName: sourceDirectory\n```\n\nThis instructs the runtime system to create a directory called **destinationDirectoryName** using the files from the path **sourceDirectory**. If the **sourceDirectory** is not an absolute path then it is considered relative to the location of the experiment definition YAML file.\n\n\nTo convert the above example to use the **Standard** project structure, first create the directory `/tmp/hello-world/bin` and move the **printer.py** script into it. Next, create the file **manifest.yaml** under the directory `/tmp/hello-world/` with the following content:\n\n```yaml\nbin: bin\n```\n\nNow, let's update the virtual definition to use the **bin/printer.py** file. You just need to change the last line in the **components** section of your **hello-world.yaml** file:\n```yaml\n...\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: python\n    arguments: /tmp/hello-world/printer.py \"%(message)s\" # HERE\n```\n\nReplace the absolute path **/tmp/hello-world/printer.py** with **bin/printer.py:ref**. The **:ref** suffix indicates that this is a reference to a file, rather than a direct path. At runtime, the system will use the **manifest.yaml** file to resolve this reference, enabling you to include additional files with your virtual experiment definition in a flexible and portable way.\n\nYour updated **hello-world.yaml** file should now look like this:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: python\n    arguments: bin/printer.py:ref \"%(message)s\"\n```\n\n\nYou should end up with the following files:\n\n```\n/tmp/hello-world\n├── bin\n│   └── printer.py\n├── hello-world.yaml\n└── manifest.yaml\n```\n\nFinally, let's run this experiment:\n\n```\nelaunch.py --nostamp --manifest manifest.yaml hello-world.yaml\n```\n\n<InlineNotification kind=\"info\">\n\nThe **--manifest manifest.yaml** argument is used to specify the **manifest.yaml** file as the source of manifest information for your virtual experiment, allowing the runtime to access the necessary configuration details.\n\n\n</InlineNotification>\n\n\nAfter a few seconds you should see this output on your terminal:\n\n```\ncompleted-on=2025-03-31 10:19:45.271792\ncost=0\ncreated-on=2025-03-31 10:19:39.121168\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-31 10:19:49.192388\nupdated-on=2025-03-31 10:19:49.192388\n```\n\nCongratulations! You have successfully packaged your virtual experiment!\n\n### Exercise\n\nModify your **printer.py** script to import a Python package, such as **transformers**. To ensure successful execution, make sure to install **transformers** within the same virtual environment where **st4sd-runtime-core** is installed.\n\nNext, run it elaunch.py:\n\n```\nrm -rf hello-world.instance\nelaunch.py --nostamp --manifest manifest.yaml hello-world.yaml\n```\n\nDouble check that it runs to completion.\n\n## Using containers for shareable virtual experiments\n\nTo make experiments truly shareable, they must include the following key information:\n\n1. All executables that they run, along with their software dependencies\n2. How to map the executables to specific steps\n3. How to connect inputs to these steps\n\nIn the [above example](#packaging-your-virtual-experiment) we wrapped a single-step executable into a virtual experiment, covering the second and third requirements for a single-step experiment. In this example, we will utilize a container to share the software dependencies of the **printer.py** python script, addressing the first requirement.\n\nCreate a new directory in `/tmp/docker-package` and cd into it, we will use it for the files of this virtual experiment.\n\n### Containerize your python application\n\nIn a **requirements.txt** file place the python dependencies of your script.\nThe **printer.py** python script that we use here does not have any python requirements but we'll just install **transformers** in the container we use to execute the script just to demonstrate the method:\n\nThe contents of the  `requirements.txt` file are:\n\n```\ntransformers==4.50.3\n```\n\nNext, create a file called `Dockerfile` with the following contexts:\n\n```docker\nFROM python:3.11-slim\n\nRUN    apt-get update \\\n    && apt-get upgrade -y \\\n    && apt-get clean -y \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Make sure that files under /app are part of $PATH\nENV PATH=/app:$PATH\nWORKDIR /app\n\nCOPY requirements.txt /app/requirements.txt\n\nRUN pip install -r requirements.txt\n\n# Place the printer.py file inside the container\nCOPY printer.py /app/printer.py\n```\n\nMake sure you have the following files in the directory you are currently in:\n\n```\n/tmp/docker-package\n├── Dockerfile\n├── printer.py\n└── requirements.txt\n```\n\nTo build your container, run **docker build**:\n\n\n```\ndocker build --platform linux/amd64 -f Dockerfile -t my-printer:latest .\n```\n\n<InlineNotification kind=\"info\">\n\nWe recommend building images for the x86-64 CPU architecture using the `--platform linux/amd64` flag to ease the transition into executing your virtual experiments on the cloud. You can specify the platform when building your image using the following command-line argument `--platform linux/amd64`.\n\n</InlineNotification>\n\n\n### Making your container available to others\n\nIf you plan to share your experiment with others, you will need to push your containers to a remote container registry, such as [Docker Hub](https://hub.docker.com/). This allows others to easily access and pull your container images, making it simpler to share and reproduce your experiment.\n\nTo push your container to a remote registry, you can use the following steps:\n\n1. **Tag your container image**: Use the `docker tag` command to assign a unique name to your image, including the registry URL and your username.\n2. **Login to the registry**: Use the `docker login` command to authenticate with the registry.\n3. **Push the image**: Use the `docker push` command to upload your image to the registry.\n\nFor example:\n\n```bash\n: # Tag the image\ndocker tag my-printer:latest <your-username>/my-printer:latest\n\n: # Login to Docker Hub\ndocker login\n\n: # Push the image\ndocker push <your-username>/my-printer:latest\n```\n\n<InlineNotification kind=\"info\">\n\nThe remainder of this example will assume that you do not have access to a container registry. In this case, you can still share your experiment with others by providing them with the necessary files and instructions to build the container image themselves. This can be done by sharing the **Dockerfile**, **printer.py**, and **requirements.txt** files. The recipient can then build the image using the `docker build --platform linux/amd64 -f Dockerfile -t my-printer:latest` command and run your virtual experiment locally.\n\n</InlineNotification>\n\n### Create a virtual experiment that uses the container\n\nCreate the file **docker-package.yaml** in the `/tmp/docker-package` directory with the following contents:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: python\n    arguments: /app/printer.py \"%(message)s\"\n    environment:\n        PATH: /usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app\n  resourceManager:\n    config:\n        backend: docker\n    docker:\n        image: my-printer:latest\n        imagePullPolicy: IfNotPresent\n```\n\n\nThe differences between this experiment and above **hello-world.yaml** experiment are all about the **printer** `component`:\n\n1. The **bin/printer.py:ref** Reference is replaced by the direct path `/app/printer.py`\n    - The file is now located inside the container so using a direct path is perfectly fine\n    - The runtime system will search for this executable in the `$PATH` environment variable of the component\n1. We set `command.environment.PATH` to include the path to the `printer.py` script\n    - By default, components receive the virtual environment of the runtime process which is not guaranteed to be compatible with the environment variables that enable the execution of commands inside the container\n1. Configure the docker backend for this component\n   - Set `resourceManager.config.backend` to `docker`\n   - Set `resourceManager.docker.image` to `my-printer:latest`\n   - Set `resourceManager.docker.imagePullPolicy` to `IfNotPresent`\n      - This setting instructs the runtime to only attempt to pull the image if it's not already present on the local machine\n\nThe resulting file tree in `/tmp/docker-package` should be:\n\n```\n/tmp/docker-package\n├── Dockerfile            # To build image\n├── requirements.txt      # To build image\n├── printer.py            # To build image\n└── docker-package.yaml   # To execute experiment\n```\n\n<InlineNotification kind=\"info\">\n\nST4SD supports multiple different backends for your components however these features are beyond the focus of this example. You can find more information in the [advanced experiments](/add-interface-to-experiments) as well as the [DSL documentation](/workflow-specification-dsl) page.\n\n</InlineNotification>\n\n### Exercise\n\nRun your virtual experiment using **elaunch.py**:\n\n```\nelaunch.py --nostamp docker-package.yaml\n```\n\nIf you encountered any issues during the process, please refer to the [troubleshooting](/direct-run#troubleshooting) section of the documentation for guidance on launching experiments locally.\n\nNow that you have ran the experiment, take a moment to **explore its outputs**. You can find the output files following directory:\n`docker-package.instance/stages/stage0/entry-instance`.\n\n\n## Your first Simulation experiment with GAMESS US\n\nIn this example, we will create a virtual experiment that performs the Parameterized Model 3 (PM3) method in GAMESS US. PM3 is a semi-empirical quantum chemistry method. Scientists use it to calculate the molecular properties and energies when computational efficiency is a priority as an alternative to high accuracy but slow to run high-level quantum methods like Hartree-Fock or Density Functional Theory (DFT).\n\nStart by creating a new directory in `/tmp/gamess-us-pm3` containing 2 directories: `bin` and `hooks` like so:\n\n```\n/tmp/gamess-us-pm3\n├── bin\n└── hooks\n```\n\nCreate the file `bin/run-gamess.sh` using the following:\n\n```\n#!/usr/bin/env sh\n\nmolecule=$1\ncpus=$2\n\n# The restart hook expects the filename to exist in the working directory\n# of GAMESS US\nmolecule_name=$(basename \"${molecule}\")\ncp ${molecule} ${molecule_name}\n\nPATH_RUNGMS_WRAPPER=${PATH_RUNGMS:-/usr/local/bin/rungms}\nPATH_GAMESS=${PATH_GAMESS:-/usr/local/bin/gamess}\n\nPATH_MY_GAMESS=${PATH_MY_GAMESS:-/tmp/gamess}\nGAMESS_SCRATCH_DIR=${GAMESS_SCRATCH_DIR:-${PATH_MY_GAMESS}/scratch}\n\nhere=`pwd`\nmkdir -p \"${PATH_MY_GAMESS}\"\nmkdir -p \"${GAMESS_SCRATCH_DIR}\"\n\nsed -e \"s#set USERSCR=/workspace/restart#set USERSCR=${here}#g\" \\\n    -e \"s#set currentdir=\\`pwd\\`#set currentdir=${PATH_GAMESS}#g\" \\\n    -e \"s#set SCR=\\`pwd\\`/scratch#set SCR=${GAMESS_SCRATCH_DIR}#g\" \\\n    -e \"s#TARGET=mpi#TARGET=ga#g\" \\\n    \"${PATH_GAMESS}/rungms\" >\"${PATH_MY_GAMESS}/run-gamess.sh\"\n\ncp /usr/local/bin/gamess/install.info \"${PATH_GAMESS}/install.info\"\n\n# The NVidia Image Features version 00 ONLY and target=GA ONLY\nversion=00\n\nchmod +x ${PATH_MY_GAMESS}/run-gamess.sh\n\n\"${PATH_MY_GAMESS}\"/run-gamess.sh \"${molecule_name}\" \"${version}\" \"${cpus}\"\n\n\n```\n\nThen download the [extract_gmsout.py script](https://github.com/st4sd/band-gap-gamess/blob/main/component-scripts/extract_gmsout.py) and store it in the `bin` directory.\n\nNext, make the **run-gamess.sh** script executable by running `chmod +x bin/run-gamess.sh` from inside the `/tmp/gamess-us-pm3` directory.\n\nDownload the [RestartHook example](https://github.com/st4sd/band-gap-gamess/blob/main/hooks/semi_empirical_restart.py) and save it under **hooks/semi_empirical_restart.py**. This script checks if the PM3 method in GAMESS US has converged. If not, it triggers a task restart. You can find more information on **RestartHooks** in our documentation about [restarting tasks](/restart).\n\nNext, prepare the definition of the experiment by pasting the following into the **gamess-us-pm3.yaml** file:\n\n```yaml\nentrypoint:\n  entry-instance: gamess-us-pm3\n  execute:\n  - target: <entry-instance>\n    args:\n      input.molecule.inp: input/molecule.inp\n      gamess-number-processors: 1\n      gamess-memory: \"4096Mi\"\n      # gamess-gpus is only relevant for execution on Kubernetes\n      gamess-gpus: 0\n      backend: docker\n\nworkflows:\n- signature:\n    name: gamess-us-pm3\n    parameters:\n    - name: input.molecule.inp\n    - name: gamess-number-processors\n    - name: gamess-memory\n    - name: gamess-gpus\n    - name: backend\n  steps:\n    optimise: geometry-optimisation\n    parse-gamess: extract-energies\n  execute:\n    - target: <optimise>\n      args:\n        molecule: \"%(input.molecule.inp)s:ref\"\n        gamess-number-processors: \"%(gamess-number-processors)s\"\n        gamess-memory: \"%(gamess-memory)s\"\n        gamess-gpus: \"%(gamess-gpus)s\"\n        backend: \"%(backend)s\"\n    - target: <parse-gamess>\n      args:\n        gamess-working-directory: \"<optimise>:ref\"\n        backend: \"%(backend)s\"\n\ncomponents:\n- signature:\n    name: geometry-optimisation\n    parameters:\n    - name: molecule\n    - name: gamess-number-processors\n      default: 1\n    - name: gamess-memory\n      default: \"4096Mi\"\n    - name: backend\n      default: docker\n    - name: gamess-image\n      default: nvcr.io/hpc/gamess:17.09-r2-libcchem\n    - name: docker-platform\n      default: \"linux/amd64\"\n    - name: gamess-gpus\n      default: 0\n  command:\n    arguments: \"%(molecule)s %(gamess-number-processors)s\"\n    environment:\n      PATH: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n    executable: bin/run-gamess.sh  # the runtime resolves relative paths in the executable field\n                                   # using the manifest file\n  workflowAttributes:\n    restartHookFile: semi_empirical_restart.py\n    restartHookOn:\n    - KnownIssue\n    - Success\n    - ResourceExhausted\n    shutdownOn:\n    - KnownIssue\n    - ResourceExhausted\n  resourceManager:\n    config:\n      backend: '%(backend)s'\n      # in minutes - only applies to Kubernetes runs\n      walltime: 600\n    docker:\n      image: \"%(gamess-image)s\"\n      platform: \"%(docker-platform)s\"\n    kubernetes:\n      image: \"%(gamess-image)s\"\n  resourceRequest:\n    memory: '%(gamess-memory)s'\n    numberThreads: '%(gamess-number-processors)s'\n    threadsPerCore: 1\n    gpus: '%(gamess-gpus)s'\n\n- signature:\n    name: extract-energies\n    parameters:\n    - name: gamess-working-directory\n    - name: backend\n    - name: docker-platform\n      default: \"linux/amd64\"\n  command:\n    executable: python\n    arguments: \"bin/extract_gmsout.py:ref %(gamess-working-directory)s\"\n  resourceManager:\n    config:\n      backend: '%(backend)s'\n    kubernetes:\n      image: quay.io/st4sd/community-applications/rdkit-st4sd:2019.09.1\n    docker:\n      image: quay.io/st4sd/community-applications/rdkit-st4sd:2019.09.1\n      platform: \"%(docker-platform)s\"\n```\n\nFinally create your **manifest.yaml** file:\n\n```yaml\nbin: bin\nhooks: hooks\n```\n\nYou should now have the following file structure:\n\n```\n/tmp/gamess-us-pm3\n├── bin\n│   ├── extract_gmsout.py\n│   └── run-gamess.sh\n├── hooks\n│   └── semi_empirical_restart.pyf\n├── manifest.yaml\n└── gamess-us-pm3.yaml\n```\n\n### Exercise\n\nTry starting your experiment now using a container runtime.\n\nCreate your GAMESS-US input **molecule.inp** file in the directory `/tmp/gamess-us-pm3`.  You can use this example input file:\n\n```\n $CONTRL COORD=UNIQUE SCFTYP=RHF RUNTYP=OPTIMIZE MULT=1\n ISPHER=1 ICHARG=0 MAXIT=100 $END\n $SYSTEM MWORDS=100 TIMLIM=600 $END\n $BASIS GBASIS=PM3 $END\n $GUESS GUESS=HUCKEL $END\n $SCF DIRSCF=.t. FDIFF=.f. DIIS=.t. $END\n $STATPT NSTEP=500 PROJCT=.f. IHREP=20 HSSEND=.t. $END\n $DATA\nCH4 C CH4\n C1\n C 6.0 0.0 0.0 0.0\n H 1.0 0.1895 0.9552 -0.4946\n H 1.0 0.9509 -0.4809 0.2396\n H 1.0 -0.5631 0.1717 0.92\n H 1.0 -0.5773 -0.6461 -0.665\n $END\n```\n\n<InlineNotification kind=\"info\">\n\nTo use your own GAMESS US input file, carefully review the configuration options preceding the `$DATA` section and include them in your file. Additionally, ensure that your input is saved in a file named **molecule.inp**.\n\n</InlineNotification>\n\n\nYou should now have this structure:\n\n```\n/tmp/gamess-us-pm3\n├── bin\n│   ├── extract_gmsout.py\n│   └── run-gamess.sh\n├── gamess-us-pm3.yaml\n├── hooks\n│   └── semi_empirical_restart.py\n├── manifest.yaml\n└── molecule.inp\n```\n\nLaunch your experiment providing the input file **molecule.inp** and the manifest file **manifest.yaml**.\n\n```\nelaunch.py --nostamp --manifest manifest.yaml -i molecule.inp gamess-us-pm3.yaml\n```\n\nAfter a couple of minutes you should see:\n\n```\ncompleted-on=2025-03-31 11:37:49.301663\ncost=0\ncreated-on=2025-03-31 11:35:46.527619\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-31 11:37:51.780640\nupdated-on=2025-03-31 11:37:51.780640\n```\n\nThe **gamess-us-pm3.instance** directory will have the following structure:\n\n```\ngamess-us-pm3.instance\n├── bin\n│     ├── extract_gmsout.py\n│     └── run-gamess.sh\n├── conf\n│     ├── dsl.yaml\n│     ├── flowir_instance.yaml\n│     ├── flowir_package.yaml\n│     └── manifest.yaml\n├── elaunch.yaml\n├── hooks\n│     ├── __pycache__\n│     │     └── semi_empirical_restart.cpython-310.pyc\n│     └── semi_empirical_restart.py\n├── input\n│     └── molecule.inp\n├── output\n│     ├── experiment.log\n│     ├── output.json\n│     ├── output.txt\n│     ├── status.txt\n│     └── status_details.json\n├── python\n├── stages\n│     └── stage0\n│         ├── optimise\n│         │     ├── Run1\n│         │     │     ├── component_performance.csv\n│         │     │     ├── molecule.dat\n│         │     │     ├── molecule.inp\n│         │     │     ├── molecule.rst\n│         │     │     ├── out.stderr\n│         │     │     └── out.stdout\n│         │     ├── component_performance.csv\n│         │     ├── molecule.dat\n│         │     ├── molecule.inp\n│         │     ├── molecule.rst\n│         │     ├── out.stderr\n│         │     └── out.stdout\n│         └── parse-gamess\n│             ├── component_performance.csv\n│             ├── csv2inp.log\n│             ├── energies.csv\n│             ├── out.stderr\n│             └── out.stdout\n└── status.db\n```\n\n\nExamine the files under **stages/stage0/optimise** and **stages/stage0/parse-gamess**.\n\nThese were the contents of **stages/stage0/parse-gamess/energies.csv** for the experiment we ran on our laptop:\n\n```\nlabel,completed,total-energy,homo,lumo,gap,electric-moments,total-time,total-time-per-core\nmolecule,OK,-180.53313527498008,-13.641,4.245,17.886,0.000050,0.1,0.10\n```\n\n## What's next?\n\n- Learn more about writing experiments, including more advanced features and best practice [here](/write-more-experiments)\n- Learn how to add [key-outputs and interfaces](/add-interface-to-experiments) to your experiments\n- More information on running experiments directly, i.e. via `elaunch.py` [here](/direct-run)\n- More information on the DSL of ST4SD i.e. how to write experiments [here](/workflow-specification-dsl)\n- More information on how to structure and test your experiments [here](/packaging-workflows/)\n\n","type":"Mdx","contentDigest":"21a69a06b8f79e5eed21fa176fe0b737","owner":"gatsby-plugin-mdx","counter":283},"frontmatter":{"title":"Write experiments"},"exports":{},"rawBody":"---\ntitle: Write experiments\n---\n\nimport { CarbonForIbmDotcom } from \"@carbon/pictograms-react\";\nimport { ArtTools_01 } from \"@carbon/pictograms-react\";\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nThis page assumes you are familiar with running experiments locally using the elaunch.py command line tool. If you need a refresher take a moment to read our [docs](/direct-run) before continuing any further.\n\n</PageDescription>\n\n\n<InlineNotification kind=\"info\">\n\nHere, we are using DSL 2.0, if you need to understand the previous syntax check out the [FlowIR docs](/workflow-specification) and [FlowIR tutorial](/tutorial).\n\n</InlineNotification>\n\n<AnchorLinks>\n\n  <AnchorLink>Wrapping a python script for native execution</AnchorLink>\n  <AnchorLink>Packaging your virtual experiment</AnchorLink>\n  <AnchorLink>Using containers for shareable virtual experiments</AnchorLink>\n  <AnchorLink>Your first Simulation experiment with GAMESS US</AnchorLink>\n\n</AnchorLinks>\n\n\n\n## Requirements\n\n- An understanding of [how to run a virtual experiment locally](/direct-run).\n- A python 3.9+ interpreter, [git](https://git-scm.com/downloads) to clone code from Git servers, and an understanding of the syntax & structure of [YAML](https://www.redhat.com/en/topics/automation/what-is-yaml)\n- A virtual environment with the `st4sd-runtime-core` python module\n\n    ```bash\n    python -m venv venv\n    . ./venv/bin/activate\n    pip pip install \"st4sd-runtime-core[develop]>=2.5.0\"\n    ```\n- A Container Runtime system: install one of [docker](https://docs.docker.com/engine/install/), [podman](https://podman.io/docs/installation), or [Rancher Desktop](https://docs.rancherdesktop.io/getting-started/installation/)\n\n<InlineNotification kind=\"warning\">\n\nBefore you continue any further, please make sure you are comfortable with [running virtual experiments locally](/direct-run).\n\n</InlineNotification>\n\n## Wrapping a python script for native execution\n\nFor your first virtual experiment, we will start with a Python script and use a virtual environment where **st4sd-runtime-core** is installed. This is a great way to quickly prototype virtual experiments without worrying about making them shareable with others. Check out [Using containers for shareable virtual experiments](#using-containers-for-shareable-virtual-experiments) for an example.\n\nBegin by creating the directory `/tmp/hello-world` and navigating into it. We are going to store all files relevant to the virtual experiment of this example in this directory.\n\n<InlineNotification kind=\"info\">\n\nDouble check you have created a directory with the path `/tmp/hello-world` - this examples assumes you are using this exact path.\n\n</InlineNotification>\n\n\nA good way to become familiar with ST4SD is to wrap a simple python script in a virtual experiment and execute it. So, let's build a **hello world** experiment using python. Create the file **printer.py** with the following contents:\n\n```python\nimport sys\nprint(\" \".join(sys.argv[1:]))\n```\n\nThis Python script is straightforward and does not rely on any external Python packages. If it did, you would need to install the required dependencies using `pip install` within the virtual environment where **st4sd-runtime-core** is installed. Since this script has no external dependencies, no additional Python modules need to be installed.\n\n\nTo create a ST4SD virtual experiment based on this script, we will define it using a YAML file. The structure of a ST4SD virtual experiment definition is as follows:\n\n\n```yaml\nentrypoint:\n    # Instructions of the entry point to your experiment\ncomponents:\n    # Templates each of which execute a single task\nworkflows:\n    # Templates each of which pipelines of tasks which themselves\n    # are either instances of Workflows or Components templates\n```\n\n\nDevelopers build experiments by connecting together **Components** and **Workflows** and identifying the entry point of the virtual experiment.\n\nComponents represent individual tasks, while Workflows represent pipelines (i.e. graphs) of Workflows and Components. The example provided demonstrates the execution of a single task. A helpful way to understand virtual experiments is to think of them as **programs** written in a programming language. In this analogy, Workflows and Components serve as functions, and the **entrypoint** is similar to declaring a **main()** function, specifying which function to execute and what arguments to pass to it.\n\nLet's put together a simple experiment consisting of a single step that prints a message to its standard output.\n\nPlace the following in the file `hello-world.yaml`:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: python\n    arguments: /tmp/hello-world/printer.py \"%(message)s\"\n```\n\nIn this example, the **entrypoint** to the experiment is an instance of the **printer** component which sets its message parameter to the value **\"Hello world\"**.\n\nMoving on to the **Components** template section we observe that there is a single template called **printer**. The **printer** component template has a single parameter called **message**, which does not have a default value. Instances of this template, run the executable **python**, passing the absolute path to the **printer.py** script and the **message** value as arguments. In the next example we will show you a better way to package experiments alleviating the need to use absolute paths for your scripts.\n\n\n<InlineNotification kind=\"warning\">\n\nAt this point, double check that you have used the exact names as above.\n\nThe expected file structure in **/tmp/hello-world** is as follows:\n\n```\n/tmp/hello-world\n├── hello-world.yaml\n└── printer.py\n```\n\n</InlineNotification>\n\n\nLet's run the experiment using `elaunch.py`. Run the following command from inside the **/tmp/hello-world** directory\n\n```\nelaunch.py --nostamp hello-world.yaml\n```\n\nAfter a few seconds you should see:\n\n```\ncompleted-on=2025-03-22 12:39:13.806401\ncost=0\ncreated-on=2025-03-22 12:39:07.382235\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-22 12:39:17.417956\nupdated-on=2025-03-22 12:39:17.417956\n```\n\nThe experiment will create the directory **hello-world.instance** and store all files it generated in it.\n\n```\nhello-world.instance\n├── conf\n│   ├── dsl.yaml               # your virtual experiment definition\n│   ├── flowir_instance.yaml   # ignore this file\n│   ├── flowir_package.yaml    # ignore this file\n│   └── manifest.yaml          # ignore this file\n├── elaunch.yaml\n├── input\n├── output\n│   ├── experiment.log\n│   ├── output.json\n│   ├── output.txt\n│   ├── status.txt\n│   └── status_details.json\n├── python\n├── stages\n│   └── stage0\n│       └── entry-instance\n│           ├── component_performance.csv\n│           ├── out.stderr\n│           └── out.stdout\n└── status.db\n\n```\n\nIf you encountered any issues during the process, please refer to the [troubleshooting](/direct-run#troubleshooting) section of the documentation for guidance on launching experiments locally.\n\nNow that you have ran the experiment, take a moment to **explore its outputs**. You can find the output files following directory:\n`hello-world.instance/stages/stage0/entry-instance`.\n\n\n### Exercise\n\n\nIn ST4SD you can override the parameters of `entry-instance` that the `entrypoint` sets via the dictionary `entrypoint.execute[0].args`.\n\nFor example, place the following into a new file `my-variables.yaml`:\n\n```yaml\nglobal:\n  message: my custom message\n```\n\nThen remove the `hello-world.instance` directory and run the experiment again but this time use load the `my-variables.yaml` file:\n\n```bash\nrm -rf hello-world.instance\nelaunch.py --nostamp -a my-variables.yaml hello-world.yaml\n```\n\nThe **stdout** of the `hello` component can be found in the following file:\n`hello-world.instance/stages/stage0/entry-instance/out.stdout`.\n\n\n## Packaging your virtual experiment\n\nWhen automating simulation codes with custom bash scripts, you may have experienced difficulties with absolute paths when relocating your codes to different directories or execution environments. ST4SD provides a solution to this issue. It offers two methods for [packaging multiple files](#packaging-workflows), with the most convenient approach being the use of the [Standard](/packaging-workflows#standard-project) project structure. This structure consists of a virtual experiment definition, defined in a YAML file, and an optional **manifest** file, which specifies additional directories to be included with the virtual experiment. The **manifest** file has the following format:\n\n\n\nThe **manifest** file has the following format:\n\n```yaml\ndestinationDirectoryName: sourceDirectory\n```\n\nThis instructs the runtime system to create a directory called **destinationDirectoryName** using the files from the path **sourceDirectory**. If the **sourceDirectory** is not an absolute path then it is considered relative to the location of the experiment definition YAML file.\n\n\nTo convert the above example to use the **Standard** project structure, first create the directory `/tmp/hello-world/bin` and move the **printer.py** script into it. Next, create the file **manifest.yaml** under the directory `/tmp/hello-world/` with the following content:\n\n```yaml\nbin: bin\n```\n\nNow, let's update the virtual definition to use the **bin/printer.py** file. You just need to change the last line in the **components** section of your **hello-world.yaml** file:\n```yaml\n...\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: python\n    arguments: /tmp/hello-world/printer.py \"%(message)s\" # HERE\n```\n\nReplace the absolute path **/tmp/hello-world/printer.py** with **bin/printer.py:ref**. The **:ref** suffix indicates that this is a reference to a file, rather than a direct path. At runtime, the system will use the **manifest.yaml** file to resolve this reference, enabling you to include additional files with your virtual experiment definition in a flexible and portable way.\n\nYour updated **hello-world.yaml** file should now look like this:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: python\n    arguments: bin/printer.py:ref \"%(message)s\"\n```\n\n\nYou should end up with the following files:\n\n```\n/tmp/hello-world\n├── bin\n│   └── printer.py\n├── hello-world.yaml\n└── manifest.yaml\n```\n\nFinally, let's run this experiment:\n\n```\nelaunch.py --nostamp --manifest manifest.yaml hello-world.yaml\n```\n\n<InlineNotification kind=\"info\">\n\nThe **--manifest manifest.yaml** argument is used to specify the **manifest.yaml** file as the source of manifest information for your virtual experiment, allowing the runtime to access the necessary configuration details.\n\n\n</InlineNotification>\n\n\nAfter a few seconds you should see this output on your terminal:\n\n```\ncompleted-on=2025-03-31 10:19:45.271792\ncost=0\ncreated-on=2025-03-31 10:19:39.121168\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-31 10:19:49.192388\nupdated-on=2025-03-31 10:19:49.192388\n```\n\nCongratulations! You have successfully packaged your virtual experiment!\n\n### Exercise\n\nModify your **printer.py** script to import a Python package, such as **transformers**. To ensure successful execution, make sure to install **transformers** within the same virtual environment where **st4sd-runtime-core** is installed.\n\nNext, run it elaunch.py:\n\n```\nrm -rf hello-world.instance\nelaunch.py --nostamp --manifest manifest.yaml hello-world.yaml\n```\n\nDouble check that it runs to completion.\n\n## Using containers for shareable virtual experiments\n\nTo make experiments truly shareable, they must include the following key information:\n\n1. All executables that they run, along with their software dependencies\n2. How to map the executables to specific steps\n3. How to connect inputs to these steps\n\nIn the [above example](#packaging-your-virtual-experiment) we wrapped a single-step executable into a virtual experiment, covering the second and third requirements for a single-step experiment. In this example, we will utilize a container to share the software dependencies of the **printer.py** python script, addressing the first requirement.\n\nCreate a new directory in `/tmp/docker-package` and cd into it, we will use it for the files of this virtual experiment.\n\n### Containerize your python application\n\nIn a **requirements.txt** file place the python dependencies of your script.\nThe **printer.py** python script that we use here does not have any python requirements but we'll just install **transformers** in the container we use to execute the script just to demonstrate the method:\n\nThe contents of the  `requirements.txt` file are:\n\n```\ntransformers==4.50.3\n```\n\nNext, create a file called `Dockerfile` with the following contexts:\n\n```docker\nFROM python:3.11-slim\n\nRUN    apt-get update \\\n    && apt-get upgrade -y \\\n    && apt-get clean -y \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Make sure that files under /app are part of $PATH\nENV PATH=/app:$PATH\nWORKDIR /app\n\nCOPY requirements.txt /app/requirements.txt\n\nRUN pip install -r requirements.txt\n\n# Place the printer.py file inside the container\nCOPY printer.py /app/printer.py\n```\n\nMake sure you have the following files in the directory you are currently in:\n\n```\n/tmp/docker-package\n├── Dockerfile\n├── printer.py\n└── requirements.txt\n```\n\nTo build your container, run **docker build**:\n\n\n```\ndocker build --platform linux/amd64 -f Dockerfile -t my-printer:latest .\n```\n\n<InlineNotification kind=\"info\">\n\nWe recommend building images for the x86-64 CPU architecture using the `--platform linux/amd64` flag to ease the transition into executing your virtual experiments on the cloud. You can specify the platform when building your image using the following command-line argument `--platform linux/amd64`.\n\n</InlineNotification>\n\n\n### Making your container available to others\n\nIf you plan to share your experiment with others, you will need to push your containers to a remote container registry, such as [Docker Hub](https://hub.docker.com/). This allows others to easily access and pull your container images, making it simpler to share and reproduce your experiment.\n\nTo push your container to a remote registry, you can use the following steps:\n\n1. **Tag your container image**: Use the `docker tag` command to assign a unique name to your image, including the registry URL and your username.\n2. **Login to the registry**: Use the `docker login` command to authenticate with the registry.\n3. **Push the image**: Use the `docker push` command to upload your image to the registry.\n\nFor example:\n\n```bash\n: # Tag the image\ndocker tag my-printer:latest <your-username>/my-printer:latest\n\n: # Login to Docker Hub\ndocker login\n\n: # Push the image\ndocker push <your-username>/my-printer:latest\n```\n\n<InlineNotification kind=\"info\">\n\nThe remainder of this example will assume that you do not have access to a container registry. In this case, you can still share your experiment with others by providing them with the necessary files and instructions to build the container image themselves. This can be done by sharing the **Dockerfile**, **printer.py**, and **requirements.txt** files. The recipient can then build the image using the `docker build --platform linux/amd64 -f Dockerfile -t my-printer:latest` command and run your virtual experiment locally.\n\n</InlineNotification>\n\n### Create a virtual experiment that uses the container\n\nCreate the file **docker-package.yaml** in the `/tmp/docker-package` directory with the following contents:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: python\n    arguments: /app/printer.py \"%(message)s\"\n    environment:\n        PATH: /usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app\n  resourceManager:\n    config:\n        backend: docker\n    docker:\n        image: my-printer:latest\n        imagePullPolicy: IfNotPresent\n```\n\n\nThe differences between this experiment and above **hello-world.yaml** experiment are all about the **printer** `component`:\n\n1. The **bin/printer.py:ref** Reference is replaced by the direct path `/app/printer.py`\n    - The file is now located inside the container so using a direct path is perfectly fine\n    - The runtime system will search for this executable in the `$PATH` environment variable of the component\n1. We set `command.environment.PATH` to include the path to the `printer.py` script\n    - By default, components receive the virtual environment of the runtime process which is not guaranteed to be compatible with the environment variables that enable the execution of commands inside the container\n1. Configure the docker backend for this component\n   - Set `resourceManager.config.backend` to `docker`\n   - Set `resourceManager.docker.image` to `my-printer:latest`\n   - Set `resourceManager.docker.imagePullPolicy` to `IfNotPresent`\n      - This setting instructs the runtime to only attempt to pull the image if it's not already present on the local machine\n\nThe resulting file tree in `/tmp/docker-package` should be:\n\n```\n/tmp/docker-package\n├── Dockerfile            # To build image\n├── requirements.txt      # To build image\n├── printer.py            # To build image\n└── docker-package.yaml   # To execute experiment\n```\n\n<InlineNotification kind=\"info\">\n\nST4SD supports multiple different backends for your components however these features are beyond the focus of this example. You can find more information in the [advanced experiments](/add-interface-to-experiments) as well as the [DSL documentation](/workflow-specification-dsl) page.\n\n</InlineNotification>\n\n### Exercise\n\nRun your virtual experiment using **elaunch.py**:\n\n```\nelaunch.py --nostamp docker-package.yaml\n```\n\nIf you encountered any issues during the process, please refer to the [troubleshooting](/direct-run#troubleshooting) section of the documentation for guidance on launching experiments locally.\n\nNow that you have ran the experiment, take a moment to **explore its outputs**. You can find the output files following directory:\n`docker-package.instance/stages/stage0/entry-instance`.\n\n\n## Your first Simulation experiment with GAMESS US\n\nIn this example, we will create a virtual experiment that performs the Parameterized Model 3 (PM3) method in GAMESS US. PM3 is a semi-empirical quantum chemistry method. Scientists use it to calculate the molecular properties and energies when computational efficiency is a priority as an alternative to high accuracy but slow to run high-level quantum methods like Hartree-Fock or Density Functional Theory (DFT).\n\nStart by creating a new directory in `/tmp/gamess-us-pm3` containing 2 directories: `bin` and `hooks` like so:\n\n```\n/tmp/gamess-us-pm3\n├── bin\n└── hooks\n```\n\nCreate the file `bin/run-gamess.sh` using the following:\n\n```\n#!/usr/bin/env sh\n\nmolecule=$1\ncpus=$2\n\n# The restart hook expects the filename to exist in the working directory\n# of GAMESS US\nmolecule_name=$(basename \"${molecule}\")\ncp ${molecule} ${molecule_name}\n\nPATH_RUNGMS_WRAPPER=${PATH_RUNGMS:-/usr/local/bin/rungms}\nPATH_GAMESS=${PATH_GAMESS:-/usr/local/bin/gamess}\n\nPATH_MY_GAMESS=${PATH_MY_GAMESS:-/tmp/gamess}\nGAMESS_SCRATCH_DIR=${GAMESS_SCRATCH_DIR:-${PATH_MY_GAMESS}/scratch}\n\nhere=`pwd`\nmkdir -p \"${PATH_MY_GAMESS}\"\nmkdir -p \"${GAMESS_SCRATCH_DIR}\"\n\nsed -e \"s#set USERSCR=/workspace/restart#set USERSCR=${here}#g\" \\\n    -e \"s#set currentdir=\\`pwd\\`#set currentdir=${PATH_GAMESS}#g\" \\\n    -e \"s#set SCR=\\`pwd\\`/scratch#set SCR=${GAMESS_SCRATCH_DIR}#g\" \\\n    -e \"s#TARGET=mpi#TARGET=ga#g\" \\\n    \"${PATH_GAMESS}/rungms\" >\"${PATH_MY_GAMESS}/run-gamess.sh\"\n\ncp /usr/local/bin/gamess/install.info \"${PATH_GAMESS}/install.info\"\n\n# The NVidia Image Features version 00 ONLY and target=GA ONLY\nversion=00\n\nchmod +x ${PATH_MY_GAMESS}/run-gamess.sh\n\n\"${PATH_MY_GAMESS}\"/run-gamess.sh \"${molecule_name}\" \"${version}\" \"${cpus}\"\n\n\n```\n\nThen download the [extract_gmsout.py script](https://github.com/st4sd/band-gap-gamess/blob/main/component-scripts/extract_gmsout.py) and store it in the `bin` directory.\n\nNext, make the **run-gamess.sh** script executable by running `chmod +x bin/run-gamess.sh` from inside the `/tmp/gamess-us-pm3` directory.\n\nDownload the [RestartHook example](https://github.com/st4sd/band-gap-gamess/blob/main/hooks/semi_empirical_restart.py) and save it under **hooks/semi_empirical_restart.py**. This script checks if the PM3 method in GAMESS US has converged. If not, it triggers a task restart. You can find more information on **RestartHooks** in our documentation about [restarting tasks](/restart).\n\nNext, prepare the definition of the experiment by pasting the following into the **gamess-us-pm3.yaml** file:\n\n```yaml\nentrypoint:\n  entry-instance: gamess-us-pm3\n  execute:\n  - target: <entry-instance>\n    args:\n      input.molecule.inp: input/molecule.inp\n      gamess-number-processors: 1\n      gamess-memory: \"4096Mi\"\n      # gamess-gpus is only relevant for execution on Kubernetes\n      gamess-gpus: 0\n      backend: docker\n\nworkflows:\n- signature:\n    name: gamess-us-pm3\n    parameters:\n    - name: input.molecule.inp\n    - name: gamess-number-processors\n    - name: gamess-memory\n    - name: gamess-gpus\n    - name: backend\n  steps:\n    optimise: geometry-optimisation\n    parse-gamess: extract-energies\n  execute:\n    - target: <optimise>\n      args:\n        molecule: \"%(input.molecule.inp)s:ref\"\n        gamess-number-processors: \"%(gamess-number-processors)s\"\n        gamess-memory: \"%(gamess-memory)s\"\n        gamess-gpus: \"%(gamess-gpus)s\"\n        backend: \"%(backend)s\"\n    - target: <parse-gamess>\n      args:\n        gamess-working-directory: \"<optimise>:ref\"\n        backend: \"%(backend)s\"\n\ncomponents:\n- signature:\n    name: geometry-optimisation\n    parameters:\n    - name: molecule\n    - name: gamess-number-processors\n      default: 1\n    - name: gamess-memory\n      default: \"4096Mi\"\n    - name: backend\n      default: docker\n    - name: gamess-image\n      default: nvcr.io/hpc/gamess:17.09-r2-libcchem\n    - name: docker-platform\n      default: \"linux/amd64\"\n    - name: gamess-gpus\n      default: 0\n  command:\n    arguments: \"%(molecule)s %(gamess-number-processors)s\"\n    environment:\n      PATH: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n    executable: bin/run-gamess.sh  # the runtime resolves relative paths in the executable field\n                                   # using the manifest file\n  workflowAttributes:\n    restartHookFile: semi_empirical_restart.py\n    restartHookOn:\n    - KnownIssue\n    - Success\n    - ResourceExhausted\n    shutdownOn:\n    - KnownIssue\n    - ResourceExhausted\n  resourceManager:\n    config:\n      backend: '%(backend)s'\n      # in minutes - only applies to Kubernetes runs\n      walltime: 600\n    docker:\n      image: \"%(gamess-image)s\"\n      platform: \"%(docker-platform)s\"\n    kubernetes:\n      image: \"%(gamess-image)s\"\n  resourceRequest:\n    memory: '%(gamess-memory)s'\n    numberThreads: '%(gamess-number-processors)s'\n    threadsPerCore: 1\n    gpus: '%(gamess-gpus)s'\n\n- signature:\n    name: extract-energies\n    parameters:\n    - name: gamess-working-directory\n    - name: backend\n    - name: docker-platform\n      default: \"linux/amd64\"\n  command:\n    executable: python\n    arguments: \"bin/extract_gmsout.py:ref %(gamess-working-directory)s\"\n  resourceManager:\n    config:\n      backend: '%(backend)s'\n    kubernetes:\n      image: quay.io/st4sd/community-applications/rdkit-st4sd:2019.09.1\n    docker:\n      image: quay.io/st4sd/community-applications/rdkit-st4sd:2019.09.1\n      platform: \"%(docker-platform)s\"\n```\n\nFinally create your **manifest.yaml** file:\n\n```yaml\nbin: bin\nhooks: hooks\n```\n\nYou should now have the following file structure:\n\n```\n/tmp/gamess-us-pm3\n├── bin\n│   ├── extract_gmsout.py\n│   └── run-gamess.sh\n├── hooks\n│   └── semi_empirical_restart.pyf\n├── manifest.yaml\n└── gamess-us-pm3.yaml\n```\n\n### Exercise\n\nTry starting your experiment now using a container runtime.\n\nCreate your GAMESS-US input **molecule.inp** file in the directory `/tmp/gamess-us-pm3`.  You can use this example input file:\n\n```\n $CONTRL COORD=UNIQUE SCFTYP=RHF RUNTYP=OPTIMIZE MULT=1\n ISPHER=1 ICHARG=0 MAXIT=100 $END\n $SYSTEM MWORDS=100 TIMLIM=600 $END\n $BASIS GBASIS=PM3 $END\n $GUESS GUESS=HUCKEL $END\n $SCF DIRSCF=.t. FDIFF=.f. DIIS=.t. $END\n $STATPT NSTEP=500 PROJCT=.f. IHREP=20 HSSEND=.t. $END\n $DATA\nCH4 C CH4\n C1\n C 6.0 0.0 0.0 0.0\n H 1.0 0.1895 0.9552 -0.4946\n H 1.0 0.9509 -0.4809 0.2396\n H 1.0 -0.5631 0.1717 0.92\n H 1.0 -0.5773 -0.6461 -0.665\n $END\n```\n\n<InlineNotification kind=\"info\">\n\nTo use your own GAMESS US input file, carefully review the configuration options preceding the `$DATA` section and include them in your file. Additionally, ensure that your input is saved in a file named **molecule.inp**.\n\n</InlineNotification>\n\n\nYou should now have this structure:\n\n```\n/tmp/gamess-us-pm3\n├── bin\n│   ├── extract_gmsout.py\n│   └── run-gamess.sh\n├── gamess-us-pm3.yaml\n├── hooks\n│   └── semi_empirical_restart.py\n├── manifest.yaml\n└── molecule.inp\n```\n\nLaunch your experiment providing the input file **molecule.inp** and the manifest file **manifest.yaml**.\n\n```\nelaunch.py --nostamp --manifest manifest.yaml -i molecule.inp gamess-us-pm3.yaml\n```\n\nAfter a couple of minutes you should see:\n\n```\ncompleted-on=2025-03-31 11:37:49.301663\ncost=0\ncreated-on=2025-03-31 11:35:46.527619\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-31 11:37:51.780640\nupdated-on=2025-03-31 11:37:51.780640\n```\n\nThe **gamess-us-pm3.instance** directory will have the following structure:\n\n```\ngamess-us-pm3.instance\n├── bin\n│     ├── extract_gmsout.py\n│     └── run-gamess.sh\n├── conf\n│     ├── dsl.yaml\n│     ├── flowir_instance.yaml\n│     ├── flowir_package.yaml\n│     └── manifest.yaml\n├── elaunch.yaml\n├── hooks\n│     ├── __pycache__\n│     │     └── semi_empirical_restart.cpython-310.pyc\n│     └── semi_empirical_restart.py\n├── input\n│     └── molecule.inp\n├── output\n│     ├── experiment.log\n│     ├── output.json\n│     ├── output.txt\n│     ├── status.txt\n│     └── status_details.json\n├── python\n├── stages\n│     └── stage0\n│         ├── optimise\n│         │     ├── Run1\n│         │     │     ├── component_performance.csv\n│         │     │     ├── molecule.dat\n│         │     │     ├── molecule.inp\n│         │     │     ├── molecule.rst\n│         │     │     ├── out.stderr\n│         │     │     └── out.stdout\n│         │     ├── component_performance.csv\n│         │     ├── molecule.dat\n│         │     ├── molecule.inp\n│         │     ├── molecule.rst\n│         │     ├── out.stderr\n│         │     └── out.stdout\n│         └── parse-gamess\n│             ├── component_performance.csv\n│             ├── csv2inp.log\n│             ├── energies.csv\n│             ├── out.stderr\n│             └── out.stdout\n└── status.db\n```\n\n\nExamine the files under **stages/stage0/optimise** and **stages/stage0/parse-gamess**.\n\nThese were the contents of **stages/stage0/parse-gamess/energies.csv** for the experiment we ran on our laptop:\n\n```\nlabel,completed,total-energy,homo,lumo,gap,electric-moments,total-time,total-time-per-core\nmolecule,OK,-180.53313527498008,-13.641,4.245,17.886,0.000050,0.1,0.10\n```\n\n## What's next?\n\n- Learn more about writing experiments, including more advanced features and best practice [here](/write-more-experiments)\n- Learn how to add [key-outputs and interfaces](/add-interface-to-experiments) to your experiments\n- More information on running experiments directly, i.e. via `elaunch.py` [here](/direct-run)\n- More information on the DSL of ST4SD i.e. how to write experiments [here](/workflow-specification-dsl)\n- More information on how to structure and test your experiments [here](/packaging-workflows/)\n\n","fileAbsolutePath":"/home/travis/build/st4sd/overview/src/pages/write-experiments.mdx"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}