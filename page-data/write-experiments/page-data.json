{"componentChunkName":"component---src-pages-write-experiments-mdx","path":"/write-experiments/","result":{"pageContext":{"frontmatter":{"title":"Write experiments"},"relativePagePath":"/write-experiments.mdx","titleType":"page","MdxNode":{"id":"a4909071-b92d-5535-976a-635698395e4a","children":[],"parent":"7378461b-e1ce-54b8-a52a-ccea1cf489d4","internal":{"content":"---\ntitle: Write experiments\n---\n\nimport { CarbonForIbmDotcom } from \"@carbon/pictograms-react\";\nimport { ArtTools_01 } from \"@carbon/pictograms-react\";\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nThis page assumes you are familiar with running experiments locally using the elaunch.py command line tool. If you need a refresher take a moment to read our [docs](/direct-run) before continuing any further.\n\n</PageDescription>\n\n\n<InlineNotification kind=\"info\">\n\nHere, we are using DSL 2.0, if you need to understand the previous syntax check out the [FlowIR docs](/workflow-specification) and [FlowIR tutorial](/tutorial).\n\n</InlineNotification>\n\n<AnchorLinks>\n\n  <AnchorLink>Wrapping a python script for native execution</AnchorLink>\n  <AnchorLink>Sharing your virtual experiments with others</AnchorLink>\n  <AnchorLink>Your first Simulation experiment with GAMESS US</AnchorLink>\n\n</AnchorLinks>\n\n\n\n## Requirements\n\n- An understanding of [how to run a virtual experiment locally](/direct-run).\n- A python 3.9+ interpreter, [git](https://git-scm.com/downloads) to clone code from Git servers, and an understanding of the syntax & structure of [YAML](https://www.redhat.com/en/topics/automation/what-is-yaml)\n- A virtual environment with the `st4sd-runtime-core` python module\n\n    ```bash\n    python -m venv venv\n    . ./venv/bin/activate\n    pip pip install \"st4sd-runtime-core[develop]\">=2.4.0\"\n    ```\n- A Container Runtime system: install one of [docker](https://docs.docker.com/engine/install/), [podman](https://podman.io/docs/installation), or [Rancher Desktop](https://docs.rancherdesktop.io/getting-started/installation/)\n\n<InlineNotification kind=\"warning\">\n\nBefore you continue any further, please make sure you are comfortable with [running virtual experiments locally](/direct-run).\n\n</InlineNotification>\n\n## Wrapping a python script for native execution\n\nFor your first virtual experiment, we will start with a Python script and use a virtual environment where **st4sd-runtime-core** is installed. This is a great way to quickly prototype virtual experiments without worrying about making them shareable with others. Check out [Sharing your virtual experiments with others](#sharing-your-virtual-experiments-with-others) for an example.\n\nBegin by creating a directory called `python-native.package`. In it, create 2 directories: `bin` and `conf`. Next, we'll define the definition of the virtual experiment.\n\n\nST4SD virtual experiments are structured as follows:\n\n\n```yaml\nentrypoint:\n    # Instructions of the entry point to your experiment\ncomponents:\n    # Templates for executing a single task\nworkflows:\n    # Templates for executing multiple steps which can be\n    # Workflows or Components\n```\n\n\nDevelopers build experiments by connecting **Components** and **Workflows**. Components represent individual tasks, while Workflows represent graphs of nested Workflows and Components. The example provided demonstrates the execution of a single task. A helpful way to understand virtual experiments is to think of them as **programs** written in a programming language. In this analogy, Workflows and Components serve as functions, and the **entrypoint** is similar to declaring a **main()** function, specifying which function to execute and what arguments to pass to it.\n\nPlace the following in the file `conf/dsl.yaml`:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: bin/printer.py\n    arguments: \"%(message)s\"\n```\n\nIn this example, the experiment's entrypoint, instantiates the printer component and sets its **message** parameter to \"Hello world\".\n\nThe **printer** component template has a single parameter, message, which does not have a default value. This component runs the executable \"bin/printer.py\", passing the message value as an argument.\n\n\nNext, create the \"bin/printer.py\" file using this very simple python code:\n\n\n```python\n#!/usr/bin/env python\n\nimport sys\nprint(\" \".join(sys.argv[1:]))\n```\n\n\nAfter creating the file, navigate to the **python-native.package** directory and run the command chmod +x bin/printer.py to make the file executable. This step is necessary to allow the file to be executed as a script.\n\n\n<InlineNotification kind=\"warning\">\n\nAt this point, double check that you have used the exact names as above, that your python file starts with the shebang line `#!/usr/bin/env python`, and that it's executable.\n\nThe expected file structure is the following:\n\n```\npython-native.package\n├── bin\n│   └── printer.py\n└── conf\n    └── dsl.yaml\n```\n\nIf you want to produce similar tree outputs for your directories use the [tree](https://oldmanprogrammer.net/source.php?dir=projects/tree) commandline utility which is also available via [brew](https://formulae.brew.sh/formula/tree).\n\n\n</InlineNotification>\n\n\nLet's run the experiment using `elaunch.py`. After a few seconds you should see the following printout:\n\n```\n$ elaunch.py --nostamp -l40 python-native.package\n\ncompleted-on=2025-03-22 12:39:13.806401\ncost=0\ncreated-on=2025-03-22 12:39:07.382235\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-22 12:39:17.417956\nupdated-on=2025-03-22 12:39:17.417956\n```\n\nThe experiment will create the directory **python-native.instance** and store all files it generated in it.\n\n```\npython-native.instance\n├── bin\n│   └── printer.py\n├── conf (For now focus on just the dsl.yaml file)\n│   ├── dsl.yaml\n│   ├── flowir_instance.yaml\n│   ├── flowir_package.yaml\n│   └── manifest.yaml\n├── stages\n│   └── stage0\n│       └── entry-instance\n│           ├── component_performance.csv\n│           ├── out.stderr\n│           └── out.stdout\n├── output\n│   ├── experiment.log\n│   ├── output.json\n│   ├── output.txt\n│   ├── status.txt\n│   └── status_details.json\n├── input\n├── python\n├── elaunch.yaml\n└── status.db\n\n```\n\nIf you encountered any issues during the process, please refer to the [troubleshooting](/direct-run#troubleshooting) section of the documentation for guidance on launching experiments locally.\n\nNow that you have ran the experiment, take a moment to **explore its outputs**. You can find the output files following directory:\n`python-native.instance/stages/stage0/entry-instance`.\n\n\n### Exercise\n\n\nIn ST4SD you can override the parameters of `entry-instance` that the `entrypoint` sets via the dictionary `entrypoint.execute[0].args`.\n\nFor example, place the following into a new file `my-variables.yaml`:\n\n```yaml\nglobal:\n  message: my custom message\n```\n\nThen remove the `python-native.instance` directory and run the experiment again but this time use load the `my-variables.yaml` file:\n\n```bash\nrm -rf python-native.instance\nelaunch.py -l40 --nostamp -a my-variables.yaml python-native.package\n```\n\nThe **stdout** of the `hello` component can be found in the following file:\n`0-hello-world.instance/stages/stage0/entry-instance/out.stdout`.\n\n## Sharing your virtual experiments with others\n\nTo make experiments shareable, they must include the following key information:\n\n1. All executables that they run, along with their software dependencies\n2. How to map the executables to specific steps\n3. How to connect inputs to these steps\n\nIn the [example](#wrapping-a-python-script-for-native-execution) above, we demonstrated how to wrap a single-step executable into a virtual experiment, covering the second and third requirements for a single-step experiment. In this example, we will utilize a container to share the software dependencies of the \"printer.py\" executable, addressing the first requirement.\n\n### Containerize your python application\n\nIn a **requirements.txt** file place the python dependencies of your script.\nThe **printer.py** python script that we use here does not have any python requirements but we'll just include **numpy** to demonstrate the method:\n\nThe contents of the  `requirements.txt` file are:\n\n```\nnumpy==2.2.4\n```\n\nNext, create a file called `Dockerfile` with the following contexts:\n\n```docker\nFROM python:3.11-slim\n\nRUN    apt-get update \\\n    && apt-get upgrade -y \\\n    && apt-get clean -y \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Make sure that files under /app are part of $PATH\nENV PATH=/app:$PATH\nWORKDIR /app\n\nCOPY requirements.txt /app/requirements.txt\n\nRUN pip install -r requirements.txt\n\nCOPY printer.py /app/printer.py\n\n# Make the printer.py file executable\nRUN chmod +x /app/printer.py\n```\n\nMake sure you have the following files in the directory you are currently in:\n\n```\n.\n├── Dockerfile\n├── printer.py\n└── requirements.txt\n```\n\nTo build your container, run docker:\n\n\n```\ndocker build --platform linux/amd64 -f Dockerfile -t my-printer:latest\n```\n\n<InlineNotification kind=\"info\">\n\nWe recommend building images for the x86-64 CPU architecture using the `--platform linux/amd64` flag to ease the transition into executing your virtual experiments on the cloud. You can specify the platform when building your image using the following command-line argument `--platform linux/amd64`.\n\n</InlineNotification>\n\n\n### Making your container available to others\n\nIf you plan to share your experiment with others, you will need to push your containers to a remote container registry, such as [Docker Hub](https://hub.docker.com/). This allows others to easily access and pull your container images, making it simpler to share and reproduce your experiment.\n\nTo push your container to a remote registry, you can use the following steps:\n\n1. **Tag your container image**: Use the `docker tag` command to assign a unique name to your image, including the registry URL and your username.\n2. **Login to the registry**: Use the `docker login` command to authenticate with the registry.\n3. **Push the image**: Use the `docker push` command to upload your image to the registry.\n\nFor example:\n\n```bash\n: # Tag the image\ndocker tag my-printer:latest <your-username>/my-printer:latest\n\n: # Login to Docker Hub\ndocker login\n\n: # Push the image\ndocker push <your-username>/my-printer:latest\n```\n\n<InlineNotification kind=\"info\">\n\nThe remainder of this example will assume that you do not have access to a container registry. In this case, you can still share your experiment with others by providing them with the necessary files and instructions to build the container image themselves. This can be done by sharing the **Dockerfile**, **printer.py**, and **requirements.txt** files. The recipient can then build the image using the `docker build --platform linux/amd64 -f Dockerfile -t my-printer:latest` command and run your virtual experiment locally.\n\n</InlineNotification>\n\n### Create a virtual experiment that uses the container\n\nCreate a new directory called `python-docker.package`, in it create a directory called `conf`.\n\nNext, create the file **cpython-docker.package/onf/dsl.yaml** using the following contents:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: printer.py\n    arguments: \"%(message)s\"\n    environment:\n        PATH: /usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app\n  resourceManager:\n    config:\n        backend: docker\n    docker:\n        image: my-printer:latest\n        imagePullPolicy: IfNotPresent\n```\n\n\nThe differences between this experiment and **python-native.package** are all about the **printer** `component`:\n\n1. The **bin/printer.py** file is no longer used.\n    - We set `command.executable` to `printer.py`\n    - The runtime system will search for this executable in the `$PATH` environment variable of the component\n1. We set `command.environment.PATH` to include the path to the `printer.py` script\n    - By default, components receive the virtual environment of the runtime process which is not guaranteed to be compatible with the environment variables that enable the execution of commands inside the container\n1. Configure the docker backend for this component\n   - Set `resourceManager.config.backend` to `docker`\n   - Set `resourceManager.docker.image` to `my-printer:latest`\n   - Set `resourceManager.docker.imagePullPolicy` to `IfNotPresent`\n      - This setting instructs the runtime to only attempt to pull the image if it's not already present on the local machine\n\nThe resulting file tree of your experiment should look like this:\n\n```\npython-docker.package\n└── conf\n    └── dsl.yaml\n```\n\n<InlineNotification kind=\"info\">\n\nST4SD supports multiple different backends for your components however these features are beyond the focus of this example. You can find more information in the [advanced experiments](/add-interface-to-experiments) as well as the [DSL documentation](/workflow-specification-dsl) page.\n\n</InlineNotification>\n\n### Exercise\n\nRun your virtual experiment using **elaunch.py**:\n\n```\nelaunch.py --nostamp -l40 python-docker.package\n```\n\nIf you encountered any issues during the process, please refer to the [troubleshooting](/direct-run#troubleshooting) section of the documentation for guidance on launching experiments locally.\n\nNow that you have ran the experiment, take a moment to **explore its outputs**. You can find the output files following directory:\n`python-native.instance/stages/stage0/entry-instance`.\n\n\n## Your first Simulation experiment with GAMESS US\n\nIn this example, we will create a virtual experiment that performs the Parameterized Model 3 (PM3) method in GAMESS US. PM3 is a semi-empirical quantum chemistry method. Scientists use it to calculate the molecular properties and energies when computational efficiency is a priority as an alternative to high accuracy but slow to run high-level quantum methods like Hartree-Fock or Density Functional Theory (DFT).\n\nStart by creating a new directory called `gamess-us-pm3.package` containing 3 directories: `bin`, `conf`, and `hooks` like so:\n\n```\ngamess-us-pm3.package\n├── bin\n├── conf\n└── hooks\n```\n\nCreate the file `bin/run-gamess.sh` using the following:\n\n```\n#!/usr/bin/env sh\n\nmolecule=$1\ncpus=$2\n\n# The restart hook expects the filename to exist in the working directory\n# of GAMESS US\nmolecule_name=$(basename \"${molecule}\")\ncp ${molecule} ${molecule_name}\n\nPATH_RUNGMS_WRAPPER=${PATH_RUNGMS:-/usr/local/bin/rungms}\nPATH_GAMESS=${PATH_GAMESS:-/usr/local/bin/gamess}\n\nPATH_MY_GAMESS=${PATH_MY_GAMESS:-/tmp/gamess}\nGAMESS_SCRATCH_DIR=${GAMESS_SCRATCH_DIR:-${PATH_MY_GAMESS}/scratch}\n\nhere=`pwd`\nmkdir -p \"${PATH_MY_GAMESS}\"\nmkdir -p \"${GAMESS_SCRATCH_DIR}\"\n\nsed -e \"s#set USERSCR=/workspace/restart#set USERSCR=${here}#g\" \\\n    -e \"s#set currentdir=\\`pwd\\`#set currentdir=${PATH_GAMESS}#g\" \\\n    -e \"s#set SCR=\\`pwd\\`/scratch#set SCR=${GAMESS_SCRATCH_DIR}#g\" \\\n    -e \"s#TARGET=mpi#TARGET=ga#g\" \\\n    \"${PATH_GAMESS}/rungms\" >\"${PATH_MY_GAMESS}/run-gamess.sh\"\n\ncp /usr/local/bin/gamess/install.info \"${PATH_GAMESS}/install.info\"\n\n# The NVidia Image Features version 00 ONLY and target=GA ONLY\nversion=00\n\nchmod +x ${PATH_MY_GAMESS}/run-gamess.sh\n\n\"${PATH_MY_GAMESS}\"/run-gamess.sh \"${molecule_name}\" \"${version}\" \"${cpus}\"\n\n\n```\n\nThen download the [extract_gmsout.py script](https://github.com/st4sd/band-gap-gamess/blob/main/component-scripts/extract_gmsout.py) and store it in the `bin` directory.\n\nNext, make the both the **run-gamess.sh** and **extract_gmsout.py** scripts executable by running `chmod +x bin/*` inside the `gamess-us-pm3.package` directory.\n\nDownload the [RestartHook example](https://github.com/st4sd/band-gap-gamess/blob/main/hooks/semi_empirical_restart.py) and save it in the **hooks** directory. This script checks if the PM3 method in GAMESS US has converged. If not, it triggers a task restart.\n\nNext, prepare the definition of the experiment by pasting the following into the **conf/dsl.yaml** file:\n\n```yaml\nentrypoint:\n  entry-instance: gamess-us-pm3\n  execute:\n  - target: <entry-instance>\n    args:\n      input.molecule.inp: input/molecule.inp\n      gamess-number-processors: 1\n      gamess-memory: \"4096Mi\"\n      # gamess-gpus is only relevant for executon on Kubernetes\n      gamess-gpus: 0\n      backend: docker\n\nworkflows:\n- signature:\n    name: gamess-us-pm3\n    parameters:\n    - name: input.molecule.inp\n    - name: gamess-number-processors\n    - name: gamess-memory\n    - name: gamess-gpus\n    - name: backend\n  steps:\n    optimise: geometry-optimisation\n    parse-gamess: extract-energies\n  execute:\n    - target: <optimise>\n      args:\n        molecule: \"%(input.molecule.inp)s:ref\"\n        gamess-number-processors: \"%(gamess-number-processors)s\"\n        gamess-memory: \"%(gamess-memory)s\"\n        gamess-gpus: \"%(gamess-gpus)s\"\n        backend: \"%(backend)s\"\n    - target: <parse-gamess>\n      args:\n        gamess-working-directory: \"<optimise>:ref\"\n        backend: \"%(backend)s\"\n\ncomponents:\n- signature:\n    name: geometry-optimisation\n    parameters:\n    - name: molecule\n    - name: gamess-number-processors\n      default: 1\n    - name: gamess-memory\n      default: \"4096Mi\"\n    - name: backend\n      default: docker\n    - name: gamess-image\n      default: nvcr.io/hpc/gamess:17.09-r2-libcchem\n    - name: docker-platform\n      default: \"linux/amd64\"\n    - name: gamess-gpus\n      default: 0\n  command:\n    arguments: \"%(molecule)s %(gamess-number-processors)s\"\n    environment:\n      PATH: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n    executable: bin/run-gamess.sh\n  workflowAttributes:\n    restartHookFile: semi_empirical_restart.py\n    restartHookOn:\n    - KnownIssue\n    - Success\n    - ResourceExhausted\n    shutdownOn:\n    - KnownIssue\n    - ResourceExhausted\n  resourceManager:\n    config:\n      backend: '%(backend)s'\n      # in minutes - only applies to Kubernetes runs\n      walltime: 600\n    docker:\n      image: \"%(gamess-image)s\"\n      platform: \"%(docker-platform)s\"\n    kubernetes:\n      image: \"%(gamess-image)s\"\n  resourceRequest:\n    memory: '%(gamess-memory)s'\n    numberThreads: '%(gamess-number-processors)s'\n    threadsPerCore: 1\n    gpus: '%(gamess-gpus)s'\n\n- signature:\n    name: extract-energies\n    parameters:\n    - name: gamess-working-directory\n    - name: backend\n    - name: docker-platform\n      default: \"linux/amd64\"\n  command:\n    arguments: \"%(gamess-working-directory)s\"\n    executable: bin/extract_gmsout.py\n  resourceManager:\n    config:\n      backend: '%(backend)s'\n    kubernetes:\n      image: quay.io/st4sd/community-applications/rdkit-st4sd:2019.09.1\n    docker:\n      image: quay.io/st4sd/community-applications/rdkit-st4sd:2019.09.1\n      platform: \"%(docker-platform)s\"\n```\n\nYou should now have the following file structure:\n\n```\ngamess-us-pm3.package\n├── bin\n│   ├── extract_gmsout.py\n│   └── run-gamess.sh\n├── conf\n│   └── dsl.yaml\n└── hooks\n    └── semi_empirical_restart.py\n```\n\n### Exercise\n\nTry starting your experiment now using a container runtime.\n\nIn the parent directory of **gamess-us-pm3.package** create your input **molecule.inp** file.\n\nYou can use this:\n\n```\n $CONTRL COORD=UNIQUE SCFTYP=RHF RUNTYP=OPTIMIZE MULT=1\n ISPHER=1 ICHARG=0 MAXIT=100 $END\n $SYSTEM MWORDS=100 TIMLIM=600 $END\n $BASIS GBASIS=PM3 $END\n $GUESS GUESS=HUCKEL $END\n $SCF DIRSCF=.t. FDIFF=.f. DIIS=.t. $END\n $STATPT NSTEP=500 PROJCT=.f. IHREP=20 HSSEND=.t. $END\n $DATA\nCH4 C CH4\n C1\n C 6.0 0.0 0.0 0.0\n H 1.0 0.1895 0.9552 -0.4946\n H 1.0 0.9509 -0.4809 0.2396\n H 1.0 -0.5631 0.1717 0.92\n H 1.0 -0.5773 -0.6461 -0.665\n $END\n```\n\n<InlineNotification kind=\"info\">\n\nTo use your own GAMESS US input file, carefully review the configuration options preceding the `$DATA` section and include them in your file. Additionally, ensure that your input is saved in a file named **molecule.inp**.\n\n</InlineNotification>\n\n\nYou should now have this structure:\n\n```\n.\n├── molecule.inp\n└── gamess-us-pm3.package\n    ├── bin\n    │   └── run-gamess.sh\n    │   └── extract_gmsout.py\n    ├── conf\n    │   └── dsl.yaml\n    └── hooks\n        └── semi_empirical_restart.py\n```\n\nThe command to launch the experiment is:\n\n```\n$ elaunch.py -l40 --nostamp -i molecule.inp gamess-us-pm3.package\n```\n\nAfter a couple of minutes you should see:\n\n```\ncompleted-on=2025-03-24 15:44:58.212321\ncost=0\ncreated-on=2025-03-24 15:44:34.036279\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-24 15:45:00.865704\nupdated-on=2025-03-24 15:45:00.865704\n```\n\nThe **gamess-us-pm3.instance** directory will have the following structure:\n\n```\ngamess-us-pm3.instance\n├── bin\n│   ├── extract_gmsout.py\n│   └── run-gamess.sh\n├── conf\n│   ├── dsl.yaml\n│   ├── flowir_instance.yaml\n│   ├── flowir_package.yaml\n│   └── manifest.yaml\n├── elaunch.yaml\n├── hooks\n│   ├── __pycache__\n│   │   └── semi_empirical_restart.cpython-310.pyc\n│   └── semi_empirical_restart.py\n├── input\n│   └── molecule.inp\n├── output\n│   ├── experiment.log\n│   ├── output.json\n│   ├── output.txt\n│   ├── status.txt\n│   └── status_details.json\n├── python\n├── stages\n│   └── stage0\n│       ├── optimise\n│       │   ├── Run1\n│       │   │   ├── component_performance.csv\n│       │   │   ├── molecule.dat\n│       │   │   ├── molecule.inp\n│       │   │   ├── molecule.rst\n│       │   │   ├── out.stderr\n│       │   │   └── out.stdout\n│       │   ├── component_performance.csv\n│       │   ├── molecule.dat\n│       │   ├── molecule.inp\n│       │   ├── molecule.rst\n│       │   ├── out.stderr\n│       │   └── out.stdout\n│       └── parse-gamess\n│           ├── component_performance.csv\n│           ├── csv2inp.log\n│           ├── energies.csv\n│           ├── out.stderr\n│           └── out.stdout\n└── status.db\n\n```\n\n\nExamine the files under **stages/stage0/optimise** and **stages/stage0/parse-gamess**.\n\nThese were the contents of **stages/stage0/parse-gamess/energies.csv** for the experiment we ran on our laptop:\n\n```\nlabel,completed,total-energy,homo,lumo,gap,electric-moments,total-time,total-time-per-core\nmolecule,OK,-180.53313527498008,-13.641,4.245,17.886,0.000050,0.1,0.10\n```\n\n\n\n## What's next?\n\n- Learn more about writing experiments, including more advanced features and best practice [here](/write-more-experiments)\n- Learn how to add [key-outputs and interfaces](/add-interface-to-experiments) to your experiments\n- More information on running experiments directly, i.e. via `elaunch.py` [here](/direct-run)\n- More information on the DSL of ST4SD i.e. how to write experiments [here](/workflow-specification-dsl)\n- More information on how to structure and test your experiments [here](/packaging-workflows/)\n\n","type":"Mdx","contentDigest":"3b10efd276a7dcb846c06423d35e5dac","owner":"gatsby-plugin-mdx","counter":284},"frontmatter":{"title":"Write experiments"},"exports":{},"rawBody":"---\ntitle: Write experiments\n---\n\nimport { CarbonForIbmDotcom } from \"@carbon/pictograms-react\";\nimport { ArtTools_01 } from \"@carbon/pictograms-react\";\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nThis page assumes you are familiar with running experiments locally using the elaunch.py command line tool. If you need a refresher take a moment to read our [docs](/direct-run) before continuing any further.\n\n</PageDescription>\n\n\n<InlineNotification kind=\"info\">\n\nHere, we are using DSL 2.0, if you need to understand the previous syntax check out the [FlowIR docs](/workflow-specification) and [FlowIR tutorial](/tutorial).\n\n</InlineNotification>\n\n<AnchorLinks>\n\n  <AnchorLink>Wrapping a python script for native execution</AnchorLink>\n  <AnchorLink>Sharing your virtual experiments with others</AnchorLink>\n  <AnchorLink>Your first Simulation experiment with GAMESS US</AnchorLink>\n\n</AnchorLinks>\n\n\n\n## Requirements\n\n- An understanding of [how to run a virtual experiment locally](/direct-run).\n- A python 3.9+ interpreter, [git](https://git-scm.com/downloads) to clone code from Git servers, and an understanding of the syntax & structure of [YAML](https://www.redhat.com/en/topics/automation/what-is-yaml)\n- A virtual environment with the `st4sd-runtime-core` python module\n\n    ```bash\n    python -m venv venv\n    . ./venv/bin/activate\n    pip pip install \"st4sd-runtime-core[develop]\">=2.4.0\"\n    ```\n- A Container Runtime system: install one of [docker](https://docs.docker.com/engine/install/), [podman](https://podman.io/docs/installation), or [Rancher Desktop](https://docs.rancherdesktop.io/getting-started/installation/)\n\n<InlineNotification kind=\"warning\">\n\nBefore you continue any further, please make sure you are comfortable with [running virtual experiments locally](/direct-run).\n\n</InlineNotification>\n\n## Wrapping a python script for native execution\n\nFor your first virtual experiment, we will start with a Python script and use a virtual environment where **st4sd-runtime-core** is installed. This is a great way to quickly prototype virtual experiments without worrying about making them shareable with others. Check out [Sharing your virtual experiments with others](#sharing-your-virtual-experiments-with-others) for an example.\n\nBegin by creating a directory called `python-native.package`. In it, create 2 directories: `bin` and `conf`. Next, we'll define the definition of the virtual experiment.\n\n\nST4SD virtual experiments are structured as follows:\n\n\n```yaml\nentrypoint:\n    # Instructions of the entry point to your experiment\ncomponents:\n    # Templates for executing a single task\nworkflows:\n    # Templates for executing multiple steps which can be\n    # Workflows or Components\n```\n\n\nDevelopers build experiments by connecting **Components** and **Workflows**. Components represent individual tasks, while Workflows represent graphs of nested Workflows and Components. The example provided demonstrates the execution of a single task. A helpful way to understand virtual experiments is to think of them as **programs** written in a programming language. In this analogy, Workflows and Components serve as functions, and the **entrypoint** is similar to declaring a **main()** function, specifying which function to execute and what arguments to pass to it.\n\nPlace the following in the file `conf/dsl.yaml`:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: bin/printer.py\n    arguments: \"%(message)s\"\n```\n\nIn this example, the experiment's entrypoint, instantiates the printer component and sets its **message** parameter to \"Hello world\".\n\nThe **printer** component template has a single parameter, message, which does not have a default value. This component runs the executable \"bin/printer.py\", passing the message value as an argument.\n\n\nNext, create the \"bin/printer.py\" file using this very simple python code:\n\n\n```python\n#!/usr/bin/env python\n\nimport sys\nprint(\" \".join(sys.argv[1:]))\n```\n\n\nAfter creating the file, navigate to the **python-native.package** directory and run the command chmod +x bin/printer.py to make the file executable. This step is necessary to allow the file to be executed as a script.\n\n\n<InlineNotification kind=\"warning\">\n\nAt this point, double check that you have used the exact names as above, that your python file starts with the shebang line `#!/usr/bin/env python`, and that it's executable.\n\nThe expected file structure is the following:\n\n```\npython-native.package\n├── bin\n│   └── printer.py\n└── conf\n    └── dsl.yaml\n```\n\nIf you want to produce similar tree outputs for your directories use the [tree](https://oldmanprogrammer.net/source.php?dir=projects/tree) commandline utility which is also available via [brew](https://formulae.brew.sh/formula/tree).\n\n\n</InlineNotification>\n\n\nLet's run the experiment using `elaunch.py`. After a few seconds you should see the following printout:\n\n```\n$ elaunch.py --nostamp -l40 python-native.package\n\ncompleted-on=2025-03-22 12:39:13.806401\ncost=0\ncreated-on=2025-03-22 12:39:07.382235\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-22 12:39:17.417956\nupdated-on=2025-03-22 12:39:17.417956\n```\n\nThe experiment will create the directory **python-native.instance** and store all files it generated in it.\n\n```\npython-native.instance\n├── bin\n│   └── printer.py\n├── conf (For now focus on just the dsl.yaml file)\n│   ├── dsl.yaml\n│   ├── flowir_instance.yaml\n│   ├── flowir_package.yaml\n│   └── manifest.yaml\n├── stages\n│   └── stage0\n│       └── entry-instance\n│           ├── component_performance.csv\n│           ├── out.stderr\n│           └── out.stdout\n├── output\n│   ├── experiment.log\n│   ├── output.json\n│   ├── output.txt\n│   ├── status.txt\n│   └── status_details.json\n├── input\n├── python\n├── elaunch.yaml\n└── status.db\n\n```\n\nIf you encountered any issues during the process, please refer to the [troubleshooting](/direct-run#troubleshooting) section of the documentation for guidance on launching experiments locally.\n\nNow that you have ran the experiment, take a moment to **explore its outputs**. You can find the output files following directory:\n`python-native.instance/stages/stage0/entry-instance`.\n\n\n### Exercise\n\n\nIn ST4SD you can override the parameters of `entry-instance` that the `entrypoint` sets via the dictionary `entrypoint.execute[0].args`.\n\nFor example, place the following into a new file `my-variables.yaml`:\n\n```yaml\nglobal:\n  message: my custom message\n```\n\nThen remove the `python-native.instance` directory and run the experiment again but this time use load the `my-variables.yaml` file:\n\n```bash\nrm -rf python-native.instance\nelaunch.py -l40 --nostamp -a my-variables.yaml python-native.package\n```\n\nThe **stdout** of the `hello` component can be found in the following file:\n`0-hello-world.instance/stages/stage0/entry-instance/out.stdout`.\n\n## Sharing your virtual experiments with others\n\nTo make experiments shareable, they must include the following key information:\n\n1. All executables that they run, along with their software dependencies\n2. How to map the executables to specific steps\n3. How to connect inputs to these steps\n\nIn the [example](#wrapping-a-python-script-for-native-execution) above, we demonstrated how to wrap a single-step executable into a virtual experiment, covering the second and third requirements for a single-step experiment. In this example, we will utilize a container to share the software dependencies of the \"printer.py\" executable, addressing the first requirement.\n\n### Containerize your python application\n\nIn a **requirements.txt** file place the python dependencies of your script.\nThe **printer.py** python script that we use here does not have any python requirements but we'll just include **numpy** to demonstrate the method:\n\nThe contents of the  `requirements.txt` file are:\n\n```\nnumpy==2.2.4\n```\n\nNext, create a file called `Dockerfile` with the following contexts:\n\n```docker\nFROM python:3.11-slim\n\nRUN    apt-get update \\\n    && apt-get upgrade -y \\\n    && apt-get clean -y \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Make sure that files under /app are part of $PATH\nENV PATH=/app:$PATH\nWORKDIR /app\n\nCOPY requirements.txt /app/requirements.txt\n\nRUN pip install -r requirements.txt\n\nCOPY printer.py /app/printer.py\n\n# Make the printer.py file executable\nRUN chmod +x /app/printer.py\n```\n\nMake sure you have the following files in the directory you are currently in:\n\n```\n.\n├── Dockerfile\n├── printer.py\n└── requirements.txt\n```\n\nTo build your container, run docker:\n\n\n```\ndocker build --platform linux/amd64 -f Dockerfile -t my-printer:latest\n```\n\n<InlineNotification kind=\"info\">\n\nWe recommend building images for the x86-64 CPU architecture using the `--platform linux/amd64` flag to ease the transition into executing your virtual experiments on the cloud. You can specify the platform when building your image using the following command-line argument `--platform linux/amd64`.\n\n</InlineNotification>\n\n\n### Making your container available to others\n\nIf you plan to share your experiment with others, you will need to push your containers to a remote container registry, such as [Docker Hub](https://hub.docker.com/). This allows others to easily access and pull your container images, making it simpler to share and reproduce your experiment.\n\nTo push your container to a remote registry, you can use the following steps:\n\n1. **Tag your container image**: Use the `docker tag` command to assign a unique name to your image, including the registry URL and your username.\n2. **Login to the registry**: Use the `docker login` command to authenticate with the registry.\n3. **Push the image**: Use the `docker push` command to upload your image to the registry.\n\nFor example:\n\n```bash\n: # Tag the image\ndocker tag my-printer:latest <your-username>/my-printer:latest\n\n: # Login to Docker Hub\ndocker login\n\n: # Push the image\ndocker push <your-username>/my-printer:latest\n```\n\n<InlineNotification kind=\"info\">\n\nThe remainder of this example will assume that you do not have access to a container registry. In this case, you can still share your experiment with others by providing them with the necessary files and instructions to build the container image themselves. This can be done by sharing the **Dockerfile**, **printer.py**, and **requirements.txt** files. The recipient can then build the image using the `docker build --platform linux/amd64 -f Dockerfile -t my-printer:latest` command and run your virtual experiment locally.\n\n</InlineNotification>\n\n### Create a virtual experiment that uses the container\n\nCreate a new directory called `python-docker.package`, in it create a directory called `conf`.\n\nNext, create the file **cpython-docker.package/onf/dsl.yaml** using the following contents:\n\n```yaml\nentrypoint:\n  entry-instance: printer\n  execute:\n  - target: <entry-instance>\n    args:\n      message: Hello world\n\ncomponents:\n- signature:\n    name: printer\n    parameters:\n      - name: message\n  command:\n    executable: printer.py\n    arguments: \"%(message)s\"\n    environment:\n        PATH: /usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app\n  resourceManager:\n    config:\n        backend: docker\n    docker:\n        image: my-printer:latest\n        imagePullPolicy: IfNotPresent\n```\n\n\nThe differences between this experiment and **python-native.package** are all about the **printer** `component`:\n\n1. The **bin/printer.py** file is no longer used.\n    - We set `command.executable` to `printer.py`\n    - The runtime system will search for this executable in the `$PATH` environment variable of the component\n1. We set `command.environment.PATH` to include the path to the `printer.py` script\n    - By default, components receive the virtual environment of the runtime process which is not guaranteed to be compatible with the environment variables that enable the execution of commands inside the container\n1. Configure the docker backend for this component\n   - Set `resourceManager.config.backend` to `docker`\n   - Set `resourceManager.docker.image` to `my-printer:latest`\n   - Set `resourceManager.docker.imagePullPolicy` to `IfNotPresent`\n      - This setting instructs the runtime to only attempt to pull the image if it's not already present on the local machine\n\nThe resulting file tree of your experiment should look like this:\n\n```\npython-docker.package\n└── conf\n    └── dsl.yaml\n```\n\n<InlineNotification kind=\"info\">\n\nST4SD supports multiple different backends for your components however these features are beyond the focus of this example. You can find more information in the [advanced experiments](/add-interface-to-experiments) as well as the [DSL documentation](/workflow-specification-dsl) page.\n\n</InlineNotification>\n\n### Exercise\n\nRun your virtual experiment using **elaunch.py**:\n\n```\nelaunch.py --nostamp -l40 python-docker.package\n```\n\nIf you encountered any issues during the process, please refer to the [troubleshooting](/direct-run#troubleshooting) section of the documentation for guidance on launching experiments locally.\n\nNow that you have ran the experiment, take a moment to **explore its outputs**. You can find the output files following directory:\n`python-native.instance/stages/stage0/entry-instance`.\n\n\n## Your first Simulation experiment with GAMESS US\n\nIn this example, we will create a virtual experiment that performs the Parameterized Model 3 (PM3) method in GAMESS US. PM3 is a semi-empirical quantum chemistry method. Scientists use it to calculate the molecular properties and energies when computational efficiency is a priority as an alternative to high accuracy but slow to run high-level quantum methods like Hartree-Fock or Density Functional Theory (DFT).\n\nStart by creating a new directory called `gamess-us-pm3.package` containing 3 directories: `bin`, `conf`, and `hooks` like so:\n\n```\ngamess-us-pm3.package\n├── bin\n├── conf\n└── hooks\n```\n\nCreate the file `bin/run-gamess.sh` using the following:\n\n```\n#!/usr/bin/env sh\n\nmolecule=$1\ncpus=$2\n\n# The restart hook expects the filename to exist in the working directory\n# of GAMESS US\nmolecule_name=$(basename \"${molecule}\")\ncp ${molecule} ${molecule_name}\n\nPATH_RUNGMS_WRAPPER=${PATH_RUNGMS:-/usr/local/bin/rungms}\nPATH_GAMESS=${PATH_GAMESS:-/usr/local/bin/gamess}\n\nPATH_MY_GAMESS=${PATH_MY_GAMESS:-/tmp/gamess}\nGAMESS_SCRATCH_DIR=${GAMESS_SCRATCH_DIR:-${PATH_MY_GAMESS}/scratch}\n\nhere=`pwd`\nmkdir -p \"${PATH_MY_GAMESS}\"\nmkdir -p \"${GAMESS_SCRATCH_DIR}\"\n\nsed -e \"s#set USERSCR=/workspace/restart#set USERSCR=${here}#g\" \\\n    -e \"s#set currentdir=\\`pwd\\`#set currentdir=${PATH_GAMESS}#g\" \\\n    -e \"s#set SCR=\\`pwd\\`/scratch#set SCR=${GAMESS_SCRATCH_DIR}#g\" \\\n    -e \"s#TARGET=mpi#TARGET=ga#g\" \\\n    \"${PATH_GAMESS}/rungms\" >\"${PATH_MY_GAMESS}/run-gamess.sh\"\n\ncp /usr/local/bin/gamess/install.info \"${PATH_GAMESS}/install.info\"\n\n# The NVidia Image Features version 00 ONLY and target=GA ONLY\nversion=00\n\nchmod +x ${PATH_MY_GAMESS}/run-gamess.sh\n\n\"${PATH_MY_GAMESS}\"/run-gamess.sh \"${molecule_name}\" \"${version}\" \"${cpus}\"\n\n\n```\n\nThen download the [extract_gmsout.py script](https://github.com/st4sd/band-gap-gamess/blob/main/component-scripts/extract_gmsout.py) and store it in the `bin` directory.\n\nNext, make the both the **run-gamess.sh** and **extract_gmsout.py** scripts executable by running `chmod +x bin/*` inside the `gamess-us-pm3.package` directory.\n\nDownload the [RestartHook example](https://github.com/st4sd/band-gap-gamess/blob/main/hooks/semi_empirical_restart.py) and save it in the **hooks** directory. This script checks if the PM3 method in GAMESS US has converged. If not, it triggers a task restart.\n\nNext, prepare the definition of the experiment by pasting the following into the **conf/dsl.yaml** file:\n\n```yaml\nentrypoint:\n  entry-instance: gamess-us-pm3\n  execute:\n  - target: <entry-instance>\n    args:\n      input.molecule.inp: input/molecule.inp\n      gamess-number-processors: 1\n      gamess-memory: \"4096Mi\"\n      # gamess-gpus is only relevant for executon on Kubernetes\n      gamess-gpus: 0\n      backend: docker\n\nworkflows:\n- signature:\n    name: gamess-us-pm3\n    parameters:\n    - name: input.molecule.inp\n    - name: gamess-number-processors\n    - name: gamess-memory\n    - name: gamess-gpus\n    - name: backend\n  steps:\n    optimise: geometry-optimisation\n    parse-gamess: extract-energies\n  execute:\n    - target: <optimise>\n      args:\n        molecule: \"%(input.molecule.inp)s:ref\"\n        gamess-number-processors: \"%(gamess-number-processors)s\"\n        gamess-memory: \"%(gamess-memory)s\"\n        gamess-gpus: \"%(gamess-gpus)s\"\n        backend: \"%(backend)s\"\n    - target: <parse-gamess>\n      args:\n        gamess-working-directory: \"<optimise>:ref\"\n        backend: \"%(backend)s\"\n\ncomponents:\n- signature:\n    name: geometry-optimisation\n    parameters:\n    - name: molecule\n    - name: gamess-number-processors\n      default: 1\n    - name: gamess-memory\n      default: \"4096Mi\"\n    - name: backend\n      default: docker\n    - name: gamess-image\n      default: nvcr.io/hpc/gamess:17.09-r2-libcchem\n    - name: docker-platform\n      default: \"linux/amd64\"\n    - name: gamess-gpus\n      default: 0\n  command:\n    arguments: \"%(molecule)s %(gamess-number-processors)s\"\n    environment:\n      PATH: /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n    executable: bin/run-gamess.sh\n  workflowAttributes:\n    restartHookFile: semi_empirical_restart.py\n    restartHookOn:\n    - KnownIssue\n    - Success\n    - ResourceExhausted\n    shutdownOn:\n    - KnownIssue\n    - ResourceExhausted\n  resourceManager:\n    config:\n      backend: '%(backend)s'\n      # in minutes - only applies to Kubernetes runs\n      walltime: 600\n    docker:\n      image: \"%(gamess-image)s\"\n      platform: \"%(docker-platform)s\"\n    kubernetes:\n      image: \"%(gamess-image)s\"\n  resourceRequest:\n    memory: '%(gamess-memory)s'\n    numberThreads: '%(gamess-number-processors)s'\n    threadsPerCore: 1\n    gpus: '%(gamess-gpus)s'\n\n- signature:\n    name: extract-energies\n    parameters:\n    - name: gamess-working-directory\n    - name: backend\n    - name: docker-platform\n      default: \"linux/amd64\"\n  command:\n    arguments: \"%(gamess-working-directory)s\"\n    executable: bin/extract_gmsout.py\n  resourceManager:\n    config:\n      backend: '%(backend)s'\n    kubernetes:\n      image: quay.io/st4sd/community-applications/rdkit-st4sd:2019.09.1\n    docker:\n      image: quay.io/st4sd/community-applications/rdkit-st4sd:2019.09.1\n      platform: \"%(docker-platform)s\"\n```\n\nYou should now have the following file structure:\n\n```\ngamess-us-pm3.package\n├── bin\n│   ├── extract_gmsout.py\n│   └── run-gamess.sh\n├── conf\n│   └── dsl.yaml\n└── hooks\n    └── semi_empirical_restart.py\n```\n\n### Exercise\n\nTry starting your experiment now using a container runtime.\n\nIn the parent directory of **gamess-us-pm3.package** create your input **molecule.inp** file.\n\nYou can use this:\n\n```\n $CONTRL COORD=UNIQUE SCFTYP=RHF RUNTYP=OPTIMIZE MULT=1\n ISPHER=1 ICHARG=0 MAXIT=100 $END\n $SYSTEM MWORDS=100 TIMLIM=600 $END\n $BASIS GBASIS=PM3 $END\n $GUESS GUESS=HUCKEL $END\n $SCF DIRSCF=.t. FDIFF=.f. DIIS=.t. $END\n $STATPT NSTEP=500 PROJCT=.f. IHREP=20 HSSEND=.t. $END\n $DATA\nCH4 C CH4\n C1\n C 6.0 0.0 0.0 0.0\n H 1.0 0.1895 0.9552 -0.4946\n H 1.0 0.9509 -0.4809 0.2396\n H 1.0 -0.5631 0.1717 0.92\n H 1.0 -0.5773 -0.6461 -0.665\n $END\n```\n\n<InlineNotification kind=\"info\">\n\nTo use your own GAMESS US input file, carefully review the configuration options preceding the `$DATA` section and include them in your file. Additionally, ensure that your input is saved in a file named **molecule.inp**.\n\n</InlineNotification>\n\n\nYou should now have this structure:\n\n```\n.\n├── molecule.inp\n└── gamess-us-pm3.package\n    ├── bin\n    │   └── run-gamess.sh\n    │   └── extract_gmsout.py\n    ├── conf\n    │   └── dsl.yaml\n    └── hooks\n        └── semi_empirical_restart.py\n```\n\nThe command to launch the experiment is:\n\n```\n$ elaunch.py -l40 --nostamp -i molecule.inp gamess-us-pm3.package\n```\n\nAfter a couple of minutes you should see:\n\n```\ncompleted-on=2025-03-24 15:44:58.212321\ncost=0\ncreated-on=2025-03-24 15:44:34.036279\ncurrent-stage=stage0\nexit-status=Success\nexperiment-state=finished\nstage-progress=1.0\nstage-state=finished\nstages=['stage0']\ntotal-progress=1.0\nupdated=2025-03-24 15:45:00.865704\nupdated-on=2025-03-24 15:45:00.865704\n```\n\nThe **gamess-us-pm3.instance** directory will have the following structure:\n\n```\ngamess-us-pm3.instance\n├── bin\n│   ├── extract_gmsout.py\n│   └── run-gamess.sh\n├── conf\n│   ├── dsl.yaml\n│   ├── flowir_instance.yaml\n│   ├── flowir_package.yaml\n│   └── manifest.yaml\n├── elaunch.yaml\n├── hooks\n│   ├── __pycache__\n│   │   └── semi_empirical_restart.cpython-310.pyc\n│   └── semi_empirical_restart.py\n├── input\n│   └── molecule.inp\n├── output\n│   ├── experiment.log\n│   ├── output.json\n│   ├── output.txt\n│   ├── status.txt\n│   └── status_details.json\n├── python\n├── stages\n│   └── stage0\n│       ├── optimise\n│       │   ├── Run1\n│       │   │   ├── component_performance.csv\n│       │   │   ├── molecule.dat\n│       │   │   ├── molecule.inp\n│       │   │   ├── molecule.rst\n│       │   │   ├── out.stderr\n│       │   │   └── out.stdout\n│       │   ├── component_performance.csv\n│       │   ├── molecule.dat\n│       │   ├── molecule.inp\n│       │   ├── molecule.rst\n│       │   ├── out.stderr\n│       │   └── out.stdout\n│       └── parse-gamess\n│           ├── component_performance.csv\n│           ├── csv2inp.log\n│           ├── energies.csv\n│           ├── out.stderr\n│           └── out.stdout\n└── status.db\n\n```\n\n\nExamine the files under **stages/stage0/optimise** and **stages/stage0/parse-gamess**.\n\nThese were the contents of **stages/stage0/parse-gamess/energies.csv** for the experiment we ran on our laptop:\n\n```\nlabel,completed,total-energy,homo,lumo,gap,electric-moments,total-time,total-time-per-core\nmolecule,OK,-180.53313527498008,-13.641,4.245,17.886,0.000050,0.1,0.10\n```\n\n\n\n## What's next?\n\n- Learn more about writing experiments, including more advanced features and best practice [here](/write-more-experiments)\n- Learn how to add [key-outputs and interfaces](/add-interface-to-experiments) to your experiments\n- More information on running experiments directly, i.e. via `elaunch.py` [here](/direct-run)\n- More information on the DSL of ST4SD i.e. how to write experiments [here](/workflow-specification-dsl)\n- More information on how to structure and test your experiments [here](/packaging-workflows/)\n\n","fileAbsolutePath":"/home/travis/build/st4sd/overview/src/pages/write-experiments.mdx"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}