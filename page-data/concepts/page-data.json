{"componentChunkName":"component---src-pages-concepts-md","path":"/concepts/","result":{"pageContext":{"frontmatter":{"title":"Concepts"},"relativePagePath":"/concepts.md","titleType":"page","MdxNode":{"id":"39ef5e21-9ca8-5b0d-a223-8b155c600eb5","children":[],"parent":"0850edc1-51f5-5455-960c-2b4878e05964","internal":{"content":"---\ntitle: Concepts\n---\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nUse this page to learn about key ST4SD concepts and terminology.\n\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Terminology</AnchorLink>\n  <AnchorLink>Virtual Experiment Inputs</AnchorLink>\n  <AnchorLink>Virtual Experiment Outputs</AnchorLink>\n</AnchorLinks>\n\n## Overview      \n\n<ImageCard\n  href=\"/\"\n  title=\"How researchers and developers interact with ST4SD\"\n  aspectRatio=\"16:9\"\n  disabled\n  >\n\n![concepts](../assets/images/concepts/io-concepts.jpg)\n</ImageCard>\n\n## Terminology\n\n* **Virtual Experiment**: A virtual experiment (sometimes shortened to _experiment_ or _VE_) is an application workflow which measures one or more characteristics of one or more input systems. Typically created by developers, they are defined by a configuration file and additional data they need to function e.g. scripts, configuration files.\n* **Parameterised Virtual Experiment Package**: A Parameterised Virtual Experiment Package (also _parameterised package_ or _PVEP_) is a virtual experiment that has been pre-configured to perform a specific measurement. Researchers select and launch Parameterised Virtual Experiment Packages defined by Developers.\n* **Virtual Experiment Instance**: A Virtual Experiment Instance (also _instance_ or _experiment instance_) is an execution of a particular virtual experiment, usually run via a PVEP.\n* **Project**: A project is a directory structure used by developers to contain the definition of one or more virtual experiments. \n* **Direct Execution**: A Direct Execution refers to a virtual experiment run via the `elaunch.py` tool from the terminal of the machine the user is logged into e.g. a laptop or a HPC cluster.\n* **REST API Execution**: A REST API Execution refers to a virtual experiment run on a (remote) Kubernetes/OpenShift cluster via the `st4sd-runtime-service` REST API (this is often is done via a Jupyter Notebook). \n\n## Virtual Experiment Inputs \n\n\nThere are four ways to provide data to a virtual experiment. Only one - [inputs](#inputs) - is required. \n\n<AnchorLinks small>\n  <AnchorLink>Inputs</AnchorLink>\n  <AnchorLink>Data</AnchorLink>\n  <AnchorLink>Variables</AnchorLink>\n  <AnchorLink>Dependencies</AnchorLink>\n</AnchorLinks>\n\n### `inputs`\n\nInputs are files that the experiment **requires** to run. Usually they contain the information on what the experiment is measuring. \n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\nTo find out what `inputs` an experiment requires check the experiment's documentation. \n\n#### REST API Execution \n\nWhen running using the REST APIs you provide the `input` files via the experiment payload. You can directly provide the content in the payload or provide a reference to an S3 bucket containing the files. \n     \n\n​     \n\n\nSee [specifying experiment inputs](/running-workflows-on-openshift#specifying-experiment-inputs) and the [example notebooks](https://github.com/st4sd/st4sd-examples/)\n\n#### Direct Execution \n\nWhen running directly `input` files are specified via the `-i` argument to `elaunch.py`\n\n</Tab>\n\n<Tab label=\"Developers\">\n\n`inputs` are any files you reference in your virtual experiment configuration using the directory `input/` e.g. `input/somefile:ref`.\n\n​     \n\nSee [specifying input files](/tutorial#input-files) for more information.\n\n​     \n\nYou can see these files by running `einputs.py` on your experiment. \n\n​     \n\n\n</Tab>\n\n</Tabs>\n\n### `data`\n\n`data` refers to configuration files that the experiment uses during runs. These can be optionally overridden but defaults always exist.\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou provide content for `data` files via the experiment payload. You can directly provide the content in the payload or provide a reference to an S3 bucket containing the files.  You can only do this for experiment packages whose parameterisation allows it.\n\n​    \n\nSee [specifying experiment data](/running-workflows-on-openshift#specifying-experiment-data) and the [example notebooks](https://github.com/st4sd/st4sd-examples/)\n\n#### Direct Execution\n\nWhen running directly, you specify data files via the `-d` argument to `elaunch.py`\n\n</Tab>\n\n<Tab label=\"Developers\">\n\n`data` is any file you reference in your experiment using the directory `data/` e.g. `data/someconfigurationtemplate.txt:ref`.\n\n​\t\t\n\nSee [specifying data files](/tutorial#data-files) for more information.\n\n​\t\t\n\nYou can see these files by running `einputs.py` on your experiment.  \n\n</Tab>\n\n</Tabs>\n\n### `variables`\n\n`variables` are non-file parameters a virtual experiment defines. These can be optionally overridden but defaults always exist.\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou provide values for variables as part of the experiment payload. You can only do this for experiment packages whose parameterisation allows it.\n\n​    \n\nSee [specifying experiment variables](/running-workflows-on-openshift#specifying-experiment-variables) and the [example notebooks](https://github.com/st4sd/st4sd-examples/)\n\n#### Direct Execution\n\nWhen running directly, you provide variables by supplying a correctly formatted YAML file to the `-a` argument to `elaunch.py`\n\n</Tab>\n\n<Tab label=\"Developers\">\n\nYou define variables in the `variables` section of the experiment configuration. \n\n​\t\t\n\n\nSee [specifying variables](/tutorial#variables) for more information.\nAlso see [variables](/workflow-specification#variables) for the specification syntax. \n\n​\t\t\n\nYou can see the defined variables by running `einputs.py` on your experiment.  \n\n</Tab>\n\n</Tabs>\n\n### `dependencies `\n\n`dependencies` are external directories that the experiment requires to run c.f. `input` and `data` are files or archives\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou provide`dependencies` information via the experiment payload. The dependencies are passed by reference i.e. you give the location of the dependencies. \n\n​     \n\nSee [providing external directories to experiments](/packaging-workflows#providing-external-data-to-experiments) for details.  \n\n#### Direct Execution \n\nWhen running directly, you specify dependencies using the `-s` option to `elaunch.py`.  \n\n</Tab>\n\n<Tab label=\"Developers\">\n\n`dependencies` are directories you reference in your experiment configuration that are listed under `application-dependencies` key. These directories are populated at runtime based either (a)  the manifest written for the experiment OR by (b) a user supplying one at runtime. \n\n\n​     \n\nSee [providing external directories to experiments](/packaging-workflows#providing-external-data-to-experiments) for details\n\n</Tab>\n\n</Tabs>\n\n## Virtual Experiment Outputs\n\nVirtual experiments can produce many output files of various sizes and importance.  \n\n<AnchorLinks small>\n  <AnchorLink>Key Outputs</AnchorLink>\n  <AnchorLink>Properties</AnchorLink>\n  <AnchorLink>Other Outputs</AnchorLink>\n</AnchorLinks>\n\n### Key Outputs\n\nKey outputs are files/directories produced by the virtual experiment that the developer has identified as being of particular interest. Since the filenames may themselves be meaningless the developer gives them unique identifiers\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou can query and retrieve the key-outputs of a virtual experiment instance using the ST4SD API. \nSee [Retrieving key-outputs](/running-workflows-on-openshift/#retrieving-key-outputs) for more details.\n\n​    \n\n**[Coming Soon]**: The key-outputs will be listed in Registry UI entry for each parameterized virtual experiment package based on the experiment. \n\n​    \n\nYou can instruct ST4SD to copy the key-outputs of an instance to an S3 bucket when the instance has finished. See [Automatically uploading key-outputs to S3](/running-workflows-on-openshift/#automatically-uploading-key-outputs-to-s3).\n\n#### **Direct Execution **\n\nMetadata describing key-outputs will be in the `output` directory in the top level of your experiment instance directory in the file `outputs.json` file. \n\nIn addition, users may also request key-outputs be copied to an external location when an experiment instance finishes.\nYou can do this by setting the `--s3StoreToURI` and `--s3AuthWithEnvVars` (or `--s3AuthBearer64=S3AUTHBEARER64`) arguments to `elaunch.py`.\n\nSee the [documentation for direct runs](/direct-run) for more information.\n\n</Tab>\n\n<Tab label=\"Developers\">\n\nYou define key-outputs in the [\"output\" section of the experiment configuration](/workflow-specification#key-outputs).\n\n​    \n\nST4SD will record metadata about the key-outputs of your experiment instance, including their location and the timestamp they were last produced.\n\n​    \n\nIn addition, users may also request key-outputs be copied to an external location when an experiment instance finishes. *Developers do not have to do anything to enable this.* \n\n\n</Tab>\n\n</Tabs>\n\n### Properties\n\nWhen an experiment has a virtual experiment interface defined, property tables are also produced.\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou can see the properties provided by a parameterized virtual package by checking the experiment registry. You can access these properties using the ST4SD API. \n\nSee [using virtual experiment interfaces](/using-a-virtual-experiment-interface) for more details. \n\n#### Direct Execution \n\nThe property tables (csv files) defined by the interface are available at in the `output` folder in the top-level of the experiment instance directory in the file `properties.csv`\n\n</Tab>\n\n<Tab label=\"Developers\">\n\nYou define the properties of your virtual experiment by defining a [virtual experiment interface](/writing-a-virtual-experiment-interface). \n\n</Tab>\n\n</Tabs>\n\n### Other Outputs\n\nAll other output files produced during an experiment run can be retrieved. \n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution\n\nYou can [retrieve any output file](/running-workflows-on-openshift/#retrieving-outputs-via-the-st4sd-datastore-apis) of a virtual experiment instance using the ST4SD API\n\n​     \n\nIf you have access to the cluster hosting the ST4SD you are using you can also [browse the outputs via a terminal](/running-ve-via-terminal/#examining-a-components-output-directory).\n\n#### Direct Execution \n\nThe experiment instance directory contains all the outputs of all steps and can be easily explored via the terminal. \n\n</Tab>\n\n<Tab label=\"Developers\">\n\nAll the outputs of an instance of a virtual experiment are available automatically via the ST4SD API. *Developers don't have to do anything to enable this.*\n\n</Tab>\n\n</Tabs>\n\n\n\n","type":"Mdx","contentDigest":"d8b082266098f5cd67460eceb6ab093e","owner":"gatsby-plugin-mdx","counter":253},"frontmatter":{"title":"Concepts"},"exports":{},"rawBody":"---\ntitle: Concepts\n---\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nUse this page to learn about key ST4SD concepts and terminology.\n\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Terminology</AnchorLink>\n  <AnchorLink>Virtual Experiment Inputs</AnchorLink>\n  <AnchorLink>Virtual Experiment Outputs</AnchorLink>\n</AnchorLinks>\n\n## Overview      \n\n<ImageCard\n  href=\"/\"\n  title=\"How researchers and developers interact with ST4SD\"\n  aspectRatio=\"16:9\"\n  disabled\n  >\n\n![concepts](../assets/images/concepts/io-concepts.jpg)\n</ImageCard>\n\n## Terminology\n\n* **Virtual Experiment**: A virtual experiment (sometimes shortened to _experiment_ or _VE_) is an application workflow which measures one or more characteristics of one or more input systems. Typically created by developers, they are defined by a configuration file and additional data they need to function e.g. scripts, configuration files.\n* **Parameterised Virtual Experiment Package**: A Parameterised Virtual Experiment Package (also _parameterised package_ or _PVEP_) is a virtual experiment that has been pre-configured to perform a specific measurement. Researchers select and launch Parameterised Virtual Experiment Packages defined by Developers.\n* **Virtual Experiment Instance**: A Virtual Experiment Instance (also _instance_ or _experiment instance_) is an execution of a particular virtual experiment, usually run via a PVEP.\n* **Project**: A project is a directory structure used by developers to contain the definition of one or more virtual experiments. \n* **Direct Execution**: A Direct Execution refers to a virtual experiment run via the `elaunch.py` tool from the terminal of the machine the user is logged into e.g. a laptop or a HPC cluster.\n* **REST API Execution**: A REST API Execution refers to a virtual experiment run on a (remote) Kubernetes/OpenShift cluster via the `st4sd-runtime-service` REST API (this is often is done via a Jupyter Notebook). \n\n## Virtual Experiment Inputs \n\n\nThere are four ways to provide data to a virtual experiment. Only one - [inputs](#inputs) - is required. \n\n<AnchorLinks small>\n  <AnchorLink>Inputs</AnchorLink>\n  <AnchorLink>Data</AnchorLink>\n  <AnchorLink>Variables</AnchorLink>\n  <AnchorLink>Dependencies</AnchorLink>\n</AnchorLinks>\n\n### `inputs`\n\nInputs are files that the experiment **requires** to run. Usually they contain the information on what the experiment is measuring. \n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\nTo find out what `inputs` an experiment requires check the experiment's documentation. \n\n#### REST API Execution \n\nWhen running using the REST APIs you provide the `input` files via the experiment payload. You can directly provide the content in the payload or provide a reference to an S3 bucket containing the files. \n     \n\n​     \n\n\nSee [specifying experiment inputs](/running-workflows-on-openshift#specifying-experiment-inputs) and the [example notebooks](https://github.com/st4sd/st4sd-examples/)\n\n#### Direct Execution \n\nWhen running directly `input` files are specified via the `-i` argument to `elaunch.py`\n\n</Tab>\n\n<Tab label=\"Developers\">\n\n`inputs` are any files you reference in your virtual experiment configuration using the directory `input/` e.g. `input/somefile:ref`.\n\n​     \n\nSee [specifying input files](/tutorial#input-files) for more information.\n\n​     \n\nYou can see these files by running `einputs.py` on your experiment. \n\n​     \n\n\n</Tab>\n\n</Tabs>\n\n### `data`\n\n`data` refers to configuration files that the experiment uses during runs. These can be optionally overridden but defaults always exist.\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou provide content for `data` files via the experiment payload. You can directly provide the content in the payload or provide a reference to an S3 bucket containing the files.  You can only do this for experiment packages whose parameterisation allows it.\n\n​    \n\nSee [specifying experiment data](/running-workflows-on-openshift#specifying-experiment-data) and the [example notebooks](https://github.com/st4sd/st4sd-examples/)\n\n#### Direct Execution\n\nWhen running directly, you specify data files via the `-d` argument to `elaunch.py`\n\n</Tab>\n\n<Tab label=\"Developers\">\n\n`data` is any file you reference in your experiment using the directory `data/` e.g. `data/someconfigurationtemplate.txt:ref`.\n\n​\t\t\n\nSee [specifying data files](/tutorial#data-files) for more information.\n\n​\t\t\n\nYou can see these files by running `einputs.py` on your experiment.  \n\n</Tab>\n\n</Tabs>\n\n### `variables`\n\n`variables` are non-file parameters a virtual experiment defines. These can be optionally overridden but defaults always exist.\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou provide values for variables as part of the experiment payload. You can only do this for experiment packages whose parameterisation allows it.\n\n​    \n\nSee [specifying experiment variables](/running-workflows-on-openshift#specifying-experiment-variables) and the [example notebooks](https://github.com/st4sd/st4sd-examples/)\n\n#### Direct Execution\n\nWhen running directly, you provide variables by supplying a correctly formatted YAML file to the `-a` argument to `elaunch.py`\n\n</Tab>\n\n<Tab label=\"Developers\">\n\nYou define variables in the `variables` section of the experiment configuration. \n\n​\t\t\n\n\nSee [specifying variables](/tutorial#variables) for more information.\nAlso see [variables](/workflow-specification#variables) for the specification syntax. \n\n​\t\t\n\nYou can see the defined variables by running `einputs.py` on your experiment.  \n\n</Tab>\n\n</Tabs>\n\n### `dependencies `\n\n`dependencies` are external directories that the experiment requires to run c.f. `input` and `data` are files or archives\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou provide`dependencies` information via the experiment payload. The dependencies are passed by reference i.e. you give the location of the dependencies. \n\n​     \n\nSee [providing external directories to experiments](/packaging-workflows#providing-external-data-to-experiments) for details.  \n\n#### Direct Execution \n\nWhen running directly, you specify dependencies using the `-s` option to `elaunch.py`.  \n\n</Tab>\n\n<Tab label=\"Developers\">\n\n`dependencies` are directories you reference in your experiment configuration that are listed under `application-dependencies` key. These directories are populated at runtime based either (a)  the manifest written for the experiment OR by (b) a user supplying one at runtime. \n\n\n​     \n\nSee [providing external directories to experiments](/packaging-workflows#providing-external-data-to-experiments) for details\n\n</Tab>\n\n</Tabs>\n\n## Virtual Experiment Outputs\n\nVirtual experiments can produce many output files of various sizes and importance.  \n\n<AnchorLinks small>\n  <AnchorLink>Key Outputs</AnchorLink>\n  <AnchorLink>Properties</AnchorLink>\n  <AnchorLink>Other Outputs</AnchorLink>\n</AnchorLinks>\n\n### Key Outputs\n\nKey outputs are files/directories produced by the virtual experiment that the developer has identified as being of particular interest. Since the filenames may themselves be meaningless the developer gives them unique identifiers\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou can query and retrieve the key-outputs of a virtual experiment instance using the ST4SD API. \nSee [Retrieving key-outputs](/running-workflows-on-openshift/#retrieving-key-outputs) for more details.\n\n​    \n\n**[Coming Soon]**: The key-outputs will be listed in Registry UI entry for each parameterized virtual experiment package based on the experiment. \n\n​    \n\nYou can instruct ST4SD to copy the key-outputs of an instance to an S3 bucket when the instance has finished. See [Automatically uploading key-outputs to S3](/running-workflows-on-openshift/#automatically-uploading-key-outputs-to-s3).\n\n#### **Direct Execution **\n\nMetadata describing key-outputs will be in the `output` directory in the top level of your experiment instance directory in the file `outputs.json` file. \n\nIn addition, users may also request key-outputs be copied to an external location when an experiment instance finishes.\nYou can do this by setting the `--s3StoreToURI` and `--s3AuthWithEnvVars` (or `--s3AuthBearer64=S3AUTHBEARER64`) arguments to `elaunch.py`.\n\nSee the [documentation for direct runs](/direct-run) for more information.\n\n</Tab>\n\n<Tab label=\"Developers\">\n\nYou define key-outputs in the [\"output\" section of the experiment configuration](/workflow-specification#key-outputs).\n\n​    \n\nST4SD will record metadata about the key-outputs of your experiment instance, including their location and the timestamp they were last produced.\n\n​    \n\nIn addition, users may also request key-outputs be copied to an external location when an experiment instance finishes. *Developers do not have to do anything to enable this.* \n\n\n</Tab>\n\n</Tabs>\n\n### Properties\n\nWhen an experiment has a virtual experiment interface defined, property tables are also produced.\n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution \n\nYou can see the properties provided by a parameterized virtual package by checking the experiment registry. You can access these properties using the ST4SD API. \n\nSee [using virtual experiment interfaces](/using-a-virtual-experiment-interface) for more details. \n\n#### Direct Execution \n\nThe property tables (csv files) defined by the interface are available at in the `output` folder in the top-level of the experiment instance directory in the file `properties.csv`\n\n</Tab>\n\n<Tab label=\"Developers\">\n\nYou define the properties of your virtual experiment by defining a [virtual experiment interface](/writing-a-virtual-experiment-interface). \n\n</Tab>\n\n</Tabs>\n\n### Other Outputs\n\nAll other output files produced during an experiment run can be retrieved. \n\n<Tabs>\n\n<Tab label=\"Researchers\">\n\n#### REST API Execution\n\nYou can [retrieve any output file](/running-workflows-on-openshift/#retrieving-outputs-via-the-st4sd-datastore-apis) of a virtual experiment instance using the ST4SD API\n\n​     \n\nIf you have access to the cluster hosting the ST4SD you are using you can also [browse the outputs via a terminal](/running-ve-via-terminal/#examining-a-components-output-directory).\n\n#### Direct Execution \n\nThe experiment instance directory contains all the outputs of all steps and can be easily explored via the terminal. \n\n</Tab>\n\n<Tab label=\"Developers\">\n\nAll the outputs of an instance of a virtual experiment are available automatically via the ST4SD API. *Developers don't have to do anything to enable this.*\n\n</Tab>\n\n</Tabs>\n\n\n\n","fileAbsolutePath":"/home/travis/build/st4sd/overview/src/pages/concepts.md"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}