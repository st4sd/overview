{"componentChunkName":"component---src-pages-workflow-specification-dsl-mdx","path":"/workflow-specification-dsl/","result":{"pageContext":{"frontmatter":{"title":"Workflow Specification 2.0"},"relativePagePath":"/workflow-specification-dsl.mdx","titleType":"page","MdxNode":{"id":"539ee079-e5d4-5b79-bca7-6a8c3ec03fda","children":[],"parent":"28e64c8c-1b2e-58e9-9b28-24244775469f","internal":{"content":"---\ntitle: Workflow Specification 2.0\n---\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nUse this page to learn about the new Domain Specific Language (DSL 2.0) of ST4SD and how it works.\n\n</PageDescription>\n\n<AnchorLinks>\n    <AnchorLink>Namespace</AnchorLink>\n    <AnchorLink>Entrypoint</AnchorLink>\n    <AnchorLink>Workflow</AnchorLink>\n    <AnchorLink>Component</AnchorLink>\n    <AnchorLink>Assigning values to parameters</AnchorLink>\n    <AnchorLink>OutputReference</AnchorLink>\n    <AnchorLink>Example</AnchorLink>\n    <AnchorLink>Differences between DSL 2.0 and FlowIR</AnchorLink>\n</AnchorLinks>\n\nDSL 2.0 is the new (and beta) way to define the computational graphs of ST4SD workflows.\n\n## Namespace\n\nIn DSL 2.0, a Computational Graph consists of Components which can be grouped under Workflow containers. \nIt also has an Entrypoint which points to the root node of the graph, which is an instance of a Component or Workflow template.\n\nA Namespace is simply a container for the Component, Workflow, and Entrypoint definitions which represent the Computational Graph of one ST4SD workflow. \n\nBelow is an example of a Namespace containing a single component that prints the message `Hello world` to the terminal.\n\n```yaml\nentrypoint:\n  entry-instance: print\n  execute:\n  - target: \"<entry-instance>\"\n    args:\n      message: Hello world\ncomponents:\n- signature:\n    name: print\n    parameters:\n      name: message\n  command:\n    executable: echo\n    arguments: \"%(message)s\"\n```\n\n## Entrypoint\n\nThe Optional Entrypoint serves a single purpose. Describe how to execute root Template instance of the Computational Graph.\n\nIts schema is:\n\n```yaml\n# This executes an instance of $template which is called \"<entry-instance>\"\nentry-instance: $template # name of a Component or Workflow template\nexecute: # an array with exactly 1 entry\n- target: <entry-instance> # which instance of a Template to execute.\n                           # In this scope there is only <entry-instance>\n  args:\n    $paramName: $value # one for each parameter of the template that\n                       # the \"target\" points to\n```\n\nThe `entry-instance` field receives the name of a Template and creates an instance of it called `<entry-instance>`.\nThe `execute` field then describes how to \"execute\" the `<entry-instance>` i.e. how to populate the arguments of the associated Template.\n\nIn `execute[].args` you:\n\n* **must** provide values for any parameters in the child `$template` which do not have default values\n* **may** override the value of the parameters in `$template` which have default values\n\nThe Template instance that the entrypoint points to can have special parameters which are data references to paths that are external to the workflow.\nThese parameters must be called `input.$filename` and they must not have default values in the signature of the Template definition.\nThe entrypoint **may** not explicitly override the values of said parameters, the runtime system will auto-generate them.\n\nConsider a scenario where the Template that the `<entry-instance>` step points to has a parameter called `input.my-input.db`. \nThe runtime will post-process the `entrypoint.execute[0].args` dictionary to include the following key-value pair:\n\n```yaml\ninput.my-input.db: \"input/my-input.db\"\n```\n\nIn [Assigning values to parameters](#assigning-values-to-parameters) we describe in more detail how to assign values to parameters of Template instances in general.\n\n\n## Workflow\n\nA Workflow is a Template that describes how to `execute` a number of Template instances called `steps`.\nIt has a `signature` that consists of a unique `name` and a `parameter` list. \nEach such step can consume the outputs of a sibling step, or the parameters of the parent Workflow.\n\nThe outputs of a workflow are its `steps`. The schema of Workflow is:\n\n```yaml\nsignature:\n  name: $Template # the name of this Workflow Template - must be unique\n  parameters:\n    - name: $paramName\n      # optional default value\n      default: $value # str, number, or dictionary of {str: str/number}\nsteps: # which steps to instantiate\n  $stepName: $Template # for example child: simulation-code\nexecute: # how to execute the steps - one for each entry of steps\n- target: <$stepName> # for example <child> or <child/grandchild>\n  args:\n    $paramName: $value # one for each parameter of the Template that\n                       # .target points to\n```\n\nIn [Assigning values to parameters](#assigning-values-to-parameters) we describe how to assign values to parameters of Template instances.\n\n## Component\n\nA Component describes how to `execute` a task.\nJust like a Workflow Template, it has a `signature` that consists of a `name` and a `parameter` list. \n\nThe outputs of a Component are the paths under its working directory. \n\nThe schema of a Component is:\n\n```yaml\nsignature:\n  name: $Template # the name of this Component Template - must be unique\n  parameters:\n    - name: $paramName\n      # optional default value\n      default: $value # str, number, or dictionary of {str: str/number}\n# All the FlowIR fields, except for stage, name, references, and override\ncommand:\n  executable: str\n  arguments: str\n  environment: (null, str)\nworkflowAttributes:\n  aggregate: bool\n  replicate: (int, null, str containing %(value-reference)s)\nresourceRequest:\n  numberProcesses: (int, str containing %(value-reference)s)\n  numberThreads: (int, str containing %(value-reference)s)\n  ranksPerNode: (int, str containing %(value-reference)s)\n  threadsPerCore: (int, str containing %(value-reference)s)\n  memory: (int (size in bytes), str containing %(value-reference)s or Mib/Kib bytes )\n  gpus: (int, str containing %(value-reference)s)\nresourceManager:\n  config:\n    backend: (name of backend e.g local, kubernetes, lsf, docker)\n    walltime: (in minutes, valid for \"kubernetes\" and \"lsf\" backends, float)\n  docker:\n    image: str\n    imagePullPolicy: (Optional) one of Always (default), Never, IfNotPresent\n  kubernetes:\n    image: str\n  lsf:\n    queue: str\nvariables:\n  <variable name:str>: <value: str, int, bool, float>\n```\n\nThe above fields are the same as those in the [Component section of the Workflow Specification in FlowIR](/workflow-specification/#component).\n\nFor more information, read our documentation on the [basic FlowIR component fields](/workflow-specification#description-of-basic-flowir-component-fields).\n\n## Assigning values to parameters\n\nBoth Component and Workflow templates are instantiated in the same way: \nby declaring them as a `step` and adding an entry to an `execute` block which assigns values to the Template's parameters.\n\nThe value of a parameter can be a number, string, or a key: value dictionary. \nThe body of a Template can reference its parameters like so `%(parameterName)s`.\n\nWhen assigning a value to the parameters of a template via the `execute[].args` dictionary\n\nIn `execute[].args` you:\n\n* **must** provide values for any parameters in the child `$template` which do not have default values\n* **may** override the value of the parameters in `$template` which have default values\n* **may** use `OutputReferences` to indicate dependencies to steps (definition follows this bullet list)\n* **may** use `%(parentParameter)s` to indicate a dependency to the value that the parent parameter has. In turn that can be a dependency to the output of a Template instance or an input file or it might just be a literal constant\n* **may** use a `$key: $value` dictionary to propagate a dictionary-type value. At the moment Template can only reference this kind of parameters to set the value of the `command.environment` field of Components\n* **may** use `%(input.$filename)s`to propagate an input file reference from a parent to a step. \n  - Eventually a step must apply a [DataReferences](/workflow-specification/#datareference) `:$method` to the parameter to indicates it wishes to consume the input file\n\nWanna find out more? Check out our [example](#example).\n\n### OutputReference\n\nThe format of an `OutputReference` is:\n\n```\n<$stepId>/$optionalPath:$optionalMethod\n```\n\n`$stepId` is a `/` separated array of `stepNames` starting from the scope of the current workflow. For example, the OutputReference `<one/child>/file.txt:ref` resolves to the absolute path of the file `file.txt` that the component `child` produces under the sibling step `one` which is an instance of a Workflow template. You can find more reference `methods` in our [DataReferences](/workflow-specification/#datareference) docs.\n\n\n\n\n# Example\n\nHere is a simple example which uses one Workflow and one Component template two run 2 tasks.\n\n- consume-input: prints the contents of an input file called `my-input.db`\n- consume-sibling: prints the text \"my sibling said\" followed by stdout of the sibling step `<consume-input>` \n\n```yaml\nentrypoint:\n  entry-instance: main\n  execute:\n  - target: <entry-instance>\nworkflows:\n- signature:\n    name: main\n    parameters:\n    # special variable with auto-populated value\n    - name: input.my-input.db\n  steps:\n    consume-input: echo\n    consume-sibling: echo\n  execute:\n    - target: <consume-input>\n      args:\n        # resolves to the contents of the file \n        # that input.my-input-d points to\n        message: \"%(input.my-input.db)s:output\"\n    - target: <consume-sibling>\n      args:\n        # resolves to the stdout of step consume-input\n        message: \"my sibling said <consume-input>:output\"\ncomponents:\n- signature:\n    name: echo\n    parameters:\n      - name: message\n  command:\n    executable: \"echo\"\n    arguments: \"%(message)s\"\n```\n\n\nTo try it out, store the above DSL in a file called `dsl-params.yaml` and run\n\n```\npip install \"st4sd-runtime-core[develop]\"\n```\n\nwhich installs the command-line-tool elaunch.py, followed by:\n\n```bash\necho \"hello world\" >my-input.db\nelaunch.py -i my-input.db --failSafeDelays=no -l40 dsl-params.yaml\n```\n\n\n## Differences between DSL 2.0 and FlowIR\n\nThere are some differences between DSL 2.0 and [FlowIR](/workflow-specification).\n\nIn the current version (0.1.x) of DSL 2.0:\n\n* we offer support for natural composition of Computational Graphs using Workflow and Component templates\n* the `signature` field replaces the `stage`, `name`, `references`, and `override` fields of the component specification in FlowIR\n* settings and inputs flow through parameters, we do not support global/stage environments or variables\n* the fields of components can only contain `%(parameter)s` references, in the future we are adding support for references to the component `%(variable)s` too\n* dependencies between components are defined by referencing the output of a producer component in one parameter of the consumer component - [DataReferences](/workflow-specification/#datareference) are reserved for referencing input files only\n    * the equivalent of a DataReference for Template instances is an OutputReference\n\nDSL 2.0 will eventually contain a superset of the FlowIR features. However, the current beta version of DSL 2.0 does not support:\n\n* using variables in the body of a component template\n* FlowIR platforms\n* defining Key Outputs or Interface and Property extraction methods\n* application-dependencies, data files, and manifests\n","type":"Mdx","contentDigest":"5832c2a667365d8e4aa66e5f4c3cb2d3","owner":"gatsby-plugin-mdx","counter":270},"frontmatter":{"title":"Workflow Specification 2.0"},"exports":{},"rawBody":"---\ntitle: Workflow Specification 2.0\n---\n\n<!--\n\n  Copyright IBM Inc. All Rights Reserved.\n  SPDX-License-Identifier: Apache-2.0\n\n-->\n\n<PageDescription>\n\nUse this page to learn about the new Domain Specific Language (DSL 2.0) of ST4SD and how it works.\n\n</PageDescription>\n\n<AnchorLinks>\n    <AnchorLink>Namespace</AnchorLink>\n    <AnchorLink>Entrypoint</AnchorLink>\n    <AnchorLink>Workflow</AnchorLink>\n    <AnchorLink>Component</AnchorLink>\n    <AnchorLink>Assigning values to parameters</AnchorLink>\n    <AnchorLink>OutputReference</AnchorLink>\n    <AnchorLink>Example</AnchorLink>\n    <AnchorLink>Differences between DSL 2.0 and FlowIR</AnchorLink>\n</AnchorLinks>\n\nDSL 2.0 is the new (and beta) way to define the computational graphs of ST4SD workflows.\n\n## Namespace\n\nIn DSL 2.0, a Computational Graph consists of Components which can be grouped under Workflow containers. \nIt also has an Entrypoint which points to the root node of the graph, which is an instance of a Component or Workflow template.\n\nA Namespace is simply a container for the Component, Workflow, and Entrypoint definitions which represent the Computational Graph of one ST4SD workflow. \n\nBelow is an example of a Namespace containing a single component that prints the message `Hello world` to the terminal.\n\n```yaml\nentrypoint:\n  entry-instance: print\n  execute:\n  - target: \"<entry-instance>\"\n    args:\n      message: Hello world\ncomponents:\n- signature:\n    name: print\n    parameters:\n      name: message\n  command:\n    executable: echo\n    arguments: \"%(message)s\"\n```\n\n## Entrypoint\n\nThe Optional Entrypoint serves a single purpose. Describe how to execute root Template instance of the Computational Graph.\n\nIts schema is:\n\n```yaml\n# This executes an instance of $template which is called \"<entry-instance>\"\nentry-instance: $template # name of a Component or Workflow template\nexecute: # an array with exactly 1 entry\n- target: <entry-instance> # which instance of a Template to execute.\n                           # In this scope there is only <entry-instance>\n  args:\n    $paramName: $value # one for each parameter of the template that\n                       # the \"target\" points to\n```\n\nThe `entry-instance` field receives the name of a Template and creates an instance of it called `<entry-instance>`.\nThe `execute` field then describes how to \"execute\" the `<entry-instance>` i.e. how to populate the arguments of the associated Template.\n\nIn `execute[].args` you:\n\n* **must** provide values for any parameters in the child `$template` which do not have default values\n* **may** override the value of the parameters in `$template` which have default values\n\nThe Template instance that the entrypoint points to can have special parameters which are data references to paths that are external to the workflow.\nThese parameters must be called `input.$filename` and they must not have default values in the signature of the Template definition.\nThe entrypoint **may** not explicitly override the values of said parameters, the runtime system will auto-generate them.\n\nConsider a scenario where the Template that the `<entry-instance>` step points to has a parameter called `input.my-input.db`. \nThe runtime will post-process the `entrypoint.execute[0].args` dictionary to include the following key-value pair:\n\n```yaml\ninput.my-input.db: \"input/my-input.db\"\n```\n\nIn [Assigning values to parameters](#assigning-values-to-parameters) we describe in more detail how to assign values to parameters of Template instances in general.\n\n\n## Workflow\n\nA Workflow is a Template that describes how to `execute` a number of Template instances called `steps`.\nIt has a `signature` that consists of a unique `name` and a `parameter` list. \nEach such step can consume the outputs of a sibling step, or the parameters of the parent Workflow.\n\nThe outputs of a workflow are its `steps`. The schema of Workflow is:\n\n```yaml\nsignature:\n  name: $Template # the name of this Workflow Template - must be unique\n  parameters:\n    - name: $paramName\n      # optional default value\n      default: $value # str, number, or dictionary of {str: str/number}\nsteps: # which steps to instantiate\n  $stepName: $Template # for example child: simulation-code\nexecute: # how to execute the steps - one for each entry of steps\n- target: <$stepName> # for example <child> or <child/grandchild>\n  args:\n    $paramName: $value # one for each parameter of the Template that\n                       # .target points to\n```\n\nIn [Assigning values to parameters](#assigning-values-to-parameters) we describe how to assign values to parameters of Template instances.\n\n## Component\n\nA Component describes how to `execute` a task.\nJust like a Workflow Template, it has a `signature` that consists of a `name` and a `parameter` list. \n\nThe outputs of a Component are the paths under its working directory. \n\nThe schema of a Component is:\n\n```yaml\nsignature:\n  name: $Template # the name of this Component Template - must be unique\n  parameters:\n    - name: $paramName\n      # optional default value\n      default: $value # str, number, or dictionary of {str: str/number}\n# All the FlowIR fields, except for stage, name, references, and override\ncommand:\n  executable: str\n  arguments: str\n  environment: (null, str)\nworkflowAttributes:\n  aggregate: bool\n  replicate: (int, null, str containing %(value-reference)s)\nresourceRequest:\n  numberProcesses: (int, str containing %(value-reference)s)\n  numberThreads: (int, str containing %(value-reference)s)\n  ranksPerNode: (int, str containing %(value-reference)s)\n  threadsPerCore: (int, str containing %(value-reference)s)\n  memory: (int (size in bytes), str containing %(value-reference)s or Mib/Kib bytes )\n  gpus: (int, str containing %(value-reference)s)\nresourceManager:\n  config:\n    backend: (name of backend e.g local, kubernetes, lsf, docker)\n    walltime: (in minutes, valid for \"kubernetes\" and \"lsf\" backends, float)\n  docker:\n    image: str\n    imagePullPolicy: (Optional) one of Always (default), Never, IfNotPresent\n  kubernetes:\n    image: str\n  lsf:\n    queue: str\nvariables:\n  <variable name:str>: <value: str, int, bool, float>\n```\n\nThe above fields are the same as those in the [Component section of the Workflow Specification in FlowIR](/workflow-specification/#component).\n\nFor more information, read our documentation on the [basic FlowIR component fields](/workflow-specification#description-of-basic-flowir-component-fields).\n\n## Assigning values to parameters\n\nBoth Component and Workflow templates are instantiated in the same way: \nby declaring them as a `step` and adding an entry to an `execute` block which assigns values to the Template's parameters.\n\nThe value of a parameter can be a number, string, or a key: value dictionary. \nThe body of a Template can reference its parameters like so `%(parameterName)s`.\n\nWhen assigning a value to the parameters of a template via the `execute[].args` dictionary\n\nIn `execute[].args` you:\n\n* **must** provide values for any parameters in the child `$template` which do not have default values\n* **may** override the value of the parameters in `$template` which have default values\n* **may** use `OutputReferences` to indicate dependencies to steps (definition follows this bullet list)\n* **may** use `%(parentParameter)s` to indicate a dependency to the value that the parent parameter has. In turn that can be a dependency to the output of a Template instance or an input file or it might just be a literal constant\n* **may** use a `$key: $value` dictionary to propagate a dictionary-type value. At the moment Template can only reference this kind of parameters to set the value of the `command.environment` field of Components\n* **may** use `%(input.$filename)s`to propagate an input file reference from a parent to a step. \n  - Eventually a step must apply a [DataReferences](/workflow-specification/#datareference) `:$method` to the parameter to indicates it wishes to consume the input file\n\nWanna find out more? Check out our [example](#example).\n\n### OutputReference\n\nThe format of an `OutputReference` is:\n\n```\n<$stepId>/$optionalPath:$optionalMethod\n```\n\n`$stepId` is a `/` separated array of `stepNames` starting from the scope of the current workflow. For example, the OutputReference `<one/child>/file.txt:ref` resolves to the absolute path of the file `file.txt` that the component `child` produces under the sibling step `one` which is an instance of a Workflow template. You can find more reference `methods` in our [DataReferences](/workflow-specification/#datareference) docs.\n\n\n\n\n# Example\n\nHere is a simple example which uses one Workflow and one Component template two run 2 tasks.\n\n- consume-input: prints the contents of an input file called `my-input.db`\n- consume-sibling: prints the text \"my sibling said\" followed by stdout of the sibling step `<consume-input>` \n\n```yaml\nentrypoint:\n  entry-instance: main\n  execute:\n  - target: <entry-instance>\nworkflows:\n- signature:\n    name: main\n    parameters:\n    # special variable with auto-populated value\n    - name: input.my-input.db\n  steps:\n    consume-input: echo\n    consume-sibling: echo\n  execute:\n    - target: <consume-input>\n      args:\n        # resolves to the contents of the file \n        # that input.my-input-d points to\n        message: \"%(input.my-input.db)s:output\"\n    - target: <consume-sibling>\n      args:\n        # resolves to the stdout of step consume-input\n        message: \"my sibling said <consume-input>:output\"\ncomponents:\n- signature:\n    name: echo\n    parameters:\n      - name: message\n  command:\n    executable: \"echo\"\n    arguments: \"%(message)s\"\n```\n\n\nTo try it out, store the above DSL in a file called `dsl-params.yaml` and run\n\n```\npip install \"st4sd-runtime-core[develop]\"\n```\n\nwhich installs the command-line-tool elaunch.py, followed by:\n\n```bash\necho \"hello world\" >my-input.db\nelaunch.py -i my-input.db --failSafeDelays=no -l40 dsl-params.yaml\n```\n\n\n## Differences between DSL 2.0 and FlowIR\n\nThere are some differences between DSL 2.0 and [FlowIR](/workflow-specification).\n\nIn the current version (0.1.x) of DSL 2.0:\n\n* we offer support for natural composition of Computational Graphs using Workflow and Component templates\n* the `signature` field replaces the `stage`, `name`, `references`, and `override` fields of the component specification in FlowIR\n* settings and inputs flow through parameters, we do not support global/stage environments or variables\n* the fields of components can only contain `%(parameter)s` references, in the future we are adding support for references to the component `%(variable)s` too\n* dependencies between components are defined by referencing the output of a producer component in one parameter of the consumer component - [DataReferences](/workflow-specification/#datareference) are reserved for referencing input files only\n    * the equivalent of a DataReference for Template instances is an OutputReference\n\nDSL 2.0 will eventually contain a superset of the FlowIR features. However, the current beta version of DSL 2.0 does not support:\n\n* using variables in the body of a component template\n* FlowIR platforms\n* defining Key Outputs or Interface and Property extraction methods\n* application-dependencies, data files, and manifests\n","fileAbsolutePath":"/home/travis/build/st4sd/overview/src/pages/workflow-specification-dsl.mdx"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}