"use strict";(self.webpackChunkst4sd_overview=self.webpackChunkst4sd_overview||[]).push([[216],{2138:function(e,n,t){t.r(n),t.d(n,{_frontmatter:function(){return l},default:function(){return c}});var a=t(45),o=(t(6540),t(5680)),i=t(8027);const r=["components"],l={},p=e=>function(n){return console.warn("Component "+e+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.yg)("div",n)},s=p("PageDescription"),u=p("AnchorLinks"),m=p("AnchorLink"),y={_frontmatter:l},h=i.A;function c(e){let{components:n}=e,t=(0,a.A)(e,r);return(0,o.yg)(h,Object.assign({},y,t,{components:n,mdxType:"MDXLayout"}),(0,o.yg)(s,{mdxType:"PageDescription"},(0,o.yg)("p",null,"This page will teach you how to run a workflow directly using the ",(0,o.yg)("inlineCode",{parentName:"p"},"elaunch.py")," command line utility.\nUsers comfortable with installing python modules and the ",(0,o.yg)("a",{parentName:"p",href:"/overview/workflow-specification"},"FlowIR")," should be able to follow this content.")),(0,o.yg)(u,{mdxType:"AnchorLinks"},(0,o.yg)(m,{mdxType:"AnchorLink"},"Prepare a virtual environment"),(0,o.yg)(m,{mdxType:"AnchorLink"},"Execute a workflow"),(0,o.yg)(m,{mdxType:"AnchorLink"},"Provide input files and override data files"),(0,o.yg)(m,{mdxType:"AnchorLink"},"Store outputs to S3")),(0,o.yg)("h2",null,"Prepare a virtual environment"),(0,o.yg)("p",null,"We recommend using a virtual environment with a modern version of python 3 (3.7+) to install ",(0,o.yg)("a",{parentName:"p",href:"/overview/st4sd-core-getting-started"},(0,o.yg)("strong",{parentName:"a"},"ST4SD Core"))," like so:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},'python3 -m venv --copies st4sd\n. ./st4sd/bin/activate\npip install "st4sd-runtime-core[develop]"\n')),(0,o.yg)("p",null,"If you are installing ST4SD on a machine that can submit tasks to ",(0,o.yg)("a",{parentName:"p",href:"https://www.ibm.com/products/hpc-workload-management"},"IBM Spectrum LSF"),"\nthen you should also install the official ",(0,o.yg)("a",{parentName:"p",href:"https://github.com/IBMSpectrumComputing/lsf-python-api"},(0,o.yg)("inlineCode",{parentName:"a"},"lsf-python-api"))," python module."),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},". /path/to/profile.lsf\ngit clone https://github.com/IBMSpectrumComputing/lsf-python-api.git\ncd lsf-python-api\npython3 setup.py build\npython3 setup.py install\n")),(0,o.yg)("p",null,"Check the homepage of ",(0,o.yg)("a",{parentName:"p",href:"https://github.com/IBMSpectrumComputing/lsf-python-api"},(0,o.yg)("inlineCode",{parentName:"a"},"lsf-python-api"))," for more information."),(0,o.yg)("p",null,"After installing the ",(0,o.yg)("inlineCode",{parentName:"p"},"lsf-python-api")," python module you can launch workflows which contain components that use the ",(0,o.yg)("a",{parentName:"p",href:"/overview/workflow-specification#description-of-basic-flowir-component-fields"},(0,o.yg)("inlineCode",{parentName:"a"},"lsf"))," backend."),(0,o.yg)("h2",null,"Execute a workflow"),(0,o.yg)("p",null,"Use the ",(0,o.yg)("inlineCode",{parentName:"p"},"elaunch.py")," command-line utility that is included by installing ",(0,o.yg)("inlineCode",{parentName:"p"},"st4sd-runtime-core")," to run your workflows.\nFor example, you can run the toy workflow ",(0,o.yg)("a",{parentName:"p",href:"https://github.com/st4sd/sum-numbers"},(0,o.yg)("inlineCode",{parentName:"a"},"sum-numbers"))," like so:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/st4sd/sum-numbers.git\nelaunch.py --nostamp -l40 sum-numbers\n")),(0,o.yg)("h2",null,"Provide input files and override data files"),(0,o.yg)("p",null,"ST4SD workflows support 3 flavours of inputs:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"Input files - files user must provide when they execute the workflow"),(0,o.yg)("li",{parentName:"ol"},"Data files - configuration files that optionally can be overridden"),(0,o.yg)("li",{parentName:"ol"},"User variables - user provided values for workflow variables")),(0,o.yg)("p",null,"The ",(0,o.yg)("a",{parentName:"p",href:"/overview/tutorial#providing-inputs-to-workflows"},"tutorial")," contains more information about inputs."),(0,o.yg)("h3",null,"Example"),(0,o.yg)("p",null,"Here’s an example of a workflow that uses an ",(0,o.yg)("inlineCode",{parentName:"p"},"input")," file, a ",(0,o.yg)("inlineCode",{parentName:"p"},"data")," file, and a variable."),(0,o.yg)("p",null,"First, prepare the workflow definition files by running the following on your terminal:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},'cat <<EOF >workflow.yaml\nvariables:\n  default:\n    global:\n      var: hello\n\ncomponents:\n- name: hello\n  command:\n    executable: sh\n    arguments: |\n      <<EOF\n      echo variable contains "%(var)s"\n      echo input contents are "input/foo.txt:output"\n      echo data contents are "data/bar.txt:output"\n      EOF\n    expandArguments: none\n  references:\n  - input/foo.txt:output\n  - data/bar.txt:output\nEOF\n\ncat <<EOF >manifest.yaml\ndata: data\nEOF\n\nmkdir -p shared_data\ncat <<EOF >shared_data/bar.txt\ndata-file-contents\nEOF\n\ncat <<EOF >foo.txt\ninput-file-contents\nEOF\n\ncat <<EOF >my_vars.yaml\nglobal:\n  var: hi\nEOF\n')),(0,o.yg)("p",null,"The above script creates the following file structure:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},'workflow.yaml  # the workflow definition\nmanifest.yaml  # manifest that maps "shared_data" to "data"\nfoo.txt        # the input file\nmy_vars.yaml   # file containing user variables\nshared_data    # the directory containing "data" files\n└─ bar.txt\n')),(0,o.yg)("p",null,"Activate the virtual environment that you used to install ",(0,o.yg)("inlineCode",{parentName:"p"},"st4sd-runtime-core")," and then run:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},'elaunch.py -l40 --nostamp  \\\n      --failSafeDelays=no \\\n      --input foo.txt \\\n      --variables my_vars.yaml \\\n      --manifest manifest.yaml workflow.yaml\necho "\\n\\nComponent stdout was:"\ncat workflow.instance/stages/stage0/hello/out.stdout\n')),(0,o.yg)("p",null,"If you omit the ",(0,o.yg)("inlineCode",{parentName:"p"},"--variables")," parameter then the ",(0,o.yg)("inlineCode",{parentName:"p"},"var")," variable will receive the value that the ",(0,o.yg)("inlineCode",{parentName:"p"},"default")," platform sets to it."),(0,o.yg)("p",null,"You can override the contents of the ",(0,o.yg)("inlineCode",{parentName:"p"},"data")," file ",(0,o.yg)("inlineCode",{parentName:"p"},"bar.txt")," by adding the argument: ",(0,o.yg)("inlineCode",{parentName:"p"},"--data path/to/a/different/bar.txt"),".\nFinally, you can use the ",(0,o.yg)("inlineCode",{parentName:"p"},"--data")," and ",(0,o.yg)("inlineCode",{parentName:"p"},"--input")," parameters multiple times."),(0,o.yg)("h2",null,"Store outputs to S3"),(0,o.yg)("p",null,"Workflows may optionally define ",(0,o.yg)("a",{parentName:"p",href:"/overview/tutorial#key-outputs"},(0,o.yg)("inlineCode",{parentName:"a"},"key-outputs"))," which which ",(0,o.yg)("inlineCode",{parentName:"p"},"elaunch.py"),"\nmay upload to S3 after the experiment terminates."),(0,o.yg)("p",null,"You can instruct ",(0,o.yg)("inlineCode",{parentName:"p"},"elaunch.py")," to upload ",(0,o.yg)("inlineCode",{parentName:"p"},"key-outputs")," to S3 via the the ",(0,o.yg)("inlineCode",{parentName:"p"},"--s3StoreToURI")," parameter.\nWhen setting the parameter ",(0,o.yg)("inlineCode",{parentName:"p"},"--s3StoreToURI")," you must also use exactly one of the parameters ",(0,o.yg)("inlineCode",{parentName:"p"},"--s3AuthWithEnvVars")," or ",(0,o.yg)("inlineCode",{parentName:"p"},"--s3AuthBearer64"),"."),(0,o.yg)("h3",null,"Example:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},'export bucket="a-bucket"\nexport path_in_bucket="optional/path"\n\nexport S3_ACCESS_KEY_ID="s3 access key id"\nexport S3_SECRET_ACCESS_KEY="s3 secret access key"\nexport S3_END_POINT="s3 end point"\n\nelaunch.py --s3StoreToURI s3://${bucket}/${path_in_bucket} \\\n  --s3AuthWithEnvVars \\\n  path/to/workflow\n')),(0,o.yg)("p",null,"When ",(0,o.yg)("inlineCode",{parentName:"p"},"--s3StoreToURI")," is set, after the experiment terminates, ",(0,o.yg)("inlineCode",{parentName:"p"},"elaunch.py")," will start uploading the ",(0,o.yg)("inlineCode",{parentName:"p"},"key-outputs")," to the S3 bucket you provided under the specifeid ",(0,o.yg)("inlineCode",{parentName:"p"},"${path_in_bucket}"),".\n",(0,o.yg)("inlineCode",{parentName:"p"},"elaunch.py")," replaces occurences of the ",(0,o.yg)("inlineCode",{parentName:"p"},"%(instanceDir)s")," literal in ",(0,o.yg)("inlineCode",{parentName:"p"},"--s3StoreToURI")," with the name of the experiment instance.\nFor example, you can use this to store the ",(0,o.yg)("inlineCode",{parentName:"p"},"key-outputs")," of multiple workflow instances in the same bucket."),(0,o.yg)("p",null,"Alternatively, you can base64-encode the JSON representation of the dictionary ",(0,o.yg)("inlineCode",{parentName:"p"},'{"S3_ACCESS_KEY_ID": "val", "S3_SECRET_ACCESS_KEY": "val", "S3_END_POINT": "val"}')," and use the ",(0,o.yg)("inlineCode",{parentName:"p"},"--s3AuthBearer64")," parameter instead:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},'export bucket="a-bucket"\nexport path_in_bucket="optional/path"\nexport json="{\\"S3_ACCESS_KEY_ID\\": \\"val\\", \\"S3_SECRET_ACCESS_KEY\\": \\"val\\", \\"S3_END_POINT\\": \\"val\\"}"\nexport s3_auth=`echo "${json}" | base64`\n\nelaunch.py --s3StoreToURI s3://${bucket}/${path_in_bucket} \\\n  --s3AuthBearer64 \\\n  path/to/workflow\n')))}c.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-direct-run-mdx-21244c7b07340442cbb6.js.map